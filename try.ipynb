{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb2b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/root/miniconda3/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    },
    {
     "ename": "UnsupportedOperatorError",
     "evalue": "Exporting the operator 'aten::scaled_dot_product_attention' to ONNX opset version 11 is not supported. Support for this operator was added in version 14, try exporting with this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 1. 实例化模型（请填入与你训练时一致的超参数）\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# layers      = [1, 1, 1, 1]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# embed_dims  = [64, 128, 256, 512]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 3. 导出为 ONNX\u001b[39;00m\n\u001b[1;32m     29\u001b[0m onnx_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meff_unet2.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ ONNX 模型已保存到 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 4. （可选）加载并查看 ONNX 计算图结构\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/onnx/utils.py:1596\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1594\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1596\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1611\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1612\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/onnx/utils.py:1139\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1150\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch IR graph at exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/onnx/utils.py:677\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    674\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    675\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 677\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    679\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/onnx/utils.py:1950\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1947\u001b[0m         \u001b[38;5;66;03m# Clone node to trigger ONNX shape inference\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m graph_context\u001b[38;5;241m.\u001b[39mop(op_name, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattrs, outputs\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39moutputsSize())  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedOperatorError(\n\u001b[1;32m   1951\u001b[0m         symbolic_function_name,\n\u001b[1;32m   1952\u001b[0m         opset_version,\n\u001b[1;32m   1953\u001b[0m         symbolic_function_group\u001b[38;5;241m.\u001b[39mget_min_supported()\n\u001b[1;32m   1954\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m symbolic_function_group\n\u001b[1;32m   1955\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1956\u001b[0m     )\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m operator_export_type \u001b[38;5;241m==\u001b[39m _C_onnx\u001b[38;5;241m.\u001b[39mOperatorExportTypes\u001b[38;5;241m.\u001b[39mONNX_FALLTHROUGH:\n",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m: Exporting the operator 'aten::scaled_dot_product_attention' to ONNX opset version 11 is not supported. Support for this operator was added in version 14, try exporting with this version."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unet.eff_unet_mod import Eff_Unet  # 根据你的项目结构调整导入路径\n",
    "\n",
    "# from unet import Eff_Unet\n",
    "model = Eff_Unet(\n",
    "    layers=[5, 5, 15, 10],\n",
    "    embed_dims=[40, 80, 192, 384],\n",
    "    downsamples=[True, True, True, True],\n",
    "    vit_num=6,\n",
    "    drop_path_rate=0.1,\n",
    "    num_classes=8)\n",
    "# 2. 构造一个与训练时相同尺寸的假输入\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "# 1. 实例化模型（请填入与你训练时一致的超参数）\n",
    "# layers      = [1, 1, 1, 1]\n",
    "# embed_dims  = [64, 128, 256, 512]\n",
    "# downsamples = [True, True, True, True]\n",
    "# model       = Eff_Unet(\n",
    "#     layers=layers,\n",
    "#     embed_dims=embed_dims,\n",
    "#     downsamples=downsamples,\n",
    "#     num_classes=9      # 或者你实际的类别数\n",
    "# )\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "\n",
    "# 3. 导出为 ONNX\n",
    "onnx_path = \"eff_unet2.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=14,\n",
    "    do_constant_folding=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"},\n",
    "    },\n",
    "\n",
    ")\n",
    "print(f\"✅ ONNX 模型已保存到 {onnx_path}\")\n",
    "\n",
    "# 4. （可选）加载并查看 ONNX 计算图结构\n",
    "try:\n",
    "    import onnx\n",
    "    from onnx import helper\n",
    "\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    # 打印前 1000 字符，必要时可调整或直接打印整个 graph\n",
    "    print(helper.printable_graph(onnx_model.graph)[:1000] + \"\\n...\")\n",
    "except ImportError:\n",
    "    print(\"❗ 未安装 onnx 库，请先运行：pip install onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28f5cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NodeIdent' from 'onnx.tools.net_drawer' (/root/miniconda3/lib/python3.10/site-packages/onnx/tools/net_drawer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. 安装依赖（如果还没安装）\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#    pip install onnx pydot graphviz\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet_drawer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GetPydotGraph, NodeIdent\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 2. 加载 ONNX 模型\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meff_unet.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'NodeIdent' from 'onnx.tools.net_drawer' (/root/miniconda3/lib/python3.10/site-packages/onnx/tools/net_drawer.py)"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx.tools.net_drawer import GetPydotGraph\n",
    "\n",
    "# 1) Load your ONNX model\n",
    "model = onnx.load(\"eff_unet.onnx\")\n",
    "\n",
    "# 2) Build a pydot graph, supplying a small lambda to label each node\n",
    "graph = GetPydotGraph(\n",
    "    model.graph,\n",
    "    name=model.graph.name,\n",
    "    rankdir=\"TB\",\n",
    "    node_producer=lambda node: node.name or node.output[0]  # use node.name if set, else its first output\n",
    ")\n",
    "\n",
    "# 3) Dump out as SVG\n",
    "graph.write_svg(\"eff_unet.svg\")\n",
    "print(\"✅ Wrote eff_unet.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab5b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/root/miniconda3/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.onnx' has no attribute '_optimize_trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 3. 生成结构图\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# dummy_input = torch.zeros(1,3,224,224)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     35\u001b[0m graph\u001b[38;5;241m.\u001b[39mtheme \u001b[38;5;241m=\u001b[39m hl\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mTHEMES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m]       \u001b[38;5;66;03m# 选择主题，或改成你喜欢的配色\u001b[39;00m\n\u001b[1;32m     36\u001b[0m graph\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# 输出 PNG 文件\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hiddenlayer/graph.py:143\u001b[0m, in \u001b[0;36mbuild_graph\u001b[0;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument args must be provided for Pytorch models.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 143\u001b[0m     \u001b[43mimport_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hiddenlayer/pytorch_builder.py:71\u001b[0m, in \u001b[0;36mimport_graph\u001b[0;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_graph\u001b[39m(hl_graph, model, args, input_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# TODO: add input names to graph\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     trace, out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_get_trace_graph(model, args)\n\u001b[0;32m---> 71\u001b[0m     torch_graph \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_trace\u001b[49m(trace, torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mOperatorExportTypes\u001b[38;5;241m.\u001b[39mONNX)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# Dump list of nodes (DEBUG only)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.onnx' has no attribute '_optimize_trace'"
     ]
    }
   ],
   "source": [
    "# 1. 安装依赖\n",
    "# pip install hiddenlayer graphviz torch\n",
    "\n",
    "import torch\n",
    "import hiddenlayer as hl\n",
    "from unet.eff_unet_mod import Eff_Unet  # 根据你的项目结构调整导入路径\n",
    "\n",
    "# from unet import Eff_Unet\n",
    "model = Eff_Unet(\n",
    "    layers=[5, 5, 15, 10],\n",
    "    embed_dims=[40, 80, 192, 384],\n",
    "    downsamples=[True, True, True, True],\n",
    "    vit_num=6,\n",
    "    drop_path_rate=0.1,\n",
    "    num_classes=8)\n",
    "# 1. 实例化模型（请填入与你训练时一致的超参数）\n",
    "# layers      = [1, 1, 1, 1]\n",
    "# embed_dims  = [64, 128, 256, 512]\n",
    "# downsamples = [True, True, True, True]\n",
    "# model       = Eff_Unet(\n",
    "#     layers=layers,\n",
    "#     embed_dims=embed_dims,\n",
    "#     downsamples=downsamples,\n",
    "#     num_classes=9      # 或者你实际的类别数\n",
    "# )\n",
    "# model.eval()\n",
    "\n",
    "# 2. 构造一个与训练时相同尺寸的假输入\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "model.eval()\n",
    "\n",
    "# 3. 生成结构图\n",
    "# dummy_input = torch.zeros(1,3,224,224)\n",
    "graph = hl.build_graph(model, dummy_input)  \n",
    "graph.theme = hl.graph.THEMES[\"blue\"]       # 选择主题，或改成你喜欢的配色\n",
    "graph.save(\"model_structure\", format=\"png\") # 输出 PNG 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362bf200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已生成 eff_unet_fx_graph.svg，可查看子模块和数据流。\n"
     ]
    }
   ],
   "source": [
    "# 安装依赖\n",
    "# pip install torch torchviz graphviz\n",
    "\n",
    "import torch\n",
    "import torch.fx as fx\n",
    "from torchviz import make_dot\n",
    "from unet.eff_unet_mod import Eff_Unet  # 替换为你的模块路径\n",
    "\n",
    "# 1. 实例化模型\n",
    "model = Eff_Unet(\n",
    "    layers=[5, 5, 15, 10],\n",
    "    embed_dims=[40, 80, 192, 384],\n",
    "    downsamples=[True, True, True, True],\n",
    "    vit_num=6,\n",
    "    drop_path_rate=0.1,\n",
    "    num_classes=8,\n",
    "    resolution=224,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# 2. 用 FX 追踪得到 GraphModule\n",
    "dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "traced: fx.GraphModule = fx.symbolic_trace(model)\n",
    "\n",
    "# 3. 将 FX Graph 转为计算图，然后渲染\n",
    "#    make_dot 会显示节点名为 fx 节点（call_module）对应的子模块\n",
    "y = traced(dummy_input)\n",
    "dot = make_dot(y, params=dict(model.named_parameters()))\n",
    "dot.format = 'svg'\n",
    "dot.render('eff_unet_fx_graph')\n",
    "\n",
    "print(\"✅ 已生成 eff_unet_fx_graph.svg，可查看子模块和数据流。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
