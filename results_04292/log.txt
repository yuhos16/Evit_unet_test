[01:26:58.785] Namespace(root_path='/root/autodl-tmp/dataset/HAM10000/pd2/npz_data', dataset='ham', list_dir='/root/autodl-tmp/dataset/HAM10000/pd2/text', num_classes=8, output_dir='./results_04292', max_iterations=30000, max_epochs=5000, batch_size=32, n_gpu=1, deterministic=1, base_lr=0.0001, img_size=224, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, gpu_id=0, lambda_x=0.015, dino_weight=0.3, alpha=20.0, sigma=5.0, load_model='')
[01:26:58.817] 220 iterations per epoch. 1100000 max iterations 
[01:27:11.241] iteration 1 : loss : 1.396911, loss_ce: 2.177760
[01:27:11.486] iteration 2 : loss : 1.366155, loss_ce: 2.142658
[01:27:11.721] iteration 3 : loss : 1.386372, loss_ce: 2.134820
[01:27:11.952] iteration 4 : loss : 1.381124, loss_ce: 2.138476
[01:27:12.184] iteration 5 : loss : 1.372364, loss_ce: 2.116028
[01:27:12.420] iteration 6 : loss : 1.362125, loss_ce: 2.098698
[01:27:12.654] iteration 7 : loss : 1.356007, loss_ce: 2.081619
[01:27:12.889] iteration 8 : loss : 1.362036, loss_ce: 2.093567
[01:27:13.152] iteration 9 : loss : 1.367745, loss_ce: 2.084360
[01:27:13.393] iteration 10 : loss : 1.349235, loss_ce: 2.056116
[01:27:13.630] iteration 11 : loss : 1.319760, loss_ce: 2.029814
[01:27:13.868] iteration 12 : loss : 1.359372, loss_ce: 2.045768
[01:27:14.102] iteration 13 : loss : 1.311723, loss_ce: 2.005440
[01:27:14.345] iteration 14 : loss : 1.340403, loss_ce: 2.029844
[01:27:14.582] iteration 15 : loss : 1.318777, loss_ce: 2.009846
[01:27:14.818] iteration 16 : loss : 1.298953, loss_ce: 2.017287
[01:27:16.384] iteration 17 : loss : 1.316342, loss_ce: 1.983765
[01:27:16.638] iteration 18 : loss : 1.300036, loss_ce: 1.950397
[01:27:16.890] iteration 19 : loss : 1.316300, loss_ce: 1.981155
[01:27:17.161] iteration 20 : loss : 1.276706, loss_ce: 1.935709
[01:27:17.418] iteration 21 : loss : 1.279004, loss_ce: 1.936043
[01:27:17.671] iteration 22 : loss : 1.294509, loss_ce: 1.933834
[01:27:17.905] iteration 23 : loss : 1.282716, loss_ce: 1.912001
[01:27:18.143] iteration 24 : loss : 1.292410, loss_ce: 1.952347
[01:27:19.429] iteration 25 : loss : 1.251861, loss_ce: 1.898879
[01:27:19.664] iteration 26 : loss : 1.254113, loss_ce: 1.885480
[01:27:19.893] iteration 27 : loss : 1.289406, loss_ce: 1.910985
[01:27:20.128] iteration 28 : loss : 1.270646, loss_ce: 1.908425
[01:27:20.364] iteration 29 : loss : 1.240206, loss_ce: 1.831132
[01:27:20.599] iteration 30 : loss : 1.283603, loss_ce: 1.882230
[01:27:20.832] iteration 31 : loss : 1.262866, loss_ce: 1.878187
[01:27:21.063] iteration 32 : loss : 1.244098, loss_ce: 1.836275
[01:27:22.475] iteration 33 : loss : 1.247016, loss_ce: 1.822172
[01:27:22.712] iteration 34 : loss : 1.233656, loss_ce: 1.820837
[01:27:22.948] iteration 35 : loss : 1.240794, loss_ce: 1.826030
[01:27:23.189] iteration 36 : loss : 1.227544, loss_ce: 1.819125
[01:27:23.422] iteration 37 : loss : 1.221137, loss_ce: 1.816269
[01:27:23.654] iteration 38 : loss : 1.198216, loss_ce: 1.777748
[01:27:23.884] iteration 39 : loss : 1.214200, loss_ce: 1.764836
[01:27:24.121] iteration 40 : loss : 1.248490, loss_ce: 1.779883
[01:27:25.539] iteration 41 : loss : 1.209314, loss_ce: 1.730714
[01:27:25.773] iteration 42 : loss : 1.199204, loss_ce: 1.736900
[01:27:26.002] iteration 43 : loss : 1.168730, loss_ce: 1.692277
[01:27:26.237] iteration 44 : loss : 1.182635, loss_ce: 1.754408
[01:27:26.477] iteration 45 : loss : 1.182550, loss_ce: 1.702878
[01:27:26.711] iteration 46 : loss : 1.200163, loss_ce: 1.763695
[01:27:26.940] iteration 47 : loss : 1.163415, loss_ce: 1.714346
[01:27:27.174] iteration 48 : loss : 1.162485, loss_ce: 1.706745
[01:27:28.564] iteration 49 : loss : 1.166065, loss_ce: 1.697589
[01:27:28.821] iteration 50 : loss : 1.162658, loss_ce: 1.669746
[01:27:29.073] iteration 51 : loss : 1.186401, loss_ce: 1.687415
[01:27:29.325] iteration 52 : loss : 1.147284, loss_ce: 1.643423
[01:27:29.579] iteration 53 : loss : 1.167689, loss_ce: 1.695655
[01:27:29.831] iteration 54 : loss : 1.151599, loss_ce: 1.642336
[01:27:30.101] iteration 55 : loss : 1.143617, loss_ce: 1.658103
[01:27:30.570] iteration 56 : loss : 1.150762, loss_ce: 1.674638
[01:27:31.526] iteration 57 : loss : 1.156526, loss_ce: 1.670509
[01:27:31.778] iteration 58 : loss : 1.127767, loss_ce: 1.601925
[01:27:32.031] iteration 59 : loss : 1.175949, loss_ce: 1.631675
[01:27:32.283] iteration 60 : loss : 1.119994, loss_ce: 1.591599
[01:27:32.537] iteration 61 : loss : 1.108691, loss_ce: 1.579496
[01:27:32.829] iteration 62 : loss : 1.107448, loss_ce: 1.604385
[01:27:33.087] iteration 63 : loss : 1.119276, loss_ce: 1.584255
[01:27:33.340] iteration 64 : loss : 1.149539, loss_ce: 1.621878
[01:27:34.399] iteration 65 : loss : 1.121609, loss_ce: 1.599222
[01:27:34.653] iteration 66 : loss : 1.118913, loss_ce: 1.566531
[01:27:34.906] iteration 67 : loss : 1.124768, loss_ce: 1.564518
[01:27:35.162] iteration 68 : loss : 1.108839, loss_ce: 1.552807
[01:27:35.416] iteration 69 : loss : 1.155056, loss_ce: 1.641296
[01:27:35.668] iteration 70 : loss : 1.121304, loss_ce: 1.605283
[01:27:35.922] iteration 71 : loss : 1.130089, loss_ce: 1.589018
[01:27:36.220] iteration 72 : loss : 1.081974, loss_ce: 1.511204
[01:27:37.445] iteration 73 : loss : 1.087786, loss_ce: 1.494240
[01:27:37.709] iteration 74 : loss : 1.076453, loss_ce: 1.501331
[01:27:37.971] iteration 75 : loss : 1.085727, loss_ce: 1.505052
[01:27:38.231] iteration 76 : loss : 1.101350, loss_ce: 1.542122
[01:27:38.484] iteration 77 : loss : 1.105057, loss_ce: 1.569983
[01:27:38.737] iteration 78 : loss : 1.082261, loss_ce: 1.521029
[01:27:38.990] iteration 79 : loss : 1.107620, loss_ce: 1.566516
[01:27:39.243] iteration 80 : loss : 1.057345, loss_ce: 1.455023
[01:27:40.436] iteration 81 : loss : 1.078094, loss_ce: 1.496875
[01:27:40.689] iteration 82 : loss : 1.085476, loss_ce: 1.483289
[01:27:40.942] iteration 83 : loss : 1.059530, loss_ce: 1.470724
[01:27:41.194] iteration 84 : loss : 1.080634, loss_ce: 1.505315
[01:27:41.447] iteration 85 : loss : 1.094146, loss_ce: 1.530265
[01:27:41.701] iteration 86 : loss : 1.073103, loss_ce: 1.495586
[01:27:41.954] iteration 87 : loss : 1.051077, loss_ce: 1.455209
[01:27:42.209] iteration 88 : loss : 1.057292, loss_ce: 1.448194
[01:27:43.419] iteration 89 : loss : 1.066128, loss_ce: 1.497224
[01:27:43.674] iteration 90 : loss : 1.062133, loss_ce: 1.494846
[01:27:43.927] iteration 91 : loss : 1.057512, loss_ce: 1.440926
[01:27:44.179] iteration 92 : loss : 1.059372, loss_ce: 1.489145
[01:27:44.432] iteration 93 : loss : 1.051043, loss_ce: 1.427500
[01:27:44.688] iteration 94 : loss : 1.039374, loss_ce: 1.424837
[01:27:44.942] iteration 95 : loss : 1.040528, loss_ce: 1.451271
[01:27:45.197] iteration 96 : loss : 1.027145, loss_ce: 1.385181
[01:27:46.556] iteration 97 : loss : 1.025759, loss_ce: 1.381345
[01:27:46.810] iteration 98 : loss : 1.045857, loss_ce: 1.421947
[01:27:47.067] iteration 99 : loss : 1.059083, loss_ce: 1.508283
[01:27:47.321] iteration 100 : loss : 1.032339, loss_ce: 1.404729
[01:27:47.575] iteration 101 : loss : 1.070416, loss_ce: 1.456491
[01:27:47.827] iteration 102 : loss : 1.012614, loss_ce: 1.424377
[01:27:48.079] iteration 103 : loss : 1.007381, loss_ce: 1.362153
[01:27:48.336] iteration 104 : loss : 1.024793, loss_ce: 1.420938
[01:27:49.525] iteration 105 : loss : 1.037982, loss_ce: 1.411385
[01:27:49.779] iteration 106 : loss : 1.016116, loss_ce: 1.375401
[01:27:50.034] iteration 107 : loss : 1.054084, loss_ce: 1.449048
[01:27:50.293] iteration 108 : loss : 0.997602, loss_ce: 1.341898
[01:27:50.547] iteration 109 : loss : 1.019141, loss_ce: 1.425311
[01:27:50.803] iteration 110 : loss : 1.018808, loss_ce: 1.382314
[01:27:51.059] iteration 111 : loss : 1.008473, loss_ce: 1.367420
[01:27:51.314] iteration 112 : loss : 1.024697, loss_ce: 1.338202
[01:27:52.510] iteration 113 : loss : 1.020919, loss_ce: 1.406282
[01:27:52.763] iteration 114 : loss : 1.012405, loss_ce: 1.337581
[01:27:53.018] iteration 115 : loss : 1.003388, loss_ce: 1.371864
[01:27:53.275] iteration 116 : loss : 0.984082, loss_ce: 1.343438
[01:27:53.528] iteration 117 : loss : 1.011607, loss_ce: 1.406494
[01:27:53.781] iteration 118 : loss : 1.031101, loss_ce: 1.415359
[01:27:54.036] iteration 119 : loss : 1.010523, loss_ce: 1.367133
[01:27:54.290] iteration 120 : loss : 1.008497, loss_ce: 1.358900
[01:27:55.461] iteration 121 : loss : 0.979273, loss_ce: 1.321178
[01:27:55.716] iteration 122 : loss : 0.986694, loss_ce: 1.344512
[01:27:55.971] iteration 123 : loss : 1.026127, loss_ce: 1.375847
[01:27:56.225] iteration 124 : loss : 0.953863, loss_ce: 1.276001
[01:27:56.479] iteration 125 : loss : 0.991624, loss_ce: 1.351058
[01:27:56.734] iteration 126 : loss : 0.959053, loss_ce: 1.313814
[01:27:56.988] iteration 127 : loss : 0.999046, loss_ce: 1.342968
[01:27:57.243] iteration 128 : loss : 0.985027, loss_ce: 1.311709
[01:27:58.502] iteration 129 : loss : 1.014159, loss_ce: 1.347751
[01:27:58.757] iteration 130 : loss : 1.003282, loss_ce: 1.353551
[01:27:59.009] iteration 131 : loss : 0.969977, loss_ce: 1.326442
[01:27:59.266] iteration 132 : loss : 0.951809, loss_ce: 1.276204
[01:27:59.518] iteration 133 : loss : 0.976425, loss_ce: 1.278802
[01:27:59.775] iteration 134 : loss : 1.006551, loss_ce: 1.355769
[01:28:00.031] iteration 135 : loss : 0.990325, loss_ce: 1.300434
[01:28:00.283] iteration 136 : loss : 0.984973, loss_ce: 1.318212
[01:28:01.538] iteration 137 : loss : 0.987824, loss_ce: 1.339250
[01:28:01.793] iteration 138 : loss : 0.968900, loss_ce: 1.288527
[01:28:02.047] iteration 139 : loss : 0.970595, loss_ce: 1.258683
[01:28:02.439] iteration 140 : loss : 0.953556, loss_ce: 1.244233
[01:28:02.726] iteration 141 : loss : 0.969986, loss_ce: 1.292066
[01:28:02.980] iteration 142 : loss : 0.977395, loss_ce: 1.300289
[01:28:03.232] iteration 143 : loss : 0.990980, loss_ce: 1.352672
[01:28:03.485] iteration 144 : loss : 0.948487, loss_ce: 1.262614
[01:28:04.451] iteration 145 : loss : 0.968767, loss_ce: 1.309056
[01:28:04.704] iteration 146 : loss : 0.970788, loss_ce: 1.285452
[01:28:04.958] iteration 147 : loss : 0.949892, loss_ce: 1.281856
[01:28:05.362] iteration 148 : loss : 0.979277, loss_ce: 1.294058
[01:28:05.615] iteration 149 : loss : 0.994521, loss_ce: 1.301267
[01:28:05.868] iteration 150 : loss : 0.969733, loss_ce: 1.308494
[01:28:06.123] iteration 151 : loss : 0.981318, loss_ce: 1.321438
[01:28:06.375] iteration 152 : loss : 0.932757, loss_ce: 1.243660
[01:28:07.429] iteration 153 : loss : 0.944066, loss_ce: 1.238658
[01:28:07.683] iteration 154 : loss : 0.930860, loss_ce: 1.226782
[01:28:07.936] iteration 155 : loss : 0.925318, loss_ce: 1.191451
[01:28:08.253] iteration 156 : loss : 0.934546, loss_ce: 1.201317
[01:28:08.508] iteration 157 : loss : 0.929278, loss_ce: 1.231459
[01:28:08.761] iteration 158 : loss : 0.977561, loss_ce: 1.299741
[01:28:09.015] iteration 159 : loss : 0.966620, loss_ce: 1.311624
[01:28:09.267] iteration 160 : loss : 0.953958, loss_ce: 1.216183
[01:28:10.392] iteration 161 : loss : 0.915259, loss_ce: 1.217232
[01:28:10.647] iteration 162 : loss : 0.905993, loss_ce: 1.157893
[01:28:10.928] iteration 163 : loss : 0.942653, loss_ce: 1.201322
[01:28:11.264] iteration 164 : loss : 0.947724, loss_ce: 1.255603
[01:28:11.541] iteration 165 : loss : 0.955532, loss_ce: 1.269933
[01:28:11.871] iteration 166 : loss : 0.916030, loss_ce: 1.187372
[01:28:12.135] iteration 167 : loss : 0.963426, loss_ce: 1.239312
[01:28:12.387] iteration 168 : loss : 0.892704, loss_ce: 1.131883
[01:28:13.394] iteration 169 : loss : 0.993942, loss_ce: 1.302945
[01:28:13.647] iteration 170 : loss : 0.926272, loss_ce: 1.202450
[01:28:13.900] iteration 171 : loss : 0.942250, loss_ce: 1.225451
[01:28:14.211] iteration 172 : loss : 0.929062, loss_ce: 1.202314
[01:28:14.473] iteration 173 : loss : 0.933472, loss_ce: 1.208014
[01:28:14.728] iteration 174 : loss : 0.929091, loss_ce: 1.254338
[01:28:14.985] iteration 175 : loss : 0.951423, loss_ce: 1.271058
[01:28:15.238] iteration 176 : loss : 0.905017, loss_ce: 1.198185
[01:28:16.361] iteration 177 : loss : 0.925172, loss_ce: 1.219188
[01:28:16.616] iteration 178 : loss : 0.897726, loss_ce: 1.177334
[01:28:16.871] iteration 179 : loss : 0.977733, loss_ce: 1.271353
[01:28:17.127] iteration 180 : loss : 0.890517, loss_ce: 1.154945
[01:28:17.383] iteration 181 : loss : 0.909605, loss_ce: 1.211395
[01:28:17.634] iteration 182 : loss : 1.009007, loss_ce: 1.370847
[01:28:17.890] iteration 183 : loss : 0.922755, loss_ce: 1.228529
[01:28:18.147] iteration 184 : loss : 0.892251, loss_ce: 1.147501
[01:28:19.244] iteration 185 : loss : 0.925428, loss_ce: 1.157593
[01:28:19.496] iteration 186 : loss : 0.921719, loss_ce: 1.177596
[01:28:19.893] iteration 187 : loss : 0.916411, loss_ce: 1.149025
[01:28:20.174] iteration 188 : loss : 0.931161, loss_ce: 1.229822
[01:28:20.445] iteration 189 : loss : 0.930442, loss_ce: 1.202744
[01:28:20.705] iteration 190 : loss : 0.918366, loss_ce: 1.170370
[01:28:20.958] iteration 191 : loss : 0.884345, loss_ce: 1.100849
[01:28:21.214] iteration 192 : loss : 0.909697, loss_ce: 1.188943
[01:28:22.232] iteration 193 : loss : 0.920486, loss_ce: 1.177021
[01:28:22.487] iteration 194 : loss : 0.926049, loss_ce: 1.189096
[01:28:22.775] iteration 195 : loss : 0.879693, loss_ce: 1.103432
[01:28:23.139] iteration 196 : loss : 0.927812, loss_ce: 1.171743
[01:28:23.394] iteration 197 : loss : 0.893252, loss_ce: 1.132698
[01:28:23.649] iteration 198 : loss : 0.866454, loss_ce: 1.094518
[01:28:23.903] iteration 199 : loss : 0.908332, loss_ce: 1.177268
[01:28:24.158] iteration 200 : loss : 0.885800, loss_ce: 1.126397
[01:28:25.282] iteration 201 : loss : 0.926365, loss_ce: 1.174266
[01:28:25.536] iteration 202 : loss : 0.897610, loss_ce: 1.139016
[01:28:25.791] iteration 203 : loss : 0.909190, loss_ce: 1.199830
[01:28:26.167] iteration 204 : loss : 0.902261, loss_ce: 1.164817
[01:28:26.431] iteration 205 : loss : 0.935535, loss_ce: 1.218583
[01:28:26.684] iteration 206 : loss : 0.875158, loss_ce: 1.134089
[01:28:26.938] iteration 207 : loss : 0.860630, loss_ce: 1.130622
[01:28:27.192] iteration 208 : loss : 0.864652, loss_ce: 1.077680
[01:28:28.269] iteration 209 : loss : 0.910880, loss_ce: 1.118157
[01:28:28.523] iteration 210 : loss : 0.866621, loss_ce: 1.102542
[01:28:28.775] iteration 211 : loss : 0.940694, loss_ce: 1.154163
[01:28:29.161] iteration 212 : loss : 0.887350, loss_ce: 1.076648
[01:28:29.416] iteration 213 : loss : 0.933308, loss_ce: 1.213730
[01:28:29.667] iteration 214 : loss : 0.878078, loss_ce: 1.103833
[01:28:29.918] iteration 215 : loss : 0.872857, loss_ce: 1.071827
[01:28:30.172] iteration 216 : loss : 0.911301, loss_ce: 1.141025
[01:28:31.179] iteration 217 : loss : 0.904340, loss_ce: 1.146394
[01:28:31.431] iteration 218 : loss : 0.901958, loss_ce: 1.156925
[01:28:31.682] iteration 219 : loss : 0.910326, loss_ce: 1.172132
[01:28:32.283] iteration 220 : loss : 1.091176, loss_ce: 1.440876
[01:28:37.313] iteration 221 : loss : 0.877300, loss_ce: 1.065365
[01:28:37.566] iteration 222 : loss : 0.889320, loss_ce: 1.099616
[01:28:37.819] iteration 223 : loss : 0.862180, loss_ce: 1.077479
[01:28:38.074] iteration 224 : loss : 0.892070, loss_ce: 1.077339
[01:28:38.326] iteration 225 : loss : 0.866066, loss_ce: 1.104482
[01:28:38.579] iteration 226 : loss : 0.913958, loss_ce: 1.165031
[01:28:38.833] iteration 227 : loss : 0.819102, loss_ce: 1.030289
[01:28:39.087] iteration 228 : loss : 0.846891, loss_ce: 1.076459
[01:28:40.190] iteration 229 : loss : 0.847517, loss_ce: 1.041898
[01:28:40.446] iteration 230 : loss : 0.883299, loss_ce: 1.146413
[01:28:40.699] iteration 231 : loss : 0.868830, loss_ce: 1.067897
[01:28:40.953] iteration 232 : loss : 0.872732, loss_ce: 1.141707
[01:28:41.207] iteration 233 : loss : 0.923627, loss_ce: 1.152746
[01:28:41.460] iteration 234 : loss : 0.852138, loss_ce: 1.053014
[01:28:41.715] iteration 235 : loss : 0.853313, loss_ce: 1.068166
[01:28:41.968] iteration 236 : loss : 0.857247, loss_ce: 1.042929
[01:28:43.194] iteration 237 : loss : 0.866615, loss_ce: 1.082931
[01:28:43.448] iteration 238 : loss : 0.862618, loss_ce: 1.046820
[01:28:43.701] iteration 239 : loss : 0.876154, loss_ce: 1.127071
[01:28:43.957] iteration 240 : loss : 0.883231, loss_ce: 1.149432
[01:28:44.210] iteration 241 : loss : 0.850518, loss_ce: 1.032886
[01:28:44.463] iteration 242 : loss : 0.875283, loss_ce: 1.098224
[01:28:44.718] iteration 243 : loss : 0.876566, loss_ce: 1.062797
[01:28:44.972] iteration 244 : loss : 0.839020, loss_ce: 1.008856
[01:28:46.207] iteration 245 : loss : 0.852283, loss_ce: 1.061257
[01:28:46.517] iteration 246 : loss : 0.860284, loss_ce: 1.081528
[01:28:46.859] iteration 247 : loss : 0.868606, loss_ce: 1.081970
[01:28:47.113] iteration 248 : loss : 0.846140, loss_ce: 1.061063
[01:28:47.371] iteration 249 : loss : 0.874077, loss_ce: 1.096214
[01:28:47.626] iteration 250 : loss : 0.849077, loss_ce: 1.061880
[01:28:47.879] iteration 251 : loss : 0.850402, loss_ce: 1.008731
[01:28:48.135] iteration 252 : loss : 0.809776, loss_ce: 0.942936
[01:28:49.265] iteration 253 : loss : 0.885160, loss_ce: 1.072135
[01:28:49.518] iteration 254 : loss : 0.860294, loss_ce: 1.034311
[01:28:49.776] iteration 255 : loss : 0.892545, loss_ce: 1.132293
[01:28:50.033] iteration 256 : loss : 0.818776, loss_ce: 0.979700
[01:28:50.316] iteration 257 : loss : 0.889607, loss_ce: 1.118012
[01:28:50.570] iteration 258 : loss : 0.840798, loss_ce: 1.049427
[01:28:50.825] iteration 259 : loss : 0.878692, loss_ce: 1.038244
[01:28:51.078] iteration 260 : loss : 0.851072, loss_ce: 1.002562
[01:28:52.349] iteration 261 : loss : 0.816948, loss_ce: 0.959875
[01:28:52.604] iteration 262 : loss : 0.836665, loss_ce: 1.000528
[01:28:52.858] iteration 263 : loss : 0.816126, loss_ce: 0.988213
[01:28:53.114] iteration 264 : loss : 0.834746, loss_ce: 1.034739
[01:28:53.370] iteration 265 : loss : 0.849494, loss_ce: 1.018019
[01:28:53.627] iteration 266 : loss : 0.872474, loss_ce: 1.076265
[01:28:53.882] iteration 267 : loss : 0.832510, loss_ce: 0.994152
[01:28:54.135] iteration 268 : loss : 0.850082, loss_ce: 1.001700
[01:28:55.373] iteration 269 : loss : 0.815566, loss_ce: 0.964074
[01:28:55.628] iteration 270 : loss : 0.833372, loss_ce: 1.011598
[01:28:55.882] iteration 271 : loss : 0.847425, loss_ce: 1.068176
[01:28:56.140] iteration 272 : loss : 0.847542, loss_ce: 1.058653
[01:28:56.410] iteration 273 : loss : 0.845391, loss_ce: 1.048695
[01:28:56.665] iteration 274 : loss : 0.827549, loss_ce: 0.999138
[01:28:56.918] iteration 275 : loss : 0.820552, loss_ce: 0.960838
[01:28:57.175] iteration 276 : loss : 0.811875, loss_ce: 0.991261
[01:28:58.396] iteration 277 : loss : 0.819707, loss_ce: 0.973266
[01:28:58.652] iteration 278 : loss : 0.826076, loss_ce: 1.073255
[01:28:58.911] iteration 279 : loss : 0.855274, loss_ce: 1.051541
[01:28:59.167] iteration 280 : loss : 0.832835, loss_ce: 0.974651
[01:28:59.427] iteration 281 : loss : 0.845800, loss_ce: 1.029666
[01:28:59.681] iteration 282 : loss : 0.829866, loss_ce: 1.016997
[01:28:59.939] iteration 283 : loss : 0.823481, loss_ce: 0.999474
[01:29:00.192] iteration 284 : loss : 0.856027, loss_ce: 1.040531
[01:29:01.439] iteration 285 : loss : 0.803512, loss_ce: 0.968633
[01:29:01.744] iteration 286 : loss : 0.877735, loss_ce: 1.120090
[01:29:02.003] iteration 287 : loss : 0.825536, loss_ce: 1.023594
[01:29:02.258] iteration 288 : loss : 0.841070, loss_ce: 0.993676
[01:29:02.512] iteration 289 : loss : 0.813977, loss_ce: 0.964301
[01:29:02.778] iteration 290 : loss : 0.826214, loss_ce: 0.955546
[01:29:03.042] iteration 291 : loss : 0.838805, loss_ce: 1.041003
[01:29:03.295] iteration 292 : loss : 0.818125, loss_ce: 1.003791
[01:29:04.516] iteration 293 : loss : 0.836420, loss_ce: 1.023288
[01:29:04.824] iteration 294 : loss : 0.806488, loss_ce: 0.951845
[01:29:05.077] iteration 295 : loss : 0.833605, loss_ce: 0.974360
[01:29:05.341] iteration 296 : loss : 0.796069, loss_ce: 0.926267
[01:29:05.598] iteration 297 : loss : 0.852574, loss_ce: 1.043075
[01:29:05.854] iteration 298 : loss : 0.834401, loss_ce: 1.018757
[01:29:06.109] iteration 299 : loss : 0.804803, loss_ce: 0.976747
[01:29:06.367] iteration 300 : loss : 0.895824, loss_ce: 1.100920
[01:29:07.678] iteration 301 : loss : 0.835676, loss_ce: 0.994057
[01:29:07.937] iteration 302 : loss : 0.800284, loss_ce: 0.993270
[01:29:08.194] iteration 303 : loss : 0.847056, loss_ce: 1.023327
[01:29:08.447] iteration 304 : loss : 0.832595, loss_ce: 0.983692
[01:29:08.702] iteration 305 : loss : 0.794233, loss_ce: 0.951820
[01:29:08.955] iteration 306 : loss : 0.837840, loss_ce: 0.988119
[01:29:09.211] iteration 307 : loss : 0.791600, loss_ce: 0.886556
[01:29:09.467] iteration 308 : loss : 0.800168, loss_ce: 0.952313
[01:29:10.684] iteration 309 : loss : 0.824141, loss_ce: 0.973615
[01:29:10.927] iteration 310 : loss : 0.788043, loss_ce: 0.936705
[01:29:11.183] iteration 311 : loss : 0.814600, loss_ce: 1.013378
[01:29:11.437] iteration 312 : loss : 0.791090, loss_ce: 0.924273
[01:29:11.690] iteration 313 : loss : 0.831376, loss_ce: 0.966382
[01:29:11.944] iteration 314 : loss : 0.859695, loss_ce: 0.983131
[01:29:12.197] iteration 315 : loss : 0.844959, loss_ce: 0.999260
[01:29:12.463] iteration 316 : loss : 0.789283, loss_ce: 0.911607
[01:29:13.507] iteration 317 : loss : 0.820937, loss_ce: 0.986201
[01:29:13.761] iteration 318 : loss : 0.801981, loss_ce: 0.958808
[01:29:14.224] iteration 319 : loss : 0.794409, loss_ce: 0.888903
[01:29:14.477] iteration 320 : loss : 0.801711, loss_ce: 0.972230
[01:29:14.730] iteration 321 : loss : 0.784011, loss_ce: 0.950682
[01:29:14.983] iteration 322 : loss : 0.834196, loss_ce: 0.985553
[01:29:15.238] iteration 323 : loss : 0.804828, loss_ce: 0.954756
[01:29:15.491] iteration 324 : loss : 0.786658, loss_ce: 0.944029
[01:29:16.185] iteration 325 : loss : 0.769515, loss_ce: 0.926995
[01:29:16.438] iteration 326 : loss : 0.798981, loss_ce: 0.857133
[01:29:16.691] iteration 327 : loss : 0.816865, loss_ce: 1.012486
[01:29:16.944] iteration 328 : loss : 0.804581, loss_ce: 0.895269
[01:29:17.197] iteration 329 : loss : 0.794682, loss_ce: 0.929304
[01:29:17.450] iteration 330 : loss : 0.801994, loss_ce: 0.940996
[01:29:17.703] iteration 331 : loss : 0.779006, loss_ce: 0.866768
[01:29:17.955] iteration 332 : loss : 0.782717, loss_ce: 0.891925
[01:29:18.893] iteration 333 : loss : 0.807785, loss_ce: 0.928577
[01:29:19.145] iteration 334 : loss : 0.800001, loss_ce: 0.920374
[01:29:19.397] iteration 335 : loss : 0.823300, loss_ce: 0.957608
[01:29:19.648] iteration 336 : loss : 0.800335, loss_ce: 0.935432
[01:29:19.899] iteration 337 : loss : 0.805958, loss_ce: 0.949314
[01:29:20.151] iteration 338 : loss : 0.754943, loss_ce: 0.851361
[01:29:20.416] iteration 339 : loss : 0.806386, loss_ce: 0.967572
[01:29:20.743] iteration 340 : loss : 0.777117, loss_ce: 0.848076
[01:29:21.722] iteration 341 : loss : 0.769717, loss_ce: 0.869148
[01:29:21.975] iteration 342 : loss : 0.786293, loss_ce: 0.892103
[01:29:22.227] iteration 343 : loss : 0.783519, loss_ce: 0.960481
[01:29:22.480] iteration 344 : loss : 0.832681, loss_ce: 1.013759
[01:29:22.732] iteration 345 : loss : 0.776328, loss_ce: 0.893208
[01:29:22.984] iteration 346 : loss : 0.764905, loss_ce: 0.890357
[01:29:23.235] iteration 347 : loss : 0.775561, loss_ce: 0.905563
[01:29:23.488] iteration 348 : loss : 0.787858, loss_ce: 0.929669
[01:29:24.577] iteration 349 : loss : 0.789727, loss_ce: 0.947139
[01:29:24.833] iteration 350 : loss : 0.792603, loss_ce: 0.960572
[01:29:25.111] iteration 351 : loss : 0.835930, loss_ce: 1.030535
[01:29:25.365] iteration 352 : loss : 0.820092, loss_ce: 0.989277
[01:29:25.617] iteration 353 : loss : 0.813652, loss_ce: 0.939238
[01:29:25.870] iteration 354 : loss : 0.773679, loss_ce: 0.907802
[01:29:26.125] iteration 355 : loss : 0.744911, loss_ce: 0.850158
[01:29:26.377] iteration 356 : loss : 0.775113, loss_ce: 0.893081
[01:29:27.584] iteration 357 : loss : 0.792375, loss_ce: 0.924711
[01:29:27.839] iteration 358 : loss : 0.785765, loss_ce: 0.909393
[01:29:28.094] iteration 359 : loss : 0.750679, loss_ce: 0.856221
[01:29:28.359] iteration 360 : loss : 0.754541, loss_ce: 0.887723
[01:29:28.653] iteration 361 : loss : 0.832060, loss_ce: 1.016506
[01:29:28.907] iteration 362 : loss : 0.813795, loss_ce: 1.047434
[01:29:29.165] iteration 363 : loss : 0.830779, loss_ce: 1.023169
[01:29:29.426] iteration 364 : loss : 0.812268, loss_ce: 0.971669
[01:29:30.731] iteration 365 : loss : 0.765445, loss_ce: 0.880928
[01:29:30.985] iteration 366 : loss : 0.765895, loss_ce: 0.877270
[01:29:31.242] iteration 367 : loss : 0.782197, loss_ce: 0.887611
[01:29:31.495] iteration 368 : loss : 0.777503, loss_ce: 0.868008
[01:29:31.763] iteration 369 : loss : 0.764076, loss_ce: 0.878587
[01:29:32.032] iteration 370 : loss : 0.817538, loss_ce: 0.948960
[01:29:32.286] iteration 371 : loss : 0.795001, loss_ce: 0.897442
[01:29:32.550] iteration 372 : loss : 0.780441, loss_ce: 0.830884
[01:29:33.704] iteration 373 : loss : 0.746003, loss_ce: 0.823563
[01:29:33.960] iteration 374 : loss : 0.804248, loss_ce: 0.945802
[01:29:34.219] iteration 375 : loss : 0.749631, loss_ce: 0.882446
[01:29:34.473] iteration 376 : loss : 0.772309, loss_ce: 0.866222
[01:29:34.729] iteration 377 : loss : 0.748256, loss_ce: 0.844972
[01:29:34.983] iteration 378 : loss : 0.766219, loss_ce: 0.915682
[01:29:35.239] iteration 379 : loss : 0.767570, loss_ce: 0.843283
[01:29:35.492] iteration 380 : loss : 0.771518, loss_ce: 0.901310
[01:29:36.784] iteration 381 : loss : 0.785726, loss_ce: 0.883936
[01:29:37.037] iteration 382 : loss : 0.817908, loss_ce: 0.929940
[01:29:37.292] iteration 383 : loss : 0.757394, loss_ce: 0.807657
[01:29:37.546] iteration 384 : loss : 0.809345, loss_ce: 0.941408
[01:29:37.799] iteration 385 : loss : 0.758897, loss_ce: 0.810895
[01:29:38.053] iteration 386 : loss : 0.813921, loss_ce: 0.945849
[01:29:38.307] iteration 387 : loss : 0.794612, loss_ce: 0.903855
[01:29:38.564] iteration 388 : loss : 0.758486, loss_ce: 0.869067
[01:29:39.716] iteration 389 : loss : 0.757348, loss_ce: 0.864326
[01:29:39.970] iteration 390 : loss : 0.749560, loss_ce: 0.853008
[01:29:40.225] iteration 391 : loss : 0.753714, loss_ce: 0.876621
[01:29:40.482] iteration 392 : loss : 0.776887, loss_ce: 0.881034
[01:29:40.737] iteration 393 : loss : 0.783122, loss_ce: 0.895113
[01:29:40.993] iteration 394 : loss : 0.764411, loss_ce: 0.829522
[01:29:41.248] iteration 395 : loss : 0.752744, loss_ce: 0.837025
[01:29:41.500] iteration 396 : loss : 0.727818, loss_ce: 0.789744
[01:29:42.717] iteration 397 : loss : 0.736809, loss_ce: 0.812869
[01:29:42.971] iteration 398 : loss : 0.745273, loss_ce: 0.824340
[01:29:43.228] iteration 399 : loss : 0.764727, loss_ce: 0.843901
[01:29:43.482] iteration 400 : loss : 0.769994, loss_ce: 0.916028
[01:29:43.739] iteration 401 : loss : 0.742639, loss_ce: 0.835895
[01:29:43.993] iteration 402 : loss : 0.750544, loss_ce: 0.815998
[01:29:44.248] iteration 403 : loss : 0.732945, loss_ce: 0.789406
[01:29:44.501] iteration 404 : loss : 0.738699, loss_ce: 0.825555
[01:29:45.660] iteration 405 : loss : 0.759327, loss_ce: 0.882095
[01:29:45.915] iteration 406 : loss : 0.753510, loss_ce: 0.851672
[01:29:46.171] iteration 407 : loss : 0.763281, loss_ce: 0.872753
[01:29:46.424] iteration 408 : loss : 0.723612, loss_ce: 0.815609
[01:29:46.678] iteration 409 : loss : 0.742110, loss_ce: 0.838944
[01:29:46.932] iteration 410 : loss : 0.755734, loss_ce: 0.811289
[01:29:47.186] iteration 411 : loss : 0.737259, loss_ce: 0.846235
[01:29:47.440] iteration 412 : loss : 0.710453, loss_ce: 0.773894
[01:29:48.556] iteration 413 : loss : 0.708708, loss_ce: 0.755156
[01:29:48.810] iteration 414 : loss : 0.751026, loss_ce: 0.870590
[01:29:49.067] iteration 415 : loss : 0.798906, loss_ce: 0.969226
[01:29:49.323] iteration 416 : loss : 0.790913, loss_ce: 0.887001
[01:29:49.578] iteration 417 : loss : 0.725307, loss_ce: 0.854317
[01:29:49.830] iteration 418 : loss : 0.704244, loss_ce: 0.791925
[01:29:50.084] iteration 419 : loss : 0.765149, loss_ce: 0.925617
[01:29:50.341] iteration 420 : loss : 0.791170, loss_ce: 0.938240
[01:29:51.574] iteration 421 : loss : 0.736331, loss_ce: 0.812409
[01:29:51.827] iteration 422 : loss : 0.732401, loss_ce: 0.832338
[01:29:52.080] iteration 423 : loss : 0.734131, loss_ce: 0.837056
[01:29:52.335] iteration 424 : loss : 0.762459, loss_ce: 0.851545
[01:29:52.591] iteration 425 : loss : 0.741129, loss_ce: 0.817766
[01:29:52.849] iteration 426 : loss : 0.715356, loss_ce: 0.792757
[01:29:53.105] iteration 427 : loss : 0.750677, loss_ce: 0.886388
[01:29:53.363] iteration 428 : loss : 0.729294, loss_ce: 0.807121
[01:29:54.419] iteration 429 : loss : 0.731527, loss_ce: 0.834256
[01:29:54.673] iteration 430 : loss : 0.736279, loss_ce: 0.785785
[01:29:54.928] iteration 431 : loss : 0.706476, loss_ce: 0.749916
[01:29:55.184] iteration 432 : loss : 0.729692, loss_ce: 0.853213
[01:29:55.491] iteration 433 : loss : 0.736805, loss_ce: 0.806623
[01:29:55.794] iteration 434 : loss : 0.722880, loss_ce: 0.822603
[01:29:56.078] iteration 435 : loss : 0.752017, loss_ce: 0.879671
[01:29:56.407] iteration 436 : loss : 0.721761, loss_ce: 0.794710
[01:29:57.285] iteration 437 : loss : 0.736340, loss_ce: 0.867104
[01:29:57.538] iteration 438 : loss : 0.751766, loss_ce: 0.854103
[01:29:57.791] iteration 439 : loss : 0.749235, loss_ce: 0.844497
[01:29:57.982] iteration 440 : loss : 0.794709, loss_ce: 0.852458
[01:30:02.537] iteration 441 : loss : 0.739470, loss_ce: 0.837522
[01:30:02.774] iteration 442 : loss : 0.720480, loss_ce: 0.809002
[01:30:03.005] iteration 443 : loss : 0.772288, loss_ce: 0.842616
[01:30:03.239] iteration 444 : loss : 0.744581, loss_ce: 0.830536
[01:30:03.493] iteration 445 : loss : 0.752586, loss_ce: 0.852975
[01:30:03.747] iteration 446 : loss : 0.750290, loss_ce: 0.837142
[01:30:04.002] iteration 447 : loss : 0.729261, loss_ce: 0.796154
[01:30:04.259] iteration 448 : loss : 0.746574, loss_ce: 0.870855
[01:30:05.663] iteration 449 : loss : 0.727394, loss_ce: 0.828462
[01:30:05.917] iteration 450 : loss : 0.753644, loss_ce: 0.815371
[01:30:06.380] iteration 451 : loss : 0.718852, loss_ce: 0.756618
[01:30:06.636] iteration 452 : loss : 0.738562, loss_ce: 0.783358
[01:30:06.891] iteration 453 : loss : 0.700587, loss_ce: 0.704959
[01:30:07.147] iteration 454 : loss : 0.782436, loss_ce: 0.895199
[01:30:07.400] iteration 455 : loss : 0.704209, loss_ce: 0.757611
[01:30:07.657] iteration 456 : loss : 0.743771, loss_ce: 0.850839
[01:30:08.628] iteration 457 : loss : 0.711941, loss_ce: 0.788327
[01:30:08.886] iteration 458 : loss : 0.708988, loss_ce: 0.773307
[01:30:09.161] iteration 459 : loss : 0.715244, loss_ce: 0.810610
[01:30:09.427] iteration 460 : loss : 0.734800, loss_ce: 0.812795
[01:30:09.683] iteration 461 : loss : 0.708070, loss_ce: 0.737073
[01:30:09.938] iteration 462 : loss : 0.748556, loss_ce: 0.801154
[01:30:10.194] iteration 463 : loss : 0.734082, loss_ce: 0.819678
[01:30:10.447] iteration 464 : loss : 0.676138, loss_ce: 0.745193
[01:30:11.664] iteration 465 : loss : 0.722043, loss_ce: 0.781784
[01:30:11.918] iteration 466 : loss : 0.749919, loss_ce: 0.831269
[01:30:12.173] iteration 467 : loss : 0.683262, loss_ce: 0.751771
[01:30:12.431] iteration 468 : loss : 0.722995, loss_ce: 0.795053
[01:30:12.687] iteration 469 : loss : 0.700587, loss_ce: 0.751453
[01:30:12.944] iteration 470 : loss : 0.737355, loss_ce: 0.757607
[01:30:13.200] iteration 471 : loss : 0.686789, loss_ce: 0.735049
[01:30:13.456] iteration 472 : loss : 0.732244, loss_ce: 0.838836
[01:30:14.665] iteration 473 : loss : 0.725901, loss_ce: 0.755799
[01:30:14.920] iteration 474 : loss : 0.662784, loss_ce: 0.700387
[01:30:15.174] iteration 475 : loss : 0.676155, loss_ce: 0.717627
[01:30:15.429] iteration 476 : loss : 0.701932, loss_ce: 0.784647
[01:30:15.683] iteration 477 : loss : 0.649331, loss_ce: 0.701520
[01:30:15.939] iteration 478 : loss : 0.696476, loss_ce: 0.730120
[01:30:16.195] iteration 479 : loss : 0.737510, loss_ce: 0.825333
[01:30:16.450] iteration 480 : loss : 0.697654, loss_ce: 0.765356
[01:30:17.682] iteration 481 : loss : 0.653206, loss_ce: 0.704910
[01:30:17.939] iteration 482 : loss : 0.726573, loss_ce: 0.814651
[01:30:18.194] iteration 483 : loss : 0.702302, loss_ce: 0.789385
[01:30:18.449] iteration 484 : loss : 0.777862, loss_ce: 0.931039
[01:30:18.705] iteration 485 : loss : 0.707526, loss_ce: 0.756018
[01:30:18.959] iteration 486 : loss : 0.746871, loss_ce: 0.789712
[01:30:19.214] iteration 487 : loss : 0.738688, loss_ce: 0.803966
[01:30:19.472] iteration 488 : loss : 0.672074, loss_ce: 0.725916
[01:30:20.850] iteration 489 : loss : 0.684788, loss_ce: 0.722867
[01:30:21.106] iteration 490 : loss : 0.684742, loss_ce: 0.704268
[01:30:21.362] iteration 491 : loss : 0.781615, loss_ce: 0.892327
[01:30:21.615] iteration 492 : loss : 0.674844, loss_ce: 0.684464
[01:30:21.876] iteration 493 : loss : 0.692970, loss_ce: 0.710978
[01:30:22.130] iteration 494 : loss : 0.730051, loss_ce: 0.802237
[01:30:22.383] iteration 495 : loss : 0.689234, loss_ce: 0.720270
[01:30:22.638] iteration 496 : loss : 0.727035, loss_ce: 0.781741
[01:30:23.797] iteration 497 : loss : 0.689738, loss_ce: 0.732763
[01:30:24.094] iteration 498 : loss : 0.696909, loss_ce: 0.754002
[01:30:24.366] iteration 499 : loss : 0.679630, loss_ce: 0.711671
[01:30:24.619] iteration 500 : loss : 0.672916, loss_ce: 0.722096
[01:30:24.872] iteration 501 : loss : 0.722640, loss_ce: 0.845755
[01:30:25.126] iteration 502 : loss : 0.709868, loss_ce: 0.755581
[01:30:25.379] iteration 503 : loss : 0.651347, loss_ce: 0.681476
[01:30:25.632] iteration 504 : loss : 0.694445, loss_ce: 0.735910
[01:30:26.788] iteration 505 : loss : 0.699289, loss_ce: 0.738908
[01:30:27.043] iteration 506 : loss : 0.690156, loss_ce: 0.753119
[01:30:27.297] iteration 507 : loss : 0.692741, loss_ce: 0.740541
[01:30:27.550] iteration 508 : loss : 0.710019, loss_ce: 0.745451
[01:30:28.009] iteration 509 : loss : 0.682873, loss_ce: 0.689046
[01:30:28.263] iteration 510 : loss : 0.691069, loss_ce: 0.734954
[01:30:28.516] iteration 511 : loss : 0.733322, loss_ce: 0.781109
[01:30:28.770] iteration 512 : loss : 0.755399, loss_ce: 0.787022
[01:30:29.708] iteration 513 : loss : 0.780547, loss_ce: 0.893546
[01:30:29.965] iteration 514 : loss : 0.698562, loss_ce: 0.768722
[01:30:30.270] iteration 515 : loss : 0.666396, loss_ce: 0.716129
[01:30:30.602] iteration 516 : loss : 0.732170, loss_ce: 0.777841
[01:30:31.194] iteration 517 : loss : 0.687227, loss_ce: 0.699143
[01:30:31.510] iteration 518 : loss : 0.671532, loss_ce: 0.738370
[01:30:31.776] iteration 519 : loss : 0.752408, loss_ce: 0.816184
[01:30:32.033] iteration 520 : loss : 0.660802, loss_ce: 0.699862
[01:30:32.842] iteration 521 : loss : 0.686456, loss_ce: 0.783735
[01:30:33.095] iteration 522 : loss : 0.700048, loss_ce: 0.738036
[01:30:33.348] iteration 523 : loss : 0.719645, loss_ce: 0.800790
[01:30:33.602] iteration 524 : loss : 0.673058, loss_ce: 0.710316
[01:30:34.155] iteration 525 : loss : 0.683193, loss_ce: 0.765139
[01:30:34.412] iteration 526 : loss : 0.689945, loss_ce: 0.720736
[01:30:34.667] iteration 527 : loss : 0.705609, loss_ce: 0.758240
[01:30:34.923] iteration 528 : loss : 0.690471, loss_ce: 0.678629
[01:30:35.859] iteration 529 : loss : 0.731324, loss_ce: 0.773553
[01:30:36.112] iteration 530 : loss : 0.696766, loss_ce: 0.720490
[01:30:36.372] iteration 531 : loss : 0.670668, loss_ce: 0.719765
[01:30:36.628] iteration 532 : loss : 0.664712, loss_ce: 0.668096
[01:30:37.169] iteration 533 : loss : 0.742997, loss_ce: 0.762009
[01:30:37.424] iteration 534 : loss : 0.653872, loss_ce: 0.723316
[01:30:37.680] iteration 535 : loss : 0.627272, loss_ce: 0.633503
[01:30:37.935] iteration 536 : loss : 0.698215, loss_ce: 0.723007
[01:30:38.815] iteration 537 : loss : 0.698764, loss_ce: 0.745951
[01:30:39.073] iteration 538 : loss : 0.645826, loss_ce: 0.641747
[01:30:39.329] iteration 539 : loss : 0.648989, loss_ce: 0.646309
[01:30:39.583] iteration 540 : loss : 0.715596, loss_ce: 0.719762
[01:30:40.127] iteration 541 : loss : 0.680755, loss_ce: 0.743094
[01:30:40.383] iteration 542 : loss : 0.670281, loss_ce: 0.666180
[01:30:40.638] iteration 543 : loss : 0.723286, loss_ce: 0.786690
[01:30:40.896] iteration 544 : loss : 0.680483, loss_ce: 0.708770
[01:30:41.843] iteration 545 : loss : 0.723101, loss_ce: 0.697228
[01:30:42.098] iteration 546 : loss : 0.715102, loss_ce: 0.757340
[01:30:42.352] iteration 547 : loss : 0.692198, loss_ce: 0.738861
[01:30:42.606] iteration 548 : loss : 0.683086, loss_ce: 0.715614
[01:30:43.181] iteration 549 : loss : 0.692477, loss_ce: 0.697119
[01:30:43.435] iteration 550 : loss : 0.630455, loss_ce: 0.631530
[01:30:43.690] iteration 551 : loss : 0.672106, loss_ce: 0.742555
[01:30:43.943] iteration 552 : loss : 0.684626, loss_ce: 0.749749
[01:30:44.700] iteration 553 : loss : 0.660729, loss_ce: 0.664388
[01:30:44.954] iteration 554 : loss : 0.694651, loss_ce: 0.763424
[01:30:45.209] iteration 555 : loss : 0.662853, loss_ce: 0.681043
[01:30:45.464] iteration 556 : loss : 0.615158, loss_ce: 0.636654
[01:30:46.124] iteration 557 : loss : 0.631827, loss_ce: 0.629810
[01:30:46.381] iteration 558 : loss : 0.671351, loss_ce: 0.705671
[01:30:46.638] iteration 559 : loss : 0.618969, loss_ce: 0.653035
[01:30:46.892] iteration 560 : loss : 0.698473, loss_ce: 0.744083
[01:30:47.569] iteration 561 : loss : 0.678867, loss_ce: 0.673221
[01:30:47.827] iteration 562 : loss : 0.643518, loss_ce: 0.635372
[01:30:48.080] iteration 563 : loss : 0.654006, loss_ce: 0.681869
[01:30:48.336] iteration 564 : loss : 0.674877, loss_ce: 0.672960
[01:30:49.003] iteration 565 : loss : 0.698427, loss_ce: 0.716506
[01:30:49.255] iteration 566 : loss : 0.676303, loss_ce: 0.691380
[01:30:49.508] iteration 567 : loss : 0.692960, loss_ce: 0.772084
[01:30:49.740] iteration 568 : loss : 0.709259, loss_ce: 0.739759
[01:30:50.396] iteration 569 : loss : 0.642455, loss_ce: 0.697450
[01:30:50.627] iteration 570 : loss : 0.663615, loss_ce: 0.697777
[01:30:50.866] iteration 571 : loss : 0.728284, loss_ce: 0.704629
[01:30:51.094] iteration 572 : loss : 0.723833, loss_ce: 0.780253
[01:30:51.839] iteration 573 : loss : 0.683911, loss_ce: 0.712368
[01:30:52.068] iteration 574 : loss : 0.677434, loss_ce: 0.699541
[01:30:52.299] iteration 575 : loss : 0.647756, loss_ce: 0.631855
[01:30:52.533] iteration 576 : loss : 0.655864, loss_ce: 0.613482
[01:30:53.314] iteration 577 : loss : 0.659610, loss_ce: 0.612527
[01:30:53.549] iteration 578 : loss : 0.709543, loss_ce: 0.795750
[01:30:53.780] iteration 579 : loss : 0.700969, loss_ce: 0.716896
[01:30:54.144] iteration 580 : loss : 0.696575, loss_ce: 0.673378
[01:30:54.747] iteration 581 : loss : 0.662134, loss_ce: 0.650677
[01:30:54.978] iteration 582 : loss : 0.661018, loss_ce: 0.718303
[01:30:55.214] iteration 583 : loss : 0.685124, loss_ce: 0.676228
[01:30:55.447] iteration 584 : loss : 0.640368, loss_ce: 0.598000
[01:30:56.217] iteration 585 : loss : 0.625942, loss_ce: 0.624461
[01:30:56.447] iteration 586 : loss : 0.674117, loss_ce: 0.664056
[01:30:56.677] iteration 587 : loss : 0.634105, loss_ce: 0.619728
[01:30:56.908] iteration 588 : loss : 0.674196, loss_ce: 0.671266
[01:30:57.881] iteration 589 : loss : 0.644506, loss_ce: 0.637721
[01:30:58.118] iteration 590 : loss : 0.657856, loss_ce: 0.679787
[01:30:58.348] iteration 591 : loss : 0.633372, loss_ce: 0.550958
[01:30:58.579] iteration 592 : loss : 0.634174, loss_ce: 0.621764
[01:30:59.128] iteration 593 : loss : 0.635529, loss_ce: 0.623754
[01:30:59.358] iteration 594 : loss : 0.657308, loss_ce: 0.668145
[01:30:59.589] iteration 595 : loss : 0.653086, loss_ce: 0.684207
[01:30:59.823] iteration 596 : loss : 0.637403, loss_ce: 0.633838
[01:31:01.209] iteration 597 : loss : 0.626941, loss_ce: 0.630614
[01:31:01.440] iteration 598 : loss : 0.665116, loss_ce: 0.684154
[01:31:01.674] iteration 599 : loss : 0.716618, loss_ce: 0.703271
[01:31:01.904] iteration 600 : loss : 0.726714, loss_ce: 0.739955
[01:31:02.137] iteration 601 : loss : 0.763977, loss_ce: 0.851629
[01:31:02.372] iteration 602 : loss : 0.632460, loss_ce: 0.618825
[01:31:02.608] iteration 603 : loss : 0.656587, loss_ce: 0.647506
[01:31:02.842] iteration 604 : loss : 0.700221, loss_ce: 0.727994
[01:31:04.173] iteration 605 : loss : 0.678175, loss_ce: 0.688196
[01:31:04.403] iteration 606 : loss : 0.710859, loss_ce: 0.742439
[01:31:04.635] iteration 607 : loss : 0.713692, loss_ce: 0.792241
[01:31:04.870] iteration 608 : loss : 0.619474, loss_ce: 0.579988
[01:31:05.182] iteration 609 : loss : 0.712638, loss_ce: 0.742936
[01:31:05.456] iteration 610 : loss : 0.646599, loss_ce: 0.632687
[01:31:05.707] iteration 611 : loss : 0.695826, loss_ce: 0.716803
[01:31:05.977] iteration 612 : loss : 0.608555, loss_ce: 0.602739
[01:31:07.296] iteration 613 : loss : 0.676114, loss_ce: 0.711085
[01:31:07.528] iteration 614 : loss : 0.646749, loss_ce: 0.654458
[01:31:07.768] iteration 615 : loss : 0.660582, loss_ce: 0.707221
[01:31:08.002] iteration 616 : loss : 0.692904, loss_ce: 0.704828
[01:31:08.241] iteration 617 : loss : 0.669476, loss_ce: 0.693124
[01:31:08.478] iteration 618 : loss : 0.650996, loss_ce: 0.595943
[01:31:08.712] iteration 619 : loss : 0.642868, loss_ce: 0.621331
[01:31:08.940] iteration 620 : loss : 0.656924, loss_ce: 0.600232
[01:31:10.324] iteration 621 : loss : 0.660981, loss_ce: 0.686505
[01:31:10.559] iteration 622 : loss : 0.635242, loss_ce: 0.648465
[01:31:10.791] iteration 623 : loss : 0.671207, loss_ce: 0.630469
[01:31:11.031] iteration 624 : loss : 0.709567, loss_ce: 0.780615
[01:31:11.268] iteration 625 : loss : 0.670482, loss_ce: 0.611153
[01:31:11.502] iteration 626 : loss : 0.634179, loss_ce: 0.643903
[01:31:11.736] iteration 627 : loss : 0.630108, loss_ce: 0.586979
[01:31:11.967] iteration 628 : loss : 0.618747, loss_ce: 0.602677
[01:31:13.451] iteration 629 : loss : 0.660862, loss_ce: 0.651021
[01:31:13.686] iteration 630 : loss : 0.659038, loss_ce: 0.646055
[01:31:13.919] iteration 631 : loss : 0.732961, loss_ce: 0.735782
[01:31:14.158] iteration 632 : loss : 0.665024, loss_ce: 0.673671
[01:31:14.398] iteration 633 : loss : 0.657139, loss_ce: 0.664515
[01:31:14.631] iteration 634 : loss : 0.621787, loss_ce: 0.654831
[01:31:14.868] iteration 635 : loss : 0.619130, loss_ce: 0.618437
[01:31:15.103] iteration 636 : loss : 0.649549, loss_ce: 0.610059
[01:31:16.447] iteration 637 : loss : 0.644627, loss_ce: 0.673281
[01:31:16.679] iteration 638 : loss : 0.637196, loss_ce: 0.644880
[01:31:16.914] iteration 639 : loss : 0.599057, loss_ce: 0.582957
[01:31:17.169] iteration 640 : loss : 0.656534, loss_ce: 0.663344
[01:31:17.429] iteration 641 : loss : 0.638659, loss_ce: 0.628902
[01:31:17.683] iteration 642 : loss : 0.597077, loss_ce: 0.553173
[01:31:17.937] iteration 643 : loss : 0.643027, loss_ce: 0.635864
[01:31:18.192] iteration 644 : loss : 0.677698, loss_ce: 0.682551
[01:31:19.472] iteration 645 : loss : 0.636496, loss_ce: 0.564467
[01:31:19.728] iteration 646 : loss : 0.617525, loss_ce: 0.597855
[01:31:19.985] iteration 647 : loss : 0.586759, loss_ce: 0.537940
[01:31:20.243] iteration 648 : loss : 0.611396, loss_ce: 0.580149
[01:31:20.475] iteration 649 : loss : 0.650458, loss_ce: 0.592690
[01:31:20.707] iteration 650 : loss : 0.618395, loss_ce: 0.643788
[01:31:20.942] iteration 651 : loss : 0.590638, loss_ce: 0.553846
[01:31:21.172] iteration 652 : loss : 0.622219, loss_ce: 0.626111
[01:31:22.393] iteration 653 : loss : 0.622525, loss_ce: 0.588012
[01:31:22.627] iteration 654 : loss : 0.637079, loss_ce: 0.581489
[01:31:22.857] iteration 655 : loss : 0.698985, loss_ce: 0.689768
[01:31:23.082] iteration 656 : loss : 0.677716, loss_ce: 0.644942
[01:31:23.314] iteration 657 : loss : 0.604228, loss_ce: 0.597639
[01:31:23.536] iteration 658 : loss : 0.677788, loss_ce: 0.648558
[01:31:23.761] iteration 659 : loss : 0.611763, loss_ce: 0.576199
[01:31:23.905] iteration 660 : loss : 0.723107, loss_ce: 0.614158
[01:31:28.811] iteration 661 : loss : 0.650925, loss_ce: 0.622142
[01:31:29.067] iteration 662 : loss : 0.641457, loss_ce: 0.651435
[01:31:29.324] iteration 663 : loss : 0.639932, loss_ce: 0.637308
[01:31:29.578] iteration 664 : loss : 0.639598, loss_ce: 0.602124
[01:31:29.830] iteration 665 : loss : 0.679675, loss_ce: 0.684536
[01:31:30.085] iteration 666 : loss : 0.621688, loss_ce: 0.554831
[01:31:30.338] iteration 667 : loss : 0.623135, loss_ce: 0.590837
[01:31:30.590] iteration 668 : loss : 0.613054, loss_ce: 0.612783
[01:31:32.507] iteration 669 : loss : 0.645362, loss_ce: 0.560132
[01:31:32.790] iteration 670 : loss : 0.657488, loss_ce: 0.642676
[01:31:33.045] iteration 671 : loss : 0.626211, loss_ce: 0.560780
[01:31:33.300] iteration 672 : loss : 0.635705, loss_ce: 0.615860
[01:31:33.554] iteration 673 : loss : 0.658093, loss_ce: 0.620870
[01:31:33.809] iteration 674 : loss : 0.627922, loss_ce: 0.558613
[01:31:34.066] iteration 675 : loss : 0.615303, loss_ce: 0.548902
[01:31:34.324] iteration 676 : loss : 0.641803, loss_ce: 0.621481
[01:31:35.394] iteration 677 : loss : 0.625635, loss_ce: 0.610114
[01:31:35.647] iteration 678 : loss : 0.632786, loss_ce: 0.580693
[01:31:35.903] iteration 679 : loss : 0.749543, loss_ce: 0.792528
[01:31:36.155] iteration 680 : loss : 0.621363, loss_ce: 0.586378
[01:31:36.410] iteration 681 : loss : 0.634124, loss_ce: 0.629088
[01:31:36.680] iteration 682 : loss : 0.640734, loss_ce: 0.587603
[01:31:36.932] iteration 683 : loss : 0.661878, loss_ce: 0.647517
[01:31:37.188] iteration 684 : loss : 0.672731, loss_ce: 0.666746
[01:31:38.366] iteration 685 : loss : 0.574897, loss_ce: 0.508895
[01:31:38.620] iteration 686 : loss : 0.598910, loss_ce: 0.598934
[01:31:38.875] iteration 687 : loss : 0.627553, loss_ce: 0.554575
[01:31:39.128] iteration 688 : loss : 0.648031, loss_ce: 0.637639
[01:31:39.380] iteration 689 : loss : 0.646761, loss_ce: 0.617687
[01:31:39.635] iteration 690 : loss : 0.634314, loss_ce: 0.570592
[01:31:39.937] iteration 691 : loss : 0.693881, loss_ce: 0.704194
[01:31:40.250] iteration 692 : loss : 0.609717, loss_ce: 0.566106
[01:31:41.426] iteration 693 : loss : 0.597516, loss_ce: 0.552661
[01:31:41.679] iteration 694 : loss : 0.639785, loss_ce: 0.656206
[01:31:41.932] iteration 695 : loss : 0.616655, loss_ce: 0.576960
[01:31:42.185] iteration 696 : loss : 0.576645, loss_ce: 0.548225
[01:31:42.438] iteration 697 : loss : 0.671767, loss_ce: 0.647232
[01:31:42.693] iteration 698 : loss : 0.693488, loss_ce: 0.629096
[01:31:42.947] iteration 699 : loss : 0.582298, loss_ce: 0.547107
[01:31:43.204] iteration 700 : loss : 0.607942, loss_ce: 0.566811
[01:31:44.395] iteration 701 : loss : 0.585521, loss_ce: 0.565615
[01:31:44.651] iteration 702 : loss : 0.597530, loss_ce: 0.542377
[01:31:44.907] iteration 703 : loss : 0.579984, loss_ce: 0.508217
[01:31:45.171] iteration 704 : loss : 0.607648, loss_ce: 0.597900
[01:31:45.425] iteration 705 : loss : 0.590882, loss_ce: 0.559864
[01:31:45.680] iteration 706 : loss : 0.632855, loss_ce: 0.578263
[01:31:45.932] iteration 707 : loss : 0.618284, loss_ce: 0.607560
[01:31:46.191] iteration 708 : loss : 0.647862, loss_ce: 0.589873
[01:31:47.419] iteration 709 : loss : 0.597389, loss_ce: 0.523614
[01:31:47.694] iteration 710 : loss : 0.626596, loss_ce: 0.563444
[01:31:47.949] iteration 711 : loss : 0.585250, loss_ce: 0.539686
[01:31:48.210] iteration 712 : loss : 0.630554, loss_ce: 0.585181
[01:31:48.492] iteration 713 : loss : 0.604042, loss_ce: 0.623947
[01:31:48.947] iteration 714 : loss : 0.590212, loss_ce: 0.560986
[01:31:49.202] iteration 715 : loss : 0.686574, loss_ce: 0.696622
[01:31:49.456] iteration 716 : loss : 0.652427, loss_ce: 0.698857
[01:31:51.161] iteration 717 : loss : 0.665552, loss_ce: 0.599310
[01:31:51.414] iteration 718 : loss : 0.606867, loss_ce: 0.543263
[01:31:51.669] iteration 719 : loss : 0.639856, loss_ce: 0.609666
[01:31:51.925] iteration 720 : loss : 0.649683, loss_ce: 0.629985
[01:31:52.179] iteration 721 : loss : 0.606105, loss_ce: 0.567326
[01:31:52.454] iteration 722 : loss : 0.598820, loss_ce: 0.532452
[01:31:52.710] iteration 723 : loss : 0.583224, loss_ce: 0.515659
[01:31:52.963] iteration 724 : loss : 0.590922, loss_ce: 0.504501
[01:31:54.200] iteration 725 : loss : 0.658896, loss_ce: 0.616295
[01:31:54.456] iteration 726 : loss : 0.618728, loss_ce: 0.602319
[01:31:54.711] iteration 727 : loss : 0.596348, loss_ce: 0.536027
[01:31:54.964] iteration 728 : loss : 0.676512, loss_ce: 0.660339
[01:31:55.228] iteration 729 : loss : 0.617484, loss_ce: 0.606923
[01:31:55.485] iteration 730 : loss : 0.652322, loss_ce: 0.670538
[01:31:55.746] iteration 731 : loss : 0.616943, loss_ce: 0.616082
[01:31:56.003] iteration 732 : loss : 0.592095, loss_ce: 0.534965
[01:31:57.251] iteration 733 : loss : 0.567164, loss_ce: 0.490598
[01:31:57.508] iteration 734 : loss : 0.545191, loss_ce: 0.502696
[01:31:57.762] iteration 735 : loss : 0.624950, loss_ce: 0.623230
[01:31:58.020] iteration 736 : loss : 0.610325, loss_ce: 0.557651
[01:31:58.285] iteration 737 : loss : 0.583613, loss_ce: 0.512190
[01:31:58.540] iteration 738 : loss : 0.583498, loss_ce: 0.526638
[01:31:58.798] iteration 739 : loss : 0.581970, loss_ce: 0.549459
[01:31:59.052] iteration 740 : loss : 0.593751, loss_ce: 0.555931
[01:32:00.318] iteration 741 : loss : 0.654592, loss_ce: 0.562762
[01:32:00.571] iteration 742 : loss : 0.609276, loss_ce: 0.544227
[01:32:00.823] iteration 743 : loss : 0.559399, loss_ce: 0.479404
[01:32:01.078] iteration 744 : loss : 0.654382, loss_ce: 0.631572
[01:32:01.333] iteration 745 : loss : 0.639256, loss_ce: 0.543358
[01:32:01.591] iteration 746 : loss : 0.613814, loss_ce: 0.569591
[01:32:01.845] iteration 747 : loss : 0.593133, loss_ce: 0.564638
[01:32:02.085] iteration 748 : loss : 0.643460, loss_ce: 0.591062
[01:32:03.338] iteration 749 : loss : 0.623267, loss_ce: 0.627798
[01:32:03.573] iteration 750 : loss : 0.619451, loss_ce: 0.496968
[01:32:03.807] iteration 751 : loss : 0.591662, loss_ce: 0.568317
[01:32:04.042] iteration 752 : loss : 0.658024, loss_ce: 0.604931
[01:32:04.284] iteration 753 : loss : 0.609547, loss_ce: 0.614482
[01:32:04.520] iteration 754 : loss : 0.711281, loss_ce: 0.735793
[01:32:04.752] iteration 755 : loss : 0.621058, loss_ce: 0.587227
[01:32:04.986] iteration 756 : loss : 0.586783, loss_ce: 0.557969
[01:32:06.363] iteration 757 : loss : 0.600270, loss_ce: 0.483532
[01:32:06.596] iteration 758 : loss : 0.574254, loss_ce: 0.531476
[01:32:06.825] iteration 759 : loss : 0.676378, loss_ce: 0.618179
[01:32:07.053] iteration 760 : loss : 0.599990, loss_ce: 0.600709
[01:32:07.287] iteration 761 : loss : 0.606594, loss_ce: 0.573879
[01:32:07.519] iteration 762 : loss : 0.607993, loss_ce: 0.590280
[01:32:07.756] iteration 763 : loss : 0.573809, loss_ce: 0.513544
[01:32:07.990] iteration 764 : loss : 0.657486, loss_ce: 0.578840
[01:32:09.221] iteration 765 : loss : 0.636118, loss_ce: 0.584228
[01:32:09.455] iteration 766 : loss : 0.585745, loss_ce: 0.539496
[01:32:09.687] iteration 767 : loss : 0.567375, loss_ce: 0.529792
[01:32:09.920] iteration 768 : loss : 0.651508, loss_ce: 0.622450
[01:32:10.158] iteration 769 : loss : 0.603586, loss_ce: 0.556710
[01:32:10.413] iteration 770 : loss : 0.576331, loss_ce: 0.539671
[01:32:10.668] iteration 771 : loss : 0.609595, loss_ce: 0.511366
[01:32:10.924] iteration 772 : loss : 0.627471, loss_ce: 0.554633
[01:32:12.286] iteration 773 : loss : 0.631275, loss_ce: 0.584991
[01:32:12.540] iteration 774 : loss : 0.602841, loss_ce: 0.568236
[01:32:12.811] iteration 775 : loss : 0.628035, loss_ce: 0.558167
[01:32:13.097] iteration 776 : loss : 0.590258, loss_ce: 0.531574
[01:32:13.332] iteration 777 : loss : 0.610919, loss_ce: 0.632017
[01:32:13.567] iteration 778 : loss : 0.603271, loss_ce: 0.600286
[01:32:13.799] iteration 779 : loss : 0.585518, loss_ce: 0.553067
[01:32:14.054] iteration 780 : loss : 0.654774, loss_ce: 0.605854
[01:32:15.249] iteration 781 : loss : 0.587158, loss_ce: 0.602240
[01:32:15.582] iteration 782 : loss : 0.601189, loss_ce: 0.529360
[01:32:15.848] iteration 783 : loss : 0.654197, loss_ce: 0.653413
[01:32:16.103] iteration 784 : loss : 0.678701, loss_ce: 0.701801
[01:32:16.359] iteration 785 : loss : 0.640564, loss_ce: 0.614879
[01:32:16.614] iteration 786 : loss : 0.605196, loss_ce: 0.527535
[01:32:16.875] iteration 787 : loss : 0.588675, loss_ce: 0.575051
[01:32:17.116] iteration 788 : loss : 0.611176, loss_ce: 0.562554
[01:32:18.193] iteration 789 : loss : 0.597035, loss_ce: 0.514414
[01:32:18.426] iteration 790 : loss : 0.639551, loss_ce: 0.580747
[01:32:18.657] iteration 791 : loss : 0.587891, loss_ce: 0.492397
[01:32:18.894] iteration 792 : loss : 0.620350, loss_ce: 0.580950
[01:32:19.133] iteration 793 : loss : 0.574980, loss_ce: 0.492268
[01:32:19.370] iteration 794 : loss : 0.620627, loss_ce: 0.511465
[01:32:19.609] iteration 795 : loss : 0.584138, loss_ce: 0.566899
[01:32:19.845] iteration 796 : loss : 0.657573, loss_ce: 0.623951
[01:32:21.170] iteration 797 : loss : 0.585833, loss_ce: 0.572077
[01:32:21.405] iteration 798 : loss : 0.615203, loss_ce: 0.560264
[01:32:21.644] iteration 799 : loss : 0.559711, loss_ce: 0.524310
[01:32:21.877] iteration 800 : loss : 0.617244, loss_ce: 0.540651
[01:32:22.119] iteration 801 : loss : 0.570344, loss_ce: 0.493276
[01:32:22.361] iteration 802 : loss : 0.592764, loss_ce: 0.565043
[01:32:22.599] iteration 803 : loss : 0.569619, loss_ce: 0.502371
[01:32:22.837] iteration 804 : loss : 0.566607, loss_ce: 0.472859
[01:32:24.149] iteration 805 : loss : 0.583087, loss_ce: 0.531194
[01:32:24.383] iteration 806 : loss : 0.567233, loss_ce: 0.482845
[01:32:24.620] iteration 807 : loss : 0.594209, loss_ce: 0.603071
[01:32:24.863] iteration 808 : loss : 0.563311, loss_ce: 0.522810
[01:32:25.098] iteration 809 : loss : 0.555609, loss_ce: 0.539298
[01:32:25.338] iteration 810 : loss : 0.614497, loss_ce: 0.581711
[01:32:25.574] iteration 811 : loss : 0.616169, loss_ce: 0.501807
[01:32:25.813] iteration 812 : loss : 0.573804, loss_ce: 0.549698
[01:32:27.240] iteration 813 : loss : 0.584024, loss_ce: 0.564806
[01:32:27.475] iteration 814 : loss : 0.610941, loss_ce: 0.551359
[01:32:27.711] iteration 815 : loss : 0.615291, loss_ce: 0.591872
[01:32:27.950] iteration 816 : loss : 0.557112, loss_ce: 0.425888
[01:32:28.192] iteration 817 : loss : 0.559899, loss_ce: 0.511075
[01:32:28.428] iteration 818 : loss : 0.540223, loss_ce: 0.455672
[01:32:28.667] iteration 819 : loss : 0.580291, loss_ce: 0.490887
[01:32:28.900] iteration 820 : loss : 0.597722, loss_ce: 0.530728
[01:32:30.274] iteration 821 : loss : 0.587700, loss_ce: 0.584429
[01:32:30.506] iteration 822 : loss : 0.625322, loss_ce: 0.602853
[01:32:30.736] iteration 823 : loss : 0.625734, loss_ce: 0.639347
[01:32:30.967] iteration 824 : loss : 0.616959, loss_ce: 0.588581
[01:32:31.205] iteration 825 : loss : 0.575075, loss_ce: 0.523854
[01:32:31.442] iteration 826 : loss : 0.556098, loss_ce: 0.523402
[01:32:31.684] iteration 827 : loss : 0.610703, loss_ce: 0.619803
[01:32:31.925] iteration 828 : loss : 0.648204, loss_ce: 0.619455
[01:32:33.198] iteration 829 : loss : 0.588464, loss_ce: 0.556737
[01:32:33.429] iteration 830 : loss : 0.621950, loss_ce: 0.632064
[01:32:33.660] iteration 831 : loss : 0.657001, loss_ce: 0.672954
[01:32:33.889] iteration 832 : loss : 0.595842, loss_ce: 0.619026
[01:32:34.127] iteration 833 : loss : 0.559644, loss_ce: 0.483010
[01:32:34.382] iteration 834 : loss : 0.537703, loss_ce: 0.511365
[01:32:34.658] iteration 835 : loss : 0.639201, loss_ce: 0.636991
[01:32:34.914] iteration 836 : loss : 0.619583, loss_ce: 0.582777
[01:32:36.179] iteration 837 : loss : 0.575632, loss_ce: 0.532715
[01:32:36.433] iteration 838 : loss : 0.579927, loss_ce: 0.506197
[01:32:36.686] iteration 839 : loss : 0.520704, loss_ce: 0.424144
[01:32:36.941] iteration 840 : loss : 0.546935, loss_ce: 0.425987
[01:32:37.194] iteration 841 : loss : 0.593405, loss_ce: 0.465359
[01:32:37.435] iteration 842 : loss : 0.616943, loss_ce: 0.524042
[01:32:37.672] iteration 843 : loss : 0.528286, loss_ce: 0.443308
[01:32:37.904] iteration 844 : loss : 0.617318, loss_ce: 0.578518
[01:32:39.081] iteration 845 : loss : 0.621413, loss_ce: 0.571742
[01:32:39.316] iteration 846 : loss : 0.616481, loss_ce: 0.530436
[01:32:39.546] iteration 847 : loss : 0.572413, loss_ce: 0.534837
[01:32:39.891] iteration 848 : loss : 0.588843, loss_ce: 0.502212
[01:32:40.136] iteration 849 : loss : 0.620836, loss_ce: 0.566447
[01:32:40.376] iteration 850 : loss : 0.622881, loss_ce: 0.606020
[01:32:40.617] iteration 851 : loss : 0.554463, loss_ce: 0.465556
[01:32:40.853] iteration 852 : loss : 0.568535, loss_ce: 0.551472
[01:32:42.082] iteration 853 : loss : 0.582128, loss_ce: 0.537292
[01:32:42.313] iteration 854 : loss : 0.566980, loss_ce: 0.478392
[01:32:42.549] iteration 855 : loss : 0.571810, loss_ce: 0.474082
[01:32:42.782] iteration 856 : loss : 0.599043, loss_ce: 0.541350
[01:32:43.019] iteration 857 : loss : 0.604665, loss_ce: 0.554480
[01:32:43.254] iteration 858 : loss : 0.519803, loss_ce: 0.460454
[01:32:43.489] iteration 859 : loss : 0.577852, loss_ce: 0.498301
[01:32:43.725] iteration 860 : loss : 0.612412, loss_ce: 0.560316
[01:32:45.078] iteration 861 : loss : 0.571200, loss_ce: 0.484423
[01:32:45.335] iteration 862 : loss : 0.595799, loss_ce: 0.542106
[01:32:45.591] iteration 863 : loss : 0.595870, loss_ce: 0.581117
[01:32:45.823] iteration 864 : loss : 0.564455, loss_ce: 0.535699
[01:32:46.057] iteration 865 : loss : 0.554449, loss_ce: 0.472196
[01:32:46.289] iteration 866 : loss : 0.590599, loss_ce: 0.518348
[01:32:46.526] iteration 867 : loss : 0.541883, loss_ce: 0.470976
[01:32:46.761] iteration 868 : loss : 0.593907, loss_ce: 0.556616
[01:32:47.967] iteration 869 : loss : 0.679437, loss_ce: 0.664663
[01:32:48.196] iteration 870 : loss : 0.610706, loss_ce: 0.547779
[01:32:48.421] iteration 871 : loss : 0.604070, loss_ce: 0.559626
[01:32:48.648] iteration 872 : loss : 0.577907, loss_ce: 0.488408
[01:32:48.870] iteration 873 : loss : 0.632393, loss_ce: 0.511881
[01:32:49.099] iteration 874 : loss : 0.612288, loss_ce: 0.527831
[01:32:49.345] iteration 875 : loss : 0.583304, loss_ce: 0.471368
[01:32:49.593] iteration 876 : loss : 0.652616, loss_ce: 0.701609
[01:32:50.738] iteration 877 : loss : 0.654881, loss_ce: 0.608913
[01:32:50.964] iteration 878 : loss : 0.604388, loss_ce: 0.561020
[01:32:51.193] iteration 879 : loss : 0.570042, loss_ce: 0.478617
[01:32:51.355] iteration 880 : loss : 0.646228, loss_ce: 0.438077
[01:32:56.051] iteration 881 : loss : 0.573937, loss_ce: 0.480906
[01:32:56.305] iteration 882 : loss : 0.629778, loss_ce: 0.592141
[01:32:56.563] iteration 883 : loss : 0.592497, loss_ce: 0.552316
[01:32:56.820] iteration 884 : loss : 0.574533, loss_ce: 0.538325
[01:32:57.077] iteration 885 : loss : 0.551494, loss_ce: 0.496552
[01:32:57.331] iteration 886 : loss : 0.598677, loss_ce: 0.542246
[01:32:57.588] iteration 887 : loss : 0.574338, loss_ce: 0.503640
[01:32:57.843] iteration 888 : loss : 0.571388, loss_ce: 0.516604
[01:32:59.161] iteration 889 : loss : 0.623142, loss_ce: 0.586142
[01:32:59.418] iteration 890 : loss : 0.560702, loss_ce: 0.551286
[01:32:59.675] iteration 891 : loss : 0.599309, loss_ce: 0.500943
[01:32:59.931] iteration 892 : loss : 0.605297, loss_ce: 0.576010
[01:33:00.187] iteration 893 : loss : 0.536525, loss_ce: 0.443465
[01:33:00.444] iteration 894 : loss : 0.613700, loss_ce: 0.572372
[01:33:00.700] iteration 895 : loss : 0.547011, loss_ce: 0.460307
[01:33:00.957] iteration 896 : loss : 0.709605, loss_ce: 0.775805
[01:33:02.293] iteration 897 : loss : 0.603386, loss_ce: 0.564187
[01:33:02.569] iteration 898 : loss : 0.618319, loss_ce: 0.622230
[01:33:02.824] iteration 899 : loss : 0.610320, loss_ce: 0.479055
[01:33:03.076] iteration 900 : loss : 0.585614, loss_ce: 0.532839
[01:33:03.329] iteration 901 : loss : 0.586596, loss_ce: 0.501391
[01:33:03.585] iteration 902 : loss : 0.564514, loss_ce: 0.468862
[01:33:03.839] iteration 903 : loss : 0.606371, loss_ce: 0.542790
[01:33:04.096] iteration 904 : loss : 0.591958, loss_ce: 0.510112
[01:33:05.330] iteration 905 : loss : 0.521099, loss_ce: 0.450756
[01:33:05.587] iteration 906 : loss : 0.525481, loss_ce: 0.447714
[01:33:05.842] iteration 907 : loss : 0.542058, loss_ce: 0.444680
[01:33:06.098] iteration 908 : loss : 0.513083, loss_ce: 0.436819
[01:33:06.354] iteration 909 : loss : 0.576825, loss_ce: 0.427557
[01:33:06.607] iteration 910 : loss : 0.525339, loss_ce: 0.400277
[01:33:06.863] iteration 911 : loss : 0.595117, loss_ce: 0.488135
[01:33:07.119] iteration 912 : loss : 0.567492, loss_ce: 0.450267
[01:33:08.370] iteration 913 : loss : 0.619751, loss_ce: 0.547112
[01:33:08.623] iteration 914 : loss : 0.530080, loss_ce: 0.431135
[01:33:08.877] iteration 915 : loss : 0.560658, loss_ce: 0.404242
[01:33:09.133] iteration 916 : loss : 0.547766, loss_ce: 0.409429
[01:33:09.388] iteration 917 : loss : 0.599675, loss_ce: 0.520098
[01:33:09.642] iteration 918 : loss : 0.612311, loss_ce: 0.529372
[01:33:09.895] iteration 919 : loss : 0.610407, loss_ce: 0.572670
[01:33:10.150] iteration 920 : loss : 0.571872, loss_ce: 0.521299
[01:33:11.488] iteration 921 : loss : 0.601494, loss_ce: 0.501087
[01:33:11.741] iteration 922 : loss : 0.558206, loss_ce: 0.453222
[01:33:11.996] iteration 923 : loss : 0.584305, loss_ce: 0.563857
[01:33:12.251] iteration 924 : loss : 0.533908, loss_ce: 0.486519
[01:33:12.506] iteration 925 : loss : 0.616186, loss_ce: 0.528108
[01:33:12.760] iteration 926 : loss : 0.579417, loss_ce: 0.532998
[01:33:13.016] iteration 927 : loss : 0.551324, loss_ce: 0.486759
[01:33:13.270] iteration 928 : loss : 0.627724, loss_ce: 0.550442
[01:33:14.460] iteration 929 : loss : 0.617416, loss_ce: 0.567850
[01:33:14.714] iteration 930 : loss : 0.625802, loss_ce: 0.555290
[01:33:14.967] iteration 931 : loss : 0.556281, loss_ce: 0.480087
[01:33:15.223] iteration 932 : loss : 0.647335, loss_ce: 0.582158
[01:33:15.480] iteration 933 : loss : 0.598052, loss_ce: 0.545312
[01:33:15.735] iteration 934 : loss : 0.575648, loss_ce: 0.499950
[01:33:15.990] iteration 935 : loss : 0.546105, loss_ce: 0.470565
[01:33:16.244] iteration 936 : loss : 0.577362, loss_ce: 0.551047
[01:33:17.388] iteration 937 : loss : 0.547171, loss_ce: 0.416383
[01:33:17.645] iteration 938 : loss : 0.573810, loss_ce: 0.493177
[01:33:17.902] iteration 939 : loss : 0.593010, loss_ce: 0.523391
[01:33:18.159] iteration 940 : loss : 0.538655, loss_ce: 0.439148
[01:33:18.412] iteration 941 : loss : 0.563651, loss_ce: 0.512726
[01:33:18.666] iteration 942 : loss : 0.546351, loss_ce: 0.450731
[01:33:18.918] iteration 943 : loss : 0.590033, loss_ce: 0.557434
[01:33:19.171] iteration 944 : loss : 0.599439, loss_ce: 0.510726
[01:33:20.299] iteration 945 : loss : 0.552335, loss_ce: 0.481384
[01:33:20.556] iteration 946 : loss : 0.584460, loss_ce: 0.480489
[01:33:20.812] iteration 947 : loss : 0.575622, loss_ce: 0.528519
[01:33:21.069] iteration 948 : loss : 0.570499, loss_ce: 0.522803
[01:33:21.364] iteration 949 : loss : 0.562240, loss_ce: 0.467357
[01:33:21.619] iteration 950 : loss : 0.609598, loss_ce: 0.562458
[01:33:21.873] iteration 951 : loss : 0.567962, loss_ce: 0.477214
[01:33:22.127] iteration 952 : loss : 0.524366, loss_ce: 0.478876
[01:33:23.224] iteration 953 : loss : 0.574649, loss_ce: 0.527693
[01:33:23.478] iteration 954 : loss : 0.566578, loss_ce: 0.476682
[01:33:23.730] iteration 955 : loss : 0.638892, loss_ce: 0.553746
[01:33:23.989] iteration 956 : loss : 0.550084, loss_ce: 0.514227
[01:33:24.299] iteration 957 : loss : 0.563916, loss_ce: 0.448810
[01:33:24.622] iteration 958 : loss : 0.595088, loss_ce: 0.495924
[01:33:24.910] iteration 959 : loss : 0.548035, loss_ce: 0.527110
[01:33:25.214] iteration 960 : loss : 0.550889, loss_ce: 0.499023
[01:33:26.235] iteration 961 : loss : 0.583217, loss_ce: 0.479132
[01:33:26.489] iteration 962 : loss : 0.613073, loss_ce: 0.596739
[01:33:26.744] iteration 963 : loss : 0.585274, loss_ce: 0.490749
[01:33:26.998] iteration 964 : loss : 0.551602, loss_ce: 0.470903
[01:33:27.374] iteration 965 : loss : 0.565680, loss_ce: 0.469924
[01:33:27.627] iteration 966 : loss : 0.522084, loss_ce: 0.473429
[01:33:27.886] iteration 967 : loss : 0.559080, loss_ce: 0.507545
[01:33:28.140] iteration 968 : loss : 0.520308, loss_ce: 0.449570
[01:33:29.199] iteration 969 : loss : 0.525044, loss_ce: 0.403688
[01:33:29.455] iteration 970 : loss : 0.536939, loss_ce: 0.506884
[01:33:29.709] iteration 971 : loss : 0.578741, loss_ce: 0.425092
[01:33:29.962] iteration 972 : loss : 0.628263, loss_ce: 0.572809
[01:33:30.322] iteration 973 : loss : 0.603679, loss_ce: 0.500711
[01:33:30.575] iteration 974 : loss : 0.554890, loss_ce: 0.450777
[01:33:30.829] iteration 975 : loss : 0.552851, loss_ce: 0.497533
[01:33:31.082] iteration 976 : loss : 0.561675, loss_ce: 0.503344
[01:33:32.255] iteration 977 : loss : 0.550842, loss_ce: 0.463840
[01:33:32.510] iteration 978 : loss : 0.565141, loss_ce: 0.492131
[01:33:32.764] iteration 979 : loss : 0.535557, loss_ce: 0.431563
[01:33:33.222] iteration 980 : loss : 0.580890, loss_ce: 0.500184
[01:33:33.480] iteration 981 : loss : 0.619938, loss_ce: 0.623050
[01:33:33.734] iteration 982 : loss : 0.641490, loss_ce: 0.593424
[01:33:33.988] iteration 983 : loss : 0.535278, loss_ce: 0.435891
[01:33:34.244] iteration 984 : loss : 0.598863, loss_ce: 0.531972
[01:33:35.265] iteration 985 : loss : 0.678087, loss_ce: 0.697499
[01:33:35.520] iteration 986 : loss : 0.581737, loss_ce: 0.534592
[01:33:35.775] iteration 987 : loss : 0.576182, loss_ce: 0.513886
[01:33:36.032] iteration 988 : loss : 0.579382, loss_ce: 0.508657
[01:33:36.431] iteration 989 : loss : 0.540285, loss_ce: 0.472222
[01:33:36.686] iteration 990 : loss : 0.568494, loss_ce: 0.527960
[01:33:36.943] iteration 991 : loss : 0.541160, loss_ce: 0.493807
[01:33:37.210] iteration 992 : loss : 0.518185, loss_ce: 0.479964
[01:33:38.282] iteration 993 : loss : 0.589870, loss_ce: 0.472979
[01:33:38.536] iteration 994 : loss : 0.561907, loss_ce: 0.515768
[01:33:38.789] iteration 995 : loss : 0.557370, loss_ce: 0.433224
[01:33:39.044] iteration 996 : loss : 0.596007, loss_ce: 0.498771
[01:33:39.455] iteration 997 : loss : 0.523256, loss_ce: 0.453521
[01:33:39.716] iteration 998 : loss : 0.565166, loss_ce: 0.539793
[01:33:39.970] iteration 999 : loss : 0.566541, loss_ce: 0.422372
[01:33:40.225] iteration 1000 : loss : 0.570947, loss_ce: 0.475840
[01:33:41.237] iteration 1001 : loss : 0.535353, loss_ce: 0.443965
[01:33:41.491] iteration 1002 : loss : 0.592727, loss_ce: 0.556507
[01:33:41.746] iteration 1003 : loss : 0.546268, loss_ce: 0.421193
[01:33:42.002] iteration 1004 : loss : 0.524058, loss_ce: 0.400000
[01:33:42.487] iteration 1005 : loss : 0.534709, loss_ce: 0.406440
[01:33:42.740] iteration 1006 : loss : 0.537863, loss_ce: 0.434847
[01:33:42.994] iteration 1007 : loss : 0.543184, loss_ce: 0.458975
[01:33:43.251] iteration 1008 : loss : 0.542170, loss_ce: 0.486711
[01:33:44.311] iteration 1009 : loss : 0.563447, loss_ce: 0.419772
[01:33:44.566] iteration 1010 : loss : 0.507892, loss_ce: 0.355955
[01:33:44.821] iteration 1011 : loss : 0.597926, loss_ce: 0.540561
[01:33:45.075] iteration 1012 : loss : 0.561225, loss_ce: 0.497701
[01:33:45.561] iteration 1013 : loss : 0.567176, loss_ce: 0.518688
[01:33:45.821] iteration 1014 : loss : 0.556308, loss_ce: 0.464889
[01:33:46.075] iteration 1015 : loss : 0.589547, loss_ce: 0.457736
[01:33:46.330] iteration 1016 : loss : 0.487137, loss_ce: 0.398105
[01:33:47.411] iteration 1017 : loss : 0.560358, loss_ce: 0.510653
[01:33:47.667] iteration 1018 : loss : 0.571138, loss_ce: 0.470970
[01:33:47.921] iteration 1019 : loss : 0.603240, loss_ce: 0.513017
[01:33:48.177] iteration 1020 : loss : 0.627446, loss_ce: 0.503321
[01:33:48.648] iteration 1021 : loss : 0.607003, loss_ce: 0.533173
[01:33:48.902] iteration 1022 : loss : 0.565716, loss_ce: 0.424025
[01:33:49.155] iteration 1023 : loss : 0.529460, loss_ce: 0.459207
[01:33:49.409] iteration 1024 : loss : 0.546811, loss_ce: 0.433334
[01:33:50.496] iteration 1025 : loss : 0.479706, loss_ce: 0.394563
[01:33:50.749] iteration 1026 : loss : 0.615767, loss_ce: 0.510586
[01:33:51.001] iteration 1027 : loss : 0.546785, loss_ce: 0.459942
[01:33:51.254] iteration 1028 : loss : 0.584512, loss_ce: 0.502297
[01:33:51.646] iteration 1029 : loss : 0.556276, loss_ce: 0.425571
[01:33:51.900] iteration 1030 : loss : 0.584694, loss_ce: 0.499075
[01:33:52.154] iteration 1031 : loss : 0.557531, loss_ce: 0.519000
[01:33:52.408] iteration 1032 : loss : 0.571048, loss_ce: 0.496627
[01:33:53.437] iteration 1033 : loss : 0.530364, loss_ce: 0.373872
[01:33:53.691] iteration 1034 : loss : 0.509254, loss_ce: 0.408253
[01:33:53.945] iteration 1035 : loss : 0.588030, loss_ce: 0.421882
[01:33:54.199] iteration 1036 : loss : 0.555270, loss_ce: 0.471835
[01:33:54.607] iteration 1037 : loss : 0.575823, loss_ce: 0.564222
[01:33:54.860] iteration 1038 : loss : 0.514346, loss_ce: 0.416995
[01:33:55.114] iteration 1039 : loss : 0.638295, loss_ce: 0.599586
[01:33:55.369] iteration 1040 : loss : 0.477604, loss_ce: 0.364955
[01:33:56.422] iteration 1041 : loss : 0.561560, loss_ce: 0.458443
[01:33:56.677] iteration 1042 : loss : 0.533145, loss_ce: 0.431231
[01:33:56.932] iteration 1043 : loss : 0.617512, loss_ce: 0.538757
[01:33:57.185] iteration 1044 : loss : 0.504275, loss_ce: 0.401648
[01:33:57.576] iteration 1045 : loss : 0.536510, loss_ce: 0.424610
[01:33:57.829] iteration 1046 : loss : 0.542596, loss_ce: 0.402253
[01:33:58.083] iteration 1047 : loss : 0.538671, loss_ce: 0.453482
[01:33:58.338] iteration 1048 : loss : 0.514901, loss_ce: 0.413325
[01:33:59.457] iteration 1049 : loss : 0.525225, loss_ce: 0.415835
[01:33:59.814] iteration 1050 : loss : 0.537829, loss_ce: 0.439165
[01:34:00.224] iteration 1051 : loss : 0.516190, loss_ce: 0.417468
[01:34:00.499] iteration 1052 : loss : 0.541760, loss_ce: 0.448566
[01:34:00.756] iteration 1053 : loss : 0.515359, loss_ce: 0.427833
[01:34:01.013] iteration 1054 : loss : 0.578098, loss_ce: 0.511163
[01:34:01.267] iteration 1055 : loss : 0.559269, loss_ce: 0.470942
[01:34:01.525] iteration 1056 : loss : 0.533493, loss_ce: 0.502538
[01:34:02.463] iteration 1057 : loss : 0.555278, loss_ce: 0.461163
[01:34:02.716] iteration 1058 : loss : 0.474771, loss_ce: 0.385485
[01:34:02.971] iteration 1059 : loss : 0.520425, loss_ce: 0.483681
[01:34:03.224] iteration 1060 : loss : 0.518066, loss_ce: 0.389311
[01:34:03.489] iteration 1061 : loss : 0.604394, loss_ce: 0.518813
[01:34:03.745] iteration 1062 : loss : 0.533508, loss_ce: 0.366488
[01:34:04.001] iteration 1063 : loss : 0.552265, loss_ce: 0.519670
[01:34:04.288] iteration 1064 : loss : 0.551839, loss_ce: 0.512904
[01:34:05.418] iteration 1065 : loss : 0.564336, loss_ce: 0.482179
[01:34:05.673] iteration 1066 : loss : 0.516165, loss_ce: 0.399970
[01:34:05.928] iteration 1067 : loss : 0.509248, loss_ce: 0.392602
[01:34:06.183] iteration 1068 : loss : 0.649615, loss_ce: 0.589969
[01:34:06.576] iteration 1069 : loss : 0.617459, loss_ce: 0.570897
[01:34:06.834] iteration 1070 : loss : 0.506255, loss_ce: 0.468157
[01:34:07.088] iteration 1071 : loss : 0.517885, loss_ce: 0.341300
[01:34:07.342] iteration 1072 : loss : 0.573748, loss_ce: 0.527526
[01:34:08.467] iteration 1073 : loss : 0.535655, loss_ce: 0.448138
[01:34:08.725] iteration 1074 : loss : 0.600120, loss_ce: 0.556545
[01:34:08.981] iteration 1075 : loss : 0.505310, loss_ce: 0.390443
[01:34:09.238] iteration 1076 : loss : 0.486367, loss_ce: 0.389628
[01:34:09.519] iteration 1077 : loss : 0.511851, loss_ce: 0.409877
[01:34:09.779] iteration 1078 : loss : 0.580453, loss_ce: 0.438160
[01:34:10.034] iteration 1079 : loss : 0.498099, loss_ce: 0.441772
[01:34:10.294] iteration 1080 : loss : 0.573690, loss_ce: 0.469846
[01:34:11.467] iteration 1081 : loss : 0.628875, loss_ce: 0.610963
[01:34:11.731] iteration 1082 : loss : 0.555565, loss_ce: 0.465333
[01:34:11.987] iteration 1083 : loss : 0.510767, loss_ce: 0.436808
[01:34:12.262] iteration 1084 : loss : 0.524988, loss_ce: 0.407352
[01:34:12.529] iteration 1085 : loss : 0.544686, loss_ce: 0.452839
[01:34:12.790] iteration 1086 : loss : 0.568162, loss_ce: 0.422612
[01:34:13.056] iteration 1087 : loss : 0.475717, loss_ce: 0.332915
[01:34:13.313] iteration 1088 : loss : 0.628519, loss_ce: 0.660553
[01:34:14.478] iteration 1089 : loss : 0.612579, loss_ce: 0.530559
[01:34:14.731] iteration 1090 : loss : 0.597191, loss_ce: 0.475413
[01:34:14.984] iteration 1091 : loss : 0.544233, loss_ce: 0.449928
[01:34:15.244] iteration 1092 : loss : 0.680903, loss_ce: 0.694567
[01:34:15.573] iteration 1093 : loss : 0.604712, loss_ce: 0.599785
[01:34:15.828] iteration 1094 : loss : 0.480622, loss_ce: 0.341987
[01:34:16.083] iteration 1095 : loss : 0.563052, loss_ce: 0.452545
[01:34:16.349] iteration 1096 : loss : 0.553768, loss_ce: 0.444307
[01:34:17.336] iteration 1097 : loss : 0.558032, loss_ce: 0.429778
[01:34:17.590] iteration 1098 : loss : 0.609523, loss_ce: 0.513215
[01:34:17.847] iteration 1099 : loss : 0.571466, loss_ce: 0.513648
[01:34:18.069] iteration 1100 : loss : 0.638774, loss_ce: 0.432783
[01:34:23.178] iteration 1101 : loss : 0.520418, loss_ce: 0.483523
[01:34:23.435] iteration 1102 : loss : 0.533938, loss_ce: 0.452130
[01:34:23.687] iteration 1103 : loss : 0.546013, loss_ce: 0.497573
[01:34:23.942] iteration 1104 : loss : 0.501035, loss_ce: 0.426903
[01:34:24.194] iteration 1105 : loss : 0.578539, loss_ce: 0.505277
[01:34:24.451] iteration 1106 : loss : 0.531957, loss_ce: 0.393180
[01:34:24.704] iteration 1107 : loss : 0.597687, loss_ce: 0.535497
[01:34:24.960] iteration 1108 : loss : 0.548713, loss_ce: 0.476079
[01:34:26.135] iteration 1109 : loss : 0.543992, loss_ce: 0.463742
[01:34:26.388] iteration 1110 : loss : 0.514392, loss_ce: 0.384608
[01:34:26.644] iteration 1111 : loss : 0.546006, loss_ce: 0.373789
[01:34:26.900] iteration 1112 : loss : 0.543411, loss_ce: 0.454352
[01:34:27.359] iteration 1113 : loss : 0.567932, loss_ce: 0.504239
[01:34:27.616] iteration 1114 : loss : 0.513082, loss_ce: 0.416978
[01:34:27.884] iteration 1115 : loss : 0.540630, loss_ce: 0.485880
[01:34:28.139] iteration 1116 : loss : 0.549150, loss_ce: 0.483850
[01:34:29.099] iteration 1117 : loss : 0.571727, loss_ce: 0.474769
[01:34:29.355] iteration 1118 : loss : 0.552520, loss_ce: 0.471058
[01:34:29.607] iteration 1119 : loss : 0.564518, loss_ce: 0.456141
[01:34:29.861] iteration 1120 : loss : 0.529339, loss_ce: 0.443177
[01:34:30.114] iteration 1121 : loss : 0.578313, loss_ce: 0.545071
[01:34:30.369] iteration 1122 : loss : 0.594932, loss_ce: 0.513470
[01:34:30.626] iteration 1123 : loss : 0.551414, loss_ce: 0.400271
[01:34:30.882] iteration 1124 : loss : 0.522521, loss_ce: 0.484549
[01:34:32.081] iteration 1125 : loss : 0.520030, loss_ce: 0.451851
[01:34:32.336] iteration 1126 : loss : 0.621328, loss_ce: 0.596918
[01:34:32.593] iteration 1127 : loss : 0.570771, loss_ce: 0.536821
[01:34:32.847] iteration 1128 : loss : 0.529295, loss_ce: 0.466580
[01:34:33.099] iteration 1129 : loss : 0.574211, loss_ce: 0.531113
[01:34:33.354] iteration 1130 : loss : 0.567375, loss_ce: 0.532508
[01:34:33.607] iteration 1131 : loss : 0.592818, loss_ce: 0.550973
[01:34:33.882] iteration 1132 : loss : 0.545343, loss_ce: 0.440047
[01:34:35.037] iteration 1133 : loss : 0.524995, loss_ce: 0.458990
[01:34:35.293] iteration 1134 : loss : 0.549357, loss_ce: 0.426973
[01:34:35.547] iteration 1135 : loss : 0.496464, loss_ce: 0.396042
[01:34:35.799] iteration 1136 : loss : 0.602225, loss_ce: 0.448852
[01:34:36.056] iteration 1137 : loss : 0.550975, loss_ce: 0.407564
[01:34:36.310] iteration 1138 : loss : 0.426832, loss_ce: 0.314349
[01:34:36.563] iteration 1139 : loss : 0.569023, loss_ce: 0.449271
[01:34:36.818] iteration 1140 : loss : 0.549520, loss_ce: 0.422007
[01:34:38.027] iteration 1141 : loss : 0.568588, loss_ce: 0.487878
[01:34:38.282] iteration 1142 : loss : 0.566879, loss_ce: 0.462210
[01:34:38.538] iteration 1143 : loss : 0.556539, loss_ce: 0.432474
[01:34:38.795] iteration 1144 : loss : 0.537289, loss_ce: 0.414094
[01:34:39.050] iteration 1145 : loss : 0.509416, loss_ce: 0.407499
[01:34:39.307] iteration 1146 : loss : 0.519951, loss_ce: 0.418581
[01:34:39.562] iteration 1147 : loss : 0.516162, loss_ce: 0.445948
[01:34:39.819] iteration 1148 : loss : 0.527395, loss_ce: 0.373281
[01:34:41.097] iteration 1149 : loss : 0.538381, loss_ce: 0.464611
[01:34:41.353] iteration 1150 : loss : 0.529362, loss_ce: 0.340490
[01:34:41.627] iteration 1151 : loss : 0.586335, loss_ce: 0.546842
[01:34:41.898] iteration 1152 : loss : 0.563949, loss_ce: 0.443895
[01:34:42.154] iteration 1153 : loss : 0.519204, loss_ce: 0.414490
[01:34:42.411] iteration 1154 : loss : 0.557195, loss_ce: 0.388926
[01:34:42.680] iteration 1155 : loss : 0.555132, loss_ce: 0.412886
[01:34:42.938] iteration 1156 : loss : 0.533615, loss_ce: 0.410926
[01:34:44.113] iteration 1157 : loss : 0.487181, loss_ce: 0.329291
[01:34:44.369] iteration 1158 : loss : 0.534077, loss_ce: 0.426419
[01:34:44.623] iteration 1159 : loss : 0.545359, loss_ce: 0.410245
[01:34:44.882] iteration 1160 : loss : 0.501034, loss_ce: 0.383139
[01:34:45.140] iteration 1161 : loss : 0.477906, loss_ce: 0.351344
[01:34:45.396] iteration 1162 : loss : 0.487020, loss_ce: 0.427337
[01:34:45.649] iteration 1163 : loss : 0.563060, loss_ce: 0.483310
[01:34:45.911] iteration 1164 : loss : 0.487364, loss_ce: 0.435669
[01:34:47.171] iteration 1165 : loss : 0.566929, loss_ce: 0.428295
[01:34:47.431] iteration 1166 : loss : 0.498163, loss_ce: 0.434364
[01:34:47.685] iteration 1167 : loss : 0.487595, loss_ce: 0.365987
[01:34:47.941] iteration 1168 : loss : 0.432714, loss_ce: 0.317868
[01:34:48.195] iteration 1169 : loss : 0.519336, loss_ce: 0.394310
[01:34:48.452] iteration 1170 : loss : 0.510165, loss_ce: 0.423812
[01:34:48.711] iteration 1171 : loss : 0.590438, loss_ce: 0.457361
[01:34:48.971] iteration 1172 : loss : 0.568947, loss_ce: 0.422812
[01:34:50.205] iteration 1173 : loss : 0.485220, loss_ce: 0.424500
[01:34:50.460] iteration 1174 : loss : 0.565782, loss_ce: 0.404390
[01:34:50.714] iteration 1175 : loss : 0.563012, loss_ce: 0.473469
[01:34:50.967] iteration 1176 : loss : 0.509537, loss_ce: 0.397467
[01:34:51.222] iteration 1177 : loss : 0.533939, loss_ce: 0.514476
[01:34:51.475] iteration 1178 : loss : 0.472034, loss_ce: 0.371278
[01:34:51.730] iteration 1179 : loss : 0.560493, loss_ce: 0.471506
[01:34:51.991] iteration 1180 : loss : 0.560192, loss_ce: 0.426347
[01:34:53.198] iteration 1181 : loss : 0.544966, loss_ce: 0.444967
[01:34:53.452] iteration 1182 : loss : 0.444079, loss_ce: 0.314029
[01:34:53.705] iteration 1183 : loss : 0.476362, loss_ce: 0.403167
[01:34:53.960] iteration 1184 : loss : 0.507944, loss_ce: 0.397383
[01:34:54.215] iteration 1185 : loss : 0.547974, loss_ce: 0.445176
[01:34:54.469] iteration 1186 : loss : 0.561582, loss_ce: 0.430425
[01:34:54.736] iteration 1187 : loss : 0.510661, loss_ce: 0.406578
[01:34:54.989] iteration 1188 : loss : 0.560134, loss_ce: 0.558883
[01:34:56.182] iteration 1189 : loss : 0.491605, loss_ce: 0.414163
[01:34:56.438] iteration 1190 : loss : 0.508426, loss_ce: 0.374397
[01:34:56.692] iteration 1191 : loss : 0.500816, loss_ce: 0.389004
[01:34:56.946] iteration 1192 : loss : 0.518052, loss_ce: 0.416297
[01:34:57.200] iteration 1193 : loss : 0.550293, loss_ce: 0.456398
[01:34:57.457] iteration 1194 : loss : 0.477799, loss_ce: 0.408926
[01:34:57.722] iteration 1195 : loss : 0.550902, loss_ce: 0.494528
[01:34:57.978] iteration 1196 : loss : 0.520342, loss_ce: 0.396383
[01:34:59.203] iteration 1197 : loss : 0.610385, loss_ce: 0.462048
[01:34:59.456] iteration 1198 : loss : 0.492904, loss_ce: 0.388227
[01:34:59.710] iteration 1199 : loss : 0.539767, loss_ce: 0.480241
[01:34:59.964] iteration 1200 : loss : 0.487546, loss_ce: 0.381700
[01:35:00.220] iteration 1201 : loss : 0.573047, loss_ce: 0.435256
[01:35:00.474] iteration 1202 : loss : 0.528325, loss_ce: 0.400734
[01:35:00.729] iteration 1203 : loss : 0.582159, loss_ce: 0.553814
[01:35:00.983] iteration 1204 : loss : 0.513674, loss_ce: 0.466853
[01:35:02.084] iteration 1205 : loss : 0.601419, loss_ce: 0.498110
[01:35:02.337] iteration 1206 : loss : 0.459260, loss_ce: 0.326308
[01:35:02.590] iteration 1207 : loss : 0.500905, loss_ce: 0.423250
[01:35:02.842] iteration 1208 : loss : 0.579981, loss_ce: 0.542236
[01:35:03.095] iteration 1209 : loss : 0.543134, loss_ce: 0.387341
[01:35:03.347] iteration 1210 : loss : 0.510948, loss_ce: 0.383492
[01:35:03.601] iteration 1211 : loss : 0.540865, loss_ce: 0.433171
[01:35:03.855] iteration 1212 : loss : 0.546667, loss_ce: 0.436565
[01:35:05.021] iteration 1213 : loss : 0.551155, loss_ce: 0.465605
[01:35:05.276] iteration 1214 : loss : 0.496678, loss_ce: 0.385401
[01:35:05.528] iteration 1215 : loss : 0.537485, loss_ce: 0.406155
[01:35:05.787] iteration 1216 : loss : 0.555096, loss_ce: 0.460095
[01:35:06.039] iteration 1217 : loss : 0.584210, loss_ce: 0.432284
[01:35:06.291] iteration 1218 : loss : 0.537482, loss_ce: 0.450234
[01:35:06.544] iteration 1219 : loss : 0.502985, loss_ce: 0.411301
[01:35:06.797] iteration 1220 : loss : 0.506647, loss_ce: 0.397114
[01:35:07.963] iteration 1221 : loss : 0.551661, loss_ce: 0.475183
[01:35:08.219] iteration 1222 : loss : 0.549243, loss_ce: 0.514070
[01:35:08.475] iteration 1223 : loss : 0.561960, loss_ce: 0.457704
[01:35:08.766] iteration 1224 : loss : 0.518532, loss_ce: 0.408289
[01:35:09.083] iteration 1225 : loss : 0.479216, loss_ce: 0.375816
[01:35:09.376] iteration 1226 : loss : 0.497138, loss_ce: 0.367278
[01:35:09.701] iteration 1227 : loss : 0.503299, loss_ce: 0.381865
[01:35:10.029] iteration 1228 : loss : 0.571573, loss_ce: 0.432034
[01:35:11.143] iteration 1229 : loss : 0.511067, loss_ce: 0.414214
[01:35:11.398] iteration 1230 : loss : 0.552800, loss_ce: 0.558484
[01:35:11.653] iteration 1231 : loss : 0.570621, loss_ce: 0.508901
[01:35:11.906] iteration 1232 : loss : 0.494709, loss_ce: 0.415028
[01:35:12.161] iteration 1233 : loss : 0.599189, loss_ce: 0.481119
[01:35:12.415] iteration 1234 : loss : 0.462294, loss_ce: 0.347608
[01:35:12.671] iteration 1235 : loss : 0.525363, loss_ce: 0.386678
[01:35:12.924] iteration 1236 : loss : 0.489809, loss_ce: 0.389934
[01:35:14.167] iteration 1237 : loss : 0.451416, loss_ce: 0.323558
[01:35:14.422] iteration 1238 : loss : 0.489335, loss_ce: 0.396300
[01:35:14.676] iteration 1239 : loss : 0.573083, loss_ce: 0.405502
[01:35:14.933] iteration 1240 : loss : 0.530649, loss_ce: 0.462181
[01:35:15.192] iteration 1241 : loss : 0.508063, loss_ce: 0.425812
[01:35:15.448] iteration 1242 : loss : 0.508929, loss_ce: 0.375115
[01:35:15.706] iteration 1243 : loss : 0.512145, loss_ce: 0.398069
[01:35:15.966] iteration 1244 : loss : 0.496023, loss_ce: 0.391634
[01:35:17.286] iteration 1245 : loss : 0.484491, loss_ce: 0.376747
[01:35:17.540] iteration 1246 : loss : 0.576061, loss_ce: 0.531655
[01:35:17.939] iteration 1247 : loss : 0.572396, loss_ce: 0.401237
[01:35:18.194] iteration 1248 : loss : 0.530703, loss_ce: 0.471013
[01:35:18.447] iteration 1249 : loss : 0.566503, loss_ce: 0.474172
[01:35:18.705] iteration 1250 : loss : 0.503733, loss_ce: 0.379449
[01:35:18.963] iteration 1251 : loss : 0.503385, loss_ce: 0.349571
[01:35:19.218] iteration 1252 : loss : 0.536198, loss_ce: 0.445871
[01:35:20.326] iteration 1253 : loss : 0.553170, loss_ce: 0.415879
[01:35:20.581] iteration 1254 : loss : 0.521142, loss_ce: 0.393824
[01:35:20.836] iteration 1255 : loss : 0.521376, loss_ce: 0.470491
[01:35:21.091] iteration 1256 : loss : 0.536018, loss_ce: 0.504208
[01:35:21.346] iteration 1257 : loss : 0.484655, loss_ce: 0.324688
[01:35:21.603] iteration 1258 : loss : 0.512067, loss_ce: 0.402203
[01:35:21.856] iteration 1259 : loss : 0.603379, loss_ce: 0.484293
[01:35:22.110] iteration 1260 : loss : 0.483214, loss_ce: 0.425590
[01:35:23.311] iteration 1261 : loss : 0.535820, loss_ce: 0.371805
[01:35:23.567] iteration 1262 : loss : 0.575608, loss_ce: 0.497966
[01:35:23.826] iteration 1263 : loss : 0.515765, loss_ce: 0.361844
[01:35:24.080] iteration 1264 : loss : 0.516089, loss_ce: 0.413428
[01:35:24.334] iteration 1265 : loss : 0.565041, loss_ce: 0.425303
[01:35:24.587] iteration 1266 : loss : 0.496797, loss_ce: 0.370349
[01:35:24.843] iteration 1267 : loss : 0.528807, loss_ce: 0.408845
[01:35:25.097] iteration 1268 : loss : 0.560404, loss_ce: 0.435515
[01:35:26.249] iteration 1269 : loss : 0.475226, loss_ce: 0.339667
[01:35:26.506] iteration 1270 : loss : 0.553370, loss_ce: 0.517421
[01:35:26.760] iteration 1271 : loss : 0.605813, loss_ce: 0.631240
[01:35:27.014] iteration 1272 : loss : 0.540598, loss_ce: 0.431260
[01:35:27.267] iteration 1273 : loss : 0.513983, loss_ce: 0.406580
[01:35:27.520] iteration 1274 : loss : 0.598151, loss_ce: 0.531190
[01:35:27.778] iteration 1275 : loss : 0.484057, loss_ce: 0.322056
[01:35:28.032] iteration 1276 : loss : 0.464406, loss_ce: 0.409114
[01:35:29.140] iteration 1277 : loss : 0.562557, loss_ce: 0.468300
[01:35:29.394] iteration 1278 : loss : 0.508204, loss_ce: 0.420049
[01:35:29.647] iteration 1279 : loss : 0.427542, loss_ce: 0.357532
[01:35:29.901] iteration 1280 : loss : 0.567072, loss_ce: 0.436618
[01:35:30.158] iteration 1281 : loss : 0.550631, loss_ce: 0.389511
[01:35:30.413] iteration 1282 : loss : 0.566086, loss_ce: 0.391299
[01:35:30.671] iteration 1283 : loss : 0.530439, loss_ce: 0.382944
[01:35:30.926] iteration 1284 : loss : 0.530819, loss_ce: 0.468889
[01:35:32.068] iteration 1285 : loss : 0.500651, loss_ce: 0.449336
[01:35:32.321] iteration 1286 : loss : 0.636906, loss_ce: 0.629350
[01:35:32.575] iteration 1287 : loss : 0.491274, loss_ce: 0.389358
[01:35:32.827] iteration 1288 : loss : 0.552512, loss_ce: 0.411344
[01:35:33.082] iteration 1289 : loss : 0.526524, loss_ce: 0.414145
[01:35:33.337] iteration 1290 : loss : 0.541278, loss_ce: 0.371655
[01:35:33.593] iteration 1291 : loss : 0.507467, loss_ce: 0.467798
[01:35:33.851] iteration 1292 : loss : 0.490325, loss_ce: 0.362280
[01:35:34.885] iteration 1293 : loss : 0.500278, loss_ce: 0.347030
[01:35:35.138] iteration 1294 : loss : 0.608813, loss_ce: 0.521010
[01:35:35.393] iteration 1295 : loss : 0.605475, loss_ce: 0.486374
[01:35:35.647] iteration 1296 : loss : 0.498837, loss_ce: 0.357464
[01:35:35.900] iteration 1297 : loss : 0.499466, loss_ce: 0.393096
[01:35:36.153] iteration 1298 : loss : 0.457040, loss_ce: 0.339112
[01:35:36.411] iteration 1299 : loss : 0.526806, loss_ce: 0.382338
[01:35:36.665] iteration 1300 : loss : 0.527352, loss_ce: 0.456577
[01:35:37.789] iteration 1301 : loss : 0.512933, loss_ce: 0.464846
[01:35:38.044] iteration 1302 : loss : 0.562596, loss_ce: 0.395752
[01:35:38.299] iteration 1303 : loss : 0.543433, loss_ce: 0.364550
[01:35:38.553] iteration 1304 : loss : 0.484142, loss_ce: 0.394666
[01:35:38.807] iteration 1305 : loss : 0.506823, loss_ce: 0.351920
[01:35:39.062] iteration 1306 : loss : 0.570073, loss_ce: 0.476572
[01:35:39.318] iteration 1307 : loss : 0.576494, loss_ce: 0.462584
[01:35:39.572] iteration 1308 : loss : 0.573883, loss_ce: 0.492137
[01:35:40.704] iteration 1309 : loss : 0.577075, loss_ce: 0.457044
[01:35:40.960] iteration 1310 : loss : 0.548100, loss_ce: 0.442428
[01:35:41.213] iteration 1311 : loss : 0.540424, loss_ce: 0.469617
[01:35:41.467] iteration 1312 : loss : 0.528900, loss_ce: 0.366573
[01:35:41.722] iteration 1313 : loss : 0.564507, loss_ce: 0.392951
[01:35:41.975] iteration 1314 : loss : 0.553644, loss_ce: 0.384638
[01:35:42.230] iteration 1315 : loss : 0.569703, loss_ce: 0.314655
[01:35:42.482] iteration 1316 : loss : 0.610475, loss_ce: 0.528460
[01:35:43.261] iteration 1317 : loss : 0.473795, loss_ce: 0.310581
[01:35:43.556] iteration 1318 : loss : 0.495200, loss_ce: 0.352562
[01:35:43.894] iteration 1319 : loss : 0.572637, loss_ce: 0.444348
[01:35:44.179] iteration 1320 : loss : 0.588835, loss_ce: 0.313850
[01:35:49.007] iteration 1321 : loss : 0.539859, loss_ce: 0.424316
[01:35:49.267] iteration 1322 : loss : 0.569583, loss_ce: 0.435471
[01:35:49.519] iteration 1323 : loss : 0.551484, loss_ce: 0.402620
[01:35:49.775] iteration 1324 : loss : 0.428366, loss_ce: 0.324269
[01:35:50.033] iteration 1325 : loss : 0.618914, loss_ce: 0.555747
[01:35:50.290] iteration 1326 : loss : 0.588085, loss_ce: 0.551399
[01:35:50.546] iteration 1327 : loss : 0.464996, loss_ce: 0.379327
[01:35:50.804] iteration 1328 : loss : 0.581529, loss_ce: 0.608648
[01:35:52.001] iteration 1329 : loss : 0.541262, loss_ce: 0.454807
[01:35:52.260] iteration 1330 : loss : 0.509143, loss_ce: 0.411337
[01:35:52.517] iteration 1331 : loss : 0.484060, loss_ce: 0.392268
[01:35:52.770] iteration 1332 : loss : 0.504874, loss_ce: 0.430156
[01:35:53.028] iteration 1333 : loss : 0.556114, loss_ce: 0.459899
[01:35:53.280] iteration 1334 : loss : 0.502418, loss_ce: 0.414200
[01:35:53.532] iteration 1335 : loss : 0.505217, loss_ce: 0.432325
[01:35:53.787] iteration 1336 : loss : 0.505113, loss_ce: 0.430500
[01:35:55.143] iteration 1337 : loss : 0.517203, loss_ce: 0.475375
[01:35:55.401] iteration 1338 : loss : 0.592618, loss_ce: 0.464186
[01:35:55.663] iteration 1339 : loss : 0.524556, loss_ce: 0.385059
[01:35:55.918] iteration 1340 : loss : 0.460491, loss_ce: 0.383755
[01:35:56.171] iteration 1341 : loss : 0.529766, loss_ce: 0.438489
[01:35:56.425] iteration 1342 : loss : 0.541938, loss_ce: 0.433309
[01:35:56.680] iteration 1343 : loss : 0.411134, loss_ce: 0.295699
[01:35:56.934] iteration 1344 : loss : 0.427622, loss_ce: 0.364832
[01:35:58.239] iteration 1345 : loss : 0.446707, loss_ce: 0.329936
[01:35:58.492] iteration 1346 : loss : 0.516402, loss_ce: 0.398423
[01:35:58.747] iteration 1347 : loss : 0.505591, loss_ce: 0.358928
[01:35:59.005] iteration 1348 : loss : 0.545831, loss_ce: 0.514289
[01:35:59.260] iteration 1349 : loss : 0.458650, loss_ce: 0.365558
[01:35:59.517] iteration 1350 : loss : 0.494530, loss_ce: 0.344857
[01:35:59.774] iteration 1351 : loss : 0.552281, loss_ce: 0.478887
[01:36:00.032] iteration 1352 : loss : 0.527722, loss_ce: 0.434402
[01:36:01.284] iteration 1353 : loss : 0.505340, loss_ce: 0.431106
[01:36:01.541] iteration 1354 : loss : 0.536473, loss_ce: 0.456063
[01:36:01.794] iteration 1355 : loss : 0.571453, loss_ce: 0.460085
[01:36:02.047] iteration 1356 : loss : 0.383478, loss_ce: 0.286692
[01:36:02.304] iteration 1357 : loss : 0.451333, loss_ce: 0.356872
[01:36:02.560] iteration 1358 : loss : 0.484758, loss_ce: 0.363268
[01:36:02.812] iteration 1359 : loss : 0.602539, loss_ce: 0.568129
[01:36:03.065] iteration 1360 : loss : 0.577840, loss_ce: 0.414732
[01:36:04.241] iteration 1361 : loss : 0.448833, loss_ce: 0.313790
[01:36:04.497] iteration 1362 : loss : 0.503141, loss_ce: 0.413528
[01:36:04.749] iteration 1363 : loss : 0.473421, loss_ce: 0.375886
[01:36:05.003] iteration 1364 : loss : 0.551528, loss_ce: 0.459250
[01:36:05.261] iteration 1365 : loss : 0.517664, loss_ce: 0.395696
[01:36:05.514] iteration 1366 : loss : 0.485658, loss_ce: 0.408593
[01:36:05.768] iteration 1367 : loss : 0.465469, loss_ce: 0.317334
[01:36:06.022] iteration 1368 : loss : 0.555508, loss_ce: 0.467368
[01:36:07.263] iteration 1369 : loss : 0.573046, loss_ce: 0.486782
[01:36:07.521] iteration 1370 : loss : 0.623711, loss_ce: 0.538632
[01:36:07.775] iteration 1371 : loss : 0.542528, loss_ce: 0.338966
[01:36:08.030] iteration 1372 : loss : 0.509281, loss_ce: 0.424080
[01:36:08.284] iteration 1373 : loss : 0.497257, loss_ce: 0.378310
[01:36:08.537] iteration 1374 : loss : 0.605689, loss_ce: 0.550853
[01:36:08.790] iteration 1375 : loss : 0.455972, loss_ce: 0.397911
[01:36:09.042] iteration 1376 : loss : 0.501126, loss_ce: 0.392417
[01:36:10.122] iteration 1377 : loss : 0.465047, loss_ce: 0.363537
[01:36:10.383] iteration 1378 : loss : 0.528783, loss_ce: 0.449909
[01:36:10.833] iteration 1379 : loss : 0.528135, loss_ce: 0.501819
[01:36:11.087] iteration 1380 : loss : 0.525167, loss_ce: 0.411991
[01:36:11.343] iteration 1381 : loss : 0.496932, loss_ce: 0.399724
[01:36:11.595] iteration 1382 : loss : 0.522652, loss_ce: 0.397196
[01:36:11.847] iteration 1383 : loss : 0.502186, loss_ce: 0.343552
[01:36:12.100] iteration 1384 : loss : 0.517097, loss_ce: 0.367317
[01:36:12.985] iteration 1385 : loss : 0.548369, loss_ce: 0.405790
[01:36:13.289] iteration 1386 : loss : 0.571587, loss_ce: 0.320921
[01:36:13.545] iteration 1387 : loss : 0.504717, loss_ce: 0.399952
[01:36:13.800] iteration 1388 : loss : 0.504054, loss_ce: 0.469842
[01:36:14.053] iteration 1389 : loss : 0.425214, loss_ce: 0.282460
[01:36:14.308] iteration 1390 : loss : 0.513494, loss_ce: 0.362275
[01:36:14.562] iteration 1391 : loss : 0.530407, loss_ce: 0.413316
[01:36:14.818] iteration 1392 : loss : 0.594616, loss_ce: 0.519139
[01:36:15.870] iteration 1393 : loss : 0.554395, loss_ce: 0.415084
[01:36:16.185] iteration 1394 : loss : 0.514010, loss_ce: 0.393675
[01:36:16.439] iteration 1395 : loss : 0.503506, loss_ce: 0.321094
[01:36:16.693] iteration 1396 : loss : 0.466534, loss_ce: 0.418978
[01:36:16.948] iteration 1397 : loss : 0.553150, loss_ce: 0.421235
[01:36:17.201] iteration 1398 : loss : 0.431775, loss_ce: 0.388506
[01:36:17.454] iteration 1399 : loss : 0.513774, loss_ce: 0.346872
[01:36:17.705] iteration 1400 : loss : 0.532157, loss_ce: 0.351747
[01:36:18.819] iteration 1401 : loss : 0.417221, loss_ce: 0.331876
[01:36:19.122] iteration 1402 : loss : 0.529124, loss_ce: 0.399795
[01:36:19.472] iteration 1403 : loss : 0.495994, loss_ce: 0.420718
[01:36:19.734] iteration 1404 : loss : 0.501240, loss_ce: 0.463295
[01:36:19.986] iteration 1405 : loss : 0.531984, loss_ce: 0.434489
[01:36:20.243] iteration 1406 : loss : 0.543368, loss_ce: 0.410591
[01:36:20.495] iteration 1407 : loss : 0.443199, loss_ce: 0.270722
[01:36:20.729] iteration 1408 : loss : 0.560092, loss_ce: 0.469104
[01:36:21.838] iteration 1409 : loss : 0.487288, loss_ce: 0.403471
[01:36:22.242] iteration 1410 : loss : 0.470905, loss_ce: 0.324083
[01:36:22.470] iteration 1411 : loss : 0.543255, loss_ce: 0.476486
[01:36:22.700] iteration 1412 : loss : 0.523143, loss_ce: 0.359601
[01:36:22.931] iteration 1413 : loss : 0.528141, loss_ce: 0.467656
[01:36:23.166] iteration 1414 : loss : 0.433203, loss_ce: 0.293586
[01:36:23.395] iteration 1415 : loss : 0.474563, loss_ce: 0.390355
[01:36:23.631] iteration 1416 : loss : 0.564198, loss_ce: 0.449084
[01:36:24.860] iteration 1417 : loss : 0.466413, loss_ce: 0.338339
[01:36:25.263] iteration 1418 : loss : 0.556347, loss_ce: 0.510237
[01:36:25.632] iteration 1419 : loss : 0.552128, loss_ce: 0.401556
[01:36:25.885] iteration 1420 : loss : 0.546145, loss_ce: 0.413624
[01:36:26.137] iteration 1421 : loss : 0.504027, loss_ce: 0.416051
[01:36:26.392] iteration 1422 : loss : 0.539592, loss_ce: 0.427502
[01:36:26.643] iteration 1423 : loss : 0.443433, loss_ce: 0.333904
[01:36:26.896] iteration 1424 : loss : 0.492447, loss_ce: 0.433906
[01:36:27.824] iteration 1425 : loss : 0.427086, loss_ce: 0.321979
[01:36:28.252] iteration 1426 : loss : 0.450078, loss_ce: 0.367674
[01:36:28.597] iteration 1427 : loss : 0.499129, loss_ce: 0.363629
[01:36:28.851] iteration 1428 : loss : 0.503377, loss_ce: 0.347403
[01:36:29.104] iteration 1429 : loss : 0.426861, loss_ce: 0.322099
[01:36:29.360] iteration 1430 : loss : 0.609175, loss_ce: 0.467043
[01:36:29.612] iteration 1431 : loss : 0.486850, loss_ce: 0.393022
[01:36:29.866] iteration 1432 : loss : 0.585514, loss_ce: 0.541635
[01:36:30.863] iteration 1433 : loss : 0.465435, loss_ce: 0.304246
[01:36:31.308] iteration 1434 : loss : 0.495238, loss_ce: 0.396433
[01:36:31.670] iteration 1435 : loss : 0.512677, loss_ce: 0.412347
[01:36:31.927] iteration 1436 : loss : 0.527607, loss_ce: 0.412559
[01:36:32.182] iteration 1437 : loss : 0.439041, loss_ce: 0.261240
[01:36:32.436] iteration 1438 : loss : 0.491993, loss_ce: 0.359350
[01:36:32.690] iteration 1439 : loss : 0.418556, loss_ce: 0.319862
[01:36:32.944] iteration 1440 : loss : 0.484441, loss_ce: 0.414297
[01:36:33.899] iteration 1441 : loss : 0.535147, loss_ce: 0.402998
[01:36:34.298] iteration 1442 : loss : 0.535055, loss_ce: 0.423888
[01:36:34.660] iteration 1443 : loss : 0.525660, loss_ce: 0.446978
[01:36:34.916] iteration 1444 : loss : 0.461347, loss_ce: 0.278369
[01:36:35.172] iteration 1445 : loss : 0.539356, loss_ce: 0.381254
[01:36:35.429] iteration 1446 : loss : 0.494950, loss_ce: 0.405744
[01:36:35.684] iteration 1447 : loss : 0.445846, loss_ce: 0.335294
[01:36:35.940] iteration 1448 : loss : 0.519736, loss_ce: 0.381362
[01:36:36.945] iteration 1449 : loss : 0.448723, loss_ce: 0.374867
[01:36:37.369] iteration 1450 : loss : 0.462955, loss_ce: 0.295834
[01:36:37.686] iteration 1451 : loss : 0.649092, loss_ce: 0.571984
[01:36:37.943] iteration 1452 : loss : 0.530142, loss_ce: 0.407867
[01:36:38.199] iteration 1453 : loss : 0.529722, loss_ce: 0.472214
[01:36:38.455] iteration 1454 : loss : 0.487190, loss_ce: 0.345637
[01:36:38.710] iteration 1455 : loss : 0.535082, loss_ce: 0.364588
[01:36:38.963] iteration 1456 : loss : 0.474341, loss_ce: 0.358799
[01:36:39.919] iteration 1457 : loss : 0.452130, loss_ce: 0.290988
[01:36:40.295] iteration 1458 : loss : 0.476505, loss_ce: 0.427303
[01:36:40.631] iteration 1459 : loss : 0.521282, loss_ce: 0.417645
[01:36:40.885] iteration 1460 : loss : 0.472117, loss_ce: 0.354758
[01:36:41.144] iteration 1461 : loss : 0.466081, loss_ce: 0.317956
[01:36:41.398] iteration 1462 : loss : 0.512011, loss_ce: 0.356655
[01:36:41.652] iteration 1463 : loss : 0.521545, loss_ce: 0.412445
[01:36:41.908] iteration 1464 : loss : 0.562744, loss_ce: 0.503906
[01:36:42.842] iteration 1465 : loss : 0.518508, loss_ce: 0.458306
[01:36:43.277] iteration 1466 : loss : 0.576369, loss_ce: 0.472677
[01:36:43.536] iteration 1467 : loss : 0.450192, loss_ce: 0.361682
[01:36:43.790] iteration 1468 : loss : 0.443661, loss_ce: 0.376500
[01:36:44.042] iteration 1469 : loss : 0.469401, loss_ce: 0.335924
[01:36:44.295] iteration 1470 : loss : 0.507919, loss_ce: 0.463589
[01:36:44.548] iteration 1471 : loss : 0.534756, loss_ce: 0.426995
[01:36:44.801] iteration 1472 : loss : 0.484902, loss_ce: 0.353040
[01:36:45.777] iteration 1473 : loss : 0.519893, loss_ce: 0.398747
[01:36:46.147] iteration 1474 : loss : 0.514020, loss_ce: 0.375737
[01:36:46.464] iteration 1475 : loss : 0.493865, loss_ce: 0.375534
[01:36:46.757] iteration 1476 : loss : 0.456641, loss_ce: 0.394828
[01:36:47.011] iteration 1477 : loss : 0.430571, loss_ce: 0.314972
[01:36:47.264] iteration 1478 : loss : 0.558246, loss_ce: 0.469395
[01:36:47.520] iteration 1479 : loss : 0.382498, loss_ce: 0.262258
[01:36:47.773] iteration 1480 : loss : 0.525275, loss_ce: 0.394675
[01:36:48.659] iteration 1481 : loss : 0.463350, loss_ce: 0.370992
[01:36:49.068] iteration 1482 : loss : 0.503117, loss_ce: 0.392509
[01:36:49.358] iteration 1483 : loss : 0.576388, loss_ce: 0.546677
[01:36:49.612] iteration 1484 : loss : 0.458667, loss_ce: 0.417765
[01:36:49.864] iteration 1485 : loss : 0.511782, loss_ce: 0.343395
[01:36:50.118] iteration 1486 : loss : 0.509586, loss_ce: 0.342808
[01:36:50.375] iteration 1487 : loss : 0.393075, loss_ce: 0.301587
[01:36:50.630] iteration 1488 : loss : 0.552984, loss_ce: 0.404703
[01:36:51.622] iteration 1489 : loss : 0.555876, loss_ce: 0.383838
[01:36:52.039] iteration 1490 : loss : 0.571344, loss_ce: 0.503171
[01:36:52.367] iteration 1491 : loss : 0.531506, loss_ce: 0.421822
[01:36:52.620] iteration 1492 : loss : 0.489843, loss_ce: 0.387673
[01:36:52.876] iteration 1493 : loss : 0.544149, loss_ce: 0.386772
[01:36:53.153] iteration 1494 : loss : 0.412255, loss_ce: 0.343660
[01:36:53.466] iteration 1495 : loss : 0.454663, loss_ce: 0.344264
[01:36:53.762] iteration 1496 : loss : 0.522337, loss_ce: 0.422899
[01:36:54.696] iteration 1497 : loss : 0.417630, loss_ce: 0.292255
[01:36:55.145] iteration 1498 : loss : 0.467202, loss_ce: 0.352896
[01:36:55.403] iteration 1499 : loss : 0.563487, loss_ce: 0.418261
[01:36:55.657] iteration 1500 : loss : 0.490900, loss_ce: 0.332116
[01:36:55.911] iteration 1501 : loss : 0.439811, loss_ce: 0.316641
[01:36:56.165] iteration 1502 : loss : 0.529471, loss_ce: 0.404836
[01:36:56.422] iteration 1503 : loss : 0.602323, loss_ce: 0.457719
[01:36:56.677] iteration 1504 : loss : 0.431613, loss_ce: 0.308677
[01:36:57.601] iteration 1505 : loss : 0.535149, loss_ce: 0.339525
[01:36:57.974] iteration 1506 : loss : 0.430914, loss_ce: 0.372733
[01:36:58.384] iteration 1507 : loss : 0.523039, loss_ce: 0.365403
[01:36:58.642] iteration 1508 : loss : 0.585845, loss_ce: 0.346250
[01:36:58.896] iteration 1509 : loss : 0.497130, loss_ce: 0.395921
[01:36:59.149] iteration 1510 : loss : 0.478189, loss_ce: 0.342062
[01:36:59.404] iteration 1511 : loss : 0.432346, loss_ce: 0.268481
[01:36:59.659] iteration 1512 : loss : 0.440793, loss_ce: 0.339509
[01:37:00.652] iteration 1513 : loss : 0.412605, loss_ce: 0.268286
[01:37:00.974] iteration 1514 : loss : 0.508652, loss_ce: 0.407627
[01:37:01.307] iteration 1515 : loss : 0.481974, loss_ce: 0.343758
[01:37:01.562] iteration 1516 : loss : 0.451600, loss_ce: 0.325252
[01:37:01.814] iteration 1517 : loss : 0.519591, loss_ce: 0.338395
[01:37:02.069] iteration 1518 : loss : 0.527569, loss_ce: 0.362604
[01:37:02.323] iteration 1519 : loss : 0.432034, loss_ce: 0.285317
[01:37:02.579] iteration 1520 : loss : 0.428126, loss_ce: 0.290984
[01:37:03.361] iteration 1521 : loss : 0.587861, loss_ce: 0.478992
[01:37:03.785] iteration 1522 : loss : 0.580111, loss_ce: 0.499473
[01:37:04.221] iteration 1523 : loss : 0.554050, loss_ce: 0.372557
[01:37:04.476] iteration 1524 : loss : 0.514667, loss_ce: 0.355264
[01:37:04.732] iteration 1525 : loss : 0.476899, loss_ce: 0.277631
[01:37:04.987] iteration 1526 : loss : 0.487847, loss_ce: 0.338864
[01:37:05.244] iteration 1527 : loss : 0.488012, loss_ce: 0.392108
[01:37:05.500] iteration 1528 : loss : 0.458729, loss_ce: 0.316055
[01:37:06.233] iteration 1529 : loss : 0.489751, loss_ce: 0.321099
[01:37:06.659] iteration 1530 : loss : 0.481036, loss_ce: 0.391068
[01:37:07.096] iteration 1531 : loss : 0.491755, loss_ce: 0.365869
[01:37:07.349] iteration 1532 : loss : 0.441865, loss_ce: 0.298744
[01:37:07.603] iteration 1533 : loss : 0.461810, loss_ce: 0.304005
[01:37:07.858] iteration 1534 : loss : 0.429128, loss_ce: 0.346275
[01:37:08.112] iteration 1535 : loss : 0.496206, loss_ce: 0.391545
[01:37:08.363] iteration 1536 : loss : 0.460197, loss_ce: 0.355871
[01:37:09.009] iteration 1537 : loss : 0.516146, loss_ce: 0.370694
[01:37:09.385] iteration 1538 : loss : 0.501471, loss_ce: 0.391130
[01:37:09.835] iteration 1539 : loss : 0.441866, loss_ce: 0.320359
[01:37:10.022] iteration 1540 : loss : 0.829469, loss_ce: 0.833971
[01:37:14.510] iteration 1541 : loss : 0.476781, loss_ce: 0.302617
[01:37:14.778] iteration 1542 : loss : 0.447521, loss_ce: 0.318441
[01:37:15.058] iteration 1543 : loss : 0.470495, loss_ce: 0.345788
[01:37:15.312] iteration 1544 : loss : 0.505168, loss_ce: 0.402954
[01:37:15.565] iteration 1545 : loss : 0.510728, loss_ce: 0.426928
[01:37:15.819] iteration 1546 : loss : 0.480124, loss_ce: 0.384288
[01:37:16.072] iteration 1547 : loss : 0.511360, loss_ce: 0.329143
[01:37:16.325] iteration 1548 : loss : 0.452015, loss_ce: 0.305316
[01:37:17.489] iteration 1549 : loss : 0.549980, loss_ce: 0.421439
[01:37:17.746] iteration 1550 : loss : 0.502387, loss_ce: 0.399312
[01:37:17.999] iteration 1551 : loss : 0.474626, loss_ce: 0.336884
[01:37:18.254] iteration 1552 : loss : 0.496781, loss_ce: 0.392575
[01:37:18.507] iteration 1553 : loss : 0.498980, loss_ce: 0.369712
[01:37:18.761] iteration 1554 : loss : 0.462777, loss_ce: 0.339501
[01:37:19.018] iteration 1555 : loss : 0.494317, loss_ce: 0.338140
[01:37:19.277] iteration 1556 : loss : 0.523746, loss_ce: 0.359041
[01:37:20.535] iteration 1557 : loss : 0.495757, loss_ce: 0.355461
[01:37:20.789] iteration 1558 : loss : 0.485522, loss_ce: 0.345946
[01:37:21.044] iteration 1559 : loss : 0.492527, loss_ce: 0.325295
[01:37:21.298] iteration 1560 : loss : 0.504187, loss_ce: 0.451490
[01:37:21.553] iteration 1561 : loss : 0.493723, loss_ce: 0.375136
[01:37:21.810] iteration 1562 : loss : 0.497749, loss_ce: 0.388571
[01:37:22.064] iteration 1563 : loss : 0.523373, loss_ce: 0.348258
[01:37:22.320] iteration 1564 : loss : 0.508518, loss_ce: 0.417275
[01:37:23.414] iteration 1565 : loss : 0.546272, loss_ce: 0.476949
[01:37:23.758] iteration 1566 : loss : 0.492085, loss_ce: 0.359078
[01:37:24.017] iteration 1567 : loss : 0.448760, loss_ce: 0.363926
[01:37:24.274] iteration 1568 : loss : 0.515969, loss_ce: 0.356646
[01:37:24.589] iteration 1569 : loss : 0.437053, loss_ce: 0.314525
[01:37:24.876] iteration 1570 : loss : 0.418479, loss_ce: 0.292076
[01:37:25.130] iteration 1571 : loss : 0.475256, loss_ce: 0.342285
[01:37:25.384] iteration 1572 : loss : 0.471199, loss_ce: 0.308975
[01:37:26.347] iteration 1573 : loss : 0.563890, loss_ce: 0.462082
[01:37:27.235] iteration 1574 : loss : 0.554709, loss_ce: 0.435268
[01:37:27.490] iteration 1575 : loss : 0.516398, loss_ce: 0.388113
[01:37:27.744] iteration 1576 : loss : 0.535523, loss_ce: 0.355068
[01:37:28.037] iteration 1577 : loss : 0.534681, loss_ce: 0.494418
[01:37:28.360] iteration 1578 : loss : 0.459519, loss_ce: 0.366705
[01:37:28.662] iteration 1579 : loss : 0.394554, loss_ce: 0.316555
[01:37:28.999] iteration 1580 : loss : 0.501987, loss_ce: 0.329237
[01:37:29.444] iteration 1581 : loss : 0.512736, loss_ce: 0.426764
[01:37:30.428] iteration 1582 : loss : 0.473487, loss_ce: 0.354869
[01:37:30.685] iteration 1583 : loss : 0.463009, loss_ce: 0.398837
[01:37:30.941] iteration 1584 : loss : 0.592667, loss_ce: 0.473726
[01:37:31.197] iteration 1585 : loss : 0.466427, loss_ce: 0.333740
[01:37:31.450] iteration 1586 : loss : 0.517633, loss_ce: 0.447472
[01:37:31.707] iteration 1587 : loss : 0.488974, loss_ce: 0.402008
[01:37:31.963] iteration 1588 : loss : 0.536765, loss_ce: 0.486553
[01:37:32.534] iteration 1589 : loss : 0.493201, loss_ce: 0.410988
[01:37:33.465] iteration 1590 : loss : 0.497811, loss_ce: 0.429443
[01:37:33.720] iteration 1591 : loss : 0.458037, loss_ce: 0.389184
[01:37:33.976] iteration 1592 : loss : 0.428980, loss_ce: 0.299232
[01:37:34.230] iteration 1593 : loss : 0.510924, loss_ce: 0.418699
[01:37:34.484] iteration 1594 : loss : 0.494488, loss_ce: 0.393557
[01:37:34.738] iteration 1595 : loss : 0.427622, loss_ce: 0.384463
[01:37:34.991] iteration 1596 : loss : 0.473469, loss_ce: 0.451178
[01:37:35.524] iteration 1597 : loss : 0.496499, loss_ce: 0.311812
[01:37:36.531] iteration 1598 : loss : 0.452681, loss_ce: 0.364945
[01:37:36.790] iteration 1599 : loss : 0.490311, loss_ce: 0.290827
[01:37:37.043] iteration 1600 : loss : 0.547720, loss_ce: 0.459077
[01:37:37.298] iteration 1601 : loss : 0.484090, loss_ce: 0.366787
[01:37:37.551] iteration 1602 : loss : 0.484823, loss_ce: 0.384463
[01:37:37.805] iteration 1603 : loss : 0.477152, loss_ce: 0.330117
[01:37:38.063] iteration 1604 : loss : 0.512859, loss_ce: 0.473873
[01:37:38.550] iteration 1605 : loss : 0.458467, loss_ce: 0.356698
[01:37:39.622] iteration 1606 : loss : 0.398701, loss_ce: 0.263383
[01:37:39.882] iteration 1607 : loss : 0.468492, loss_ce: 0.311633
[01:37:40.137] iteration 1608 : loss : 0.495402, loss_ce: 0.405337
[01:37:40.394] iteration 1609 : loss : 0.400214, loss_ce: 0.279167
[01:37:40.650] iteration 1610 : loss : 0.466412, loss_ce: 0.333149
[01:37:40.903] iteration 1611 : loss : 0.416446, loss_ce: 0.286542
[01:37:41.160] iteration 1612 : loss : 0.567311, loss_ce: 0.476671
[01:37:41.544] iteration 1613 : loss : 0.463458, loss_ce: 0.343420
[01:37:42.655] iteration 1614 : loss : 0.576620, loss_ce: 0.393616
[01:37:42.909] iteration 1615 : loss : 0.374587, loss_ce: 0.259401
[01:37:43.164] iteration 1616 : loss : 0.425665, loss_ce: 0.273094
[01:37:43.418] iteration 1617 : loss : 0.509408, loss_ce: 0.379469
[01:37:43.674] iteration 1618 : loss : 0.520889, loss_ce: 0.426563
[01:37:43.928] iteration 1619 : loss : 0.499183, loss_ce: 0.380744
[01:37:44.184] iteration 1620 : loss : 0.498559, loss_ce: 0.350629
[01:37:44.464] iteration 1621 : loss : 0.460895, loss_ce: 0.370965
[01:37:45.574] iteration 1622 : loss : 0.538256, loss_ce: 0.548502
[01:37:45.831] iteration 1623 : loss : 0.452961, loss_ce: 0.293401
[01:37:46.085] iteration 1624 : loss : 0.439006, loss_ce: 0.302775
[01:37:46.341] iteration 1625 : loss : 0.417565, loss_ce: 0.289553
[01:37:46.596] iteration 1626 : loss : 0.515316, loss_ce: 0.442941
[01:37:46.853] iteration 1627 : loss : 0.477849, loss_ce: 0.300398
[01:37:47.109] iteration 1628 : loss : 0.485459, loss_ce: 0.358586
[01:37:47.410] iteration 1629 : loss : 0.515481, loss_ce: 0.441770
[01:37:48.496] iteration 1630 : loss : 0.498977, loss_ce: 0.323615
[01:37:48.752] iteration 1631 : loss : 0.479149, loss_ce: 0.445670
[01:37:49.008] iteration 1632 : loss : 0.500995, loss_ce: 0.301787
[01:37:49.261] iteration 1633 : loss : 0.452916, loss_ce: 0.260375
[01:37:49.518] iteration 1634 : loss : 0.485643, loss_ce: 0.319391
[01:37:49.776] iteration 1635 : loss : 0.442903, loss_ce: 0.253313
[01:37:50.030] iteration 1636 : loss : 0.596803, loss_ce: 0.450834
[01:37:50.443] iteration 1637 : loss : 0.578928, loss_ce: 0.510812
[01:37:51.491] iteration 1638 : loss : 0.544349, loss_ce: 0.333980
[01:37:51.744] iteration 1639 : loss : 0.439235, loss_ce: 0.303874
[01:37:51.997] iteration 1640 : loss : 0.631484, loss_ce: 0.528934
[01:37:52.250] iteration 1641 : loss : 0.553442, loss_ce: 0.343875
[01:37:52.504] iteration 1642 : loss : 0.598207, loss_ce: 0.524304
[01:37:52.756] iteration 1643 : loss : 0.485357, loss_ce: 0.333461
[01:37:53.012] iteration 1644 : loss : 0.525685, loss_ce: 0.401754
[01:37:53.267] iteration 1645 : loss : 0.447853, loss_ce: 0.252130
[01:37:54.328] iteration 1646 : loss : 0.553904, loss_ce: 0.415678
[01:37:54.769] iteration 1647 : loss : 0.498980, loss_ce: 0.327477
[01:37:55.027] iteration 1648 : loss : 0.505521, loss_ce: 0.420221
[01:37:55.283] iteration 1649 : loss : 0.441240, loss_ce: 0.348728
[01:37:55.535] iteration 1650 : loss : 0.533726, loss_ce: 0.432390
[01:37:55.789] iteration 1651 : loss : 0.501425, loss_ce: 0.334877
[01:37:56.048] iteration 1652 : loss : 0.497609, loss_ce: 0.359802
[01:37:56.303] iteration 1653 : loss : 0.431303, loss_ce: 0.321782
[01:37:57.208] iteration 1654 : loss : 0.504185, loss_ce: 0.379686
[01:37:57.462] iteration 1655 : loss : 0.418448, loss_ce: 0.302405
[01:37:57.716] iteration 1656 : loss : 0.533544, loss_ce: 0.478493
[01:37:57.971] iteration 1657 : loss : 0.533246, loss_ce: 0.354901
[01:37:58.226] iteration 1658 : loss : 0.471793, loss_ce: 0.359591
[01:37:58.491] iteration 1659 : loss : 0.527260, loss_ce: 0.489644
[01:37:58.743] iteration 1660 : loss : 0.548492, loss_ce: 0.360085
[01:37:59.108] iteration 1661 : loss : 0.477496, loss_ce: 0.376586
[01:38:00.157] iteration 1662 : loss : 0.564536, loss_ce: 0.428622
[01:38:00.409] iteration 1663 : loss : 0.434047, loss_ce: 0.283538
[01:38:00.664] iteration 1664 : loss : 0.572320, loss_ce: 0.473977
[01:38:00.916] iteration 1665 : loss : 0.450902, loss_ce: 0.382590
[01:38:01.168] iteration 1666 : loss : 0.522450, loss_ce: 0.436290
[01:38:01.421] iteration 1667 : loss : 0.501481, loss_ce: 0.368874
[01:38:01.675] iteration 1668 : loss : 0.477875, loss_ce: 0.321447
[01:38:02.070] iteration 1669 : loss : 0.453954, loss_ce: 0.374137
[01:38:03.215] iteration 1670 : loss : 0.434968, loss_ce: 0.322749
[01:38:03.533] iteration 1671 : loss : 0.557623, loss_ce: 0.482907
[01:38:03.939] iteration 1672 : loss : 0.516572, loss_ce: 0.460830
[01:38:04.209] iteration 1673 : loss : 0.445923, loss_ce: 0.347838
[01:38:04.462] iteration 1674 : loss : 0.530295, loss_ce: 0.425495
[01:38:04.715] iteration 1675 : loss : 0.380113, loss_ce: 0.318299
[01:38:04.974] iteration 1676 : loss : 0.477036, loss_ce: 0.432218
[01:38:05.231] iteration 1677 : loss : 0.534382, loss_ce: 0.489024
[01:38:06.294] iteration 1678 : loss : 0.554086, loss_ce: 0.509176
[01:38:06.551] iteration 1679 : loss : 0.494914, loss_ce: 0.371214
[01:38:06.807] iteration 1680 : loss : 0.414009, loss_ce: 0.339521
[01:38:07.060] iteration 1681 : loss : 0.451795, loss_ce: 0.361494
[01:38:07.314] iteration 1682 : loss : 0.562018, loss_ce: 0.439907
[01:38:07.571] iteration 1683 : loss : 0.430453, loss_ce: 0.246602
[01:38:07.826] iteration 1684 : loss : 0.520718, loss_ce: 0.413601
[01:38:08.112] iteration 1685 : loss : 0.490473, loss_ce: 0.374525
[01:38:09.311] iteration 1686 : loss : 0.482055, loss_ce: 0.398257
[01:38:09.568] iteration 1687 : loss : 0.511318, loss_ce: 0.431464
[01:38:09.823] iteration 1688 : loss : 0.577270, loss_ce: 0.477571
[01:38:10.081] iteration 1689 : loss : 0.573024, loss_ce: 0.447238
[01:38:10.336] iteration 1690 : loss : 0.491652, loss_ce: 0.384920
[01:38:10.590] iteration 1691 : loss : 0.504543, loss_ce: 0.420505
[01:38:10.846] iteration 1692 : loss : 0.477904, loss_ce: 0.413683
[01:38:11.158] iteration 1693 : loss : 0.486701, loss_ce: 0.367776
[01:38:12.334] iteration 1694 : loss : 0.404778, loss_ce: 0.266061
[01:38:12.592] iteration 1695 : loss : 0.392106, loss_ce: 0.309805
[01:38:12.846] iteration 1696 : loss : 0.515931, loss_ce: 0.433555
[01:38:13.100] iteration 1697 : loss : 0.440562, loss_ce: 0.285431
[01:38:13.355] iteration 1698 : loss : 0.455367, loss_ce: 0.294477
[01:38:13.609] iteration 1699 : loss : 0.454372, loss_ce: 0.301013
[01:38:13.866] iteration 1700 : loss : 0.520692, loss_ce: 0.408394
[01:38:14.139] iteration 1701 : loss : 0.410532, loss_ce: 0.330485
[01:38:15.375] iteration 1702 : loss : 0.393754, loss_ce: 0.338729
[01:38:15.631] iteration 1703 : loss : 0.537798, loss_ce: 0.467535
[01:38:15.887] iteration 1704 : loss : 0.438850, loss_ce: 0.343332
[01:38:16.143] iteration 1705 : loss : 0.508254, loss_ce: 0.302296
[01:38:16.399] iteration 1706 : loss : 0.419874, loss_ce: 0.241898
[01:38:16.655] iteration 1707 : loss : 0.438191, loss_ce: 0.329478
[01:38:16.917] iteration 1708 : loss : 0.473078, loss_ce: 0.411012
[01:38:17.174] iteration 1709 : loss : 0.571739, loss_ce: 0.387406
[01:38:18.459] iteration 1710 : loss : 0.427653, loss_ce: 0.310715
[01:38:18.723] iteration 1711 : loss : 0.429217, loss_ce: 0.308649
[01:38:19.000] iteration 1712 : loss : 0.456324, loss_ce: 0.356550
[01:38:19.263] iteration 1713 : loss : 0.456496, loss_ce: 0.337658
[01:38:19.520] iteration 1714 : loss : 0.419182, loss_ce: 0.264802
[01:38:19.776] iteration 1715 : loss : 0.374006, loss_ce: 0.279849
[01:38:20.034] iteration 1716 : loss : 0.406163, loss_ce: 0.240357
[01:38:20.290] iteration 1717 : loss : 0.482172, loss_ce: 0.332572
[01:38:21.375] iteration 1718 : loss : 0.450314, loss_ce: 0.377289
[01:38:21.633] iteration 1719 : loss : 0.408324, loss_ce: 0.266335
[01:38:21.887] iteration 1720 : loss : 0.398907, loss_ce: 0.282980
[01:38:22.141] iteration 1721 : loss : 0.579514, loss_ce: 0.446052
[01:38:22.396] iteration 1722 : loss : 0.547816, loss_ce: 0.395626
[01:38:22.654] iteration 1723 : loss : 0.408013, loss_ce: 0.294644
[01:38:22.934] iteration 1724 : loss : 0.614437, loss_ce: 0.507758
[01:38:23.195] iteration 1725 : loss : 0.479762, loss_ce: 0.404197
[01:38:24.299] iteration 1726 : loss : 0.449278, loss_ce: 0.270214
[01:38:24.556] iteration 1727 : loss : 0.440096, loss_ce: 0.349357
[01:38:24.813] iteration 1728 : loss : 0.531714, loss_ce: 0.429175
[01:38:25.068] iteration 1729 : loss : 0.357574, loss_ce: 0.251558
[01:38:25.324] iteration 1730 : loss : 0.434434, loss_ce: 0.341796
[01:38:25.583] iteration 1731 : loss : 0.469204, loss_ce: 0.292883
[01:38:25.837] iteration 1732 : loss : 0.448501, loss_ce: 0.302568
[01:38:26.092] iteration 1733 : loss : 0.484619, loss_ce: 0.343455
[01:38:27.267] iteration 1734 : loss : 0.467667, loss_ce: 0.356768
[01:38:27.524] iteration 1735 : loss : 0.426647, loss_ce: 0.387447
[01:38:27.779] iteration 1736 : loss : 0.551263, loss_ce: 0.417544
[01:38:28.032] iteration 1737 : loss : 0.507079, loss_ce: 0.461570
[01:38:28.284] iteration 1738 : loss : 0.539435, loss_ce: 0.415886
[01:38:28.538] iteration 1739 : loss : 0.559019, loss_ce: 0.467598
[01:38:28.791] iteration 1740 : loss : 0.372481, loss_ce: 0.285976
[01:38:29.045] iteration 1741 : loss : 0.525548, loss_ce: 0.371340
[01:38:30.172] iteration 1742 : loss : 0.479946, loss_ce: 0.303711
[01:38:30.428] iteration 1743 : loss : 0.395347, loss_ce: 0.280855
[01:38:30.684] iteration 1744 : loss : 0.486697, loss_ce: 0.341489
[01:38:30.938] iteration 1745 : loss : 0.505855, loss_ce: 0.339820
[01:38:31.191] iteration 1746 : loss : 0.401170, loss_ce: 0.305590
[01:38:31.443] iteration 1747 : loss : 0.549071, loss_ce: 0.480868
[01:38:31.697] iteration 1748 : loss : 0.414297, loss_ce: 0.295601
[01:38:31.954] iteration 1749 : loss : 0.428685, loss_ce: 0.382198
[01:38:33.049] iteration 1750 : loss : 0.515457, loss_ce: 0.351587
[01:38:33.306] iteration 1751 : loss : 0.505736, loss_ce: 0.511986
[01:38:33.561] iteration 1752 : loss : 0.393991, loss_ce: 0.301486
[01:38:33.813] iteration 1753 : loss : 0.436478, loss_ce: 0.296153
[01:38:34.067] iteration 1754 : loss : 0.406261, loss_ce: 0.316119
[01:38:34.318] iteration 1755 : loss : 0.577471, loss_ce: 0.411984
[01:38:34.573] iteration 1756 : loss : 0.459959, loss_ce: 0.286126
[01:38:34.825] iteration 1757 : loss : 0.408574, loss_ce: 0.242306
[01:38:35.632] iteration 1758 : loss : 0.425131, loss_ce: 0.308032
[01:38:35.884] iteration 1759 : loss : 0.485406, loss_ce: 0.330425
[01:38:36.071] iteration 1760 : loss : 0.680374, loss_ce: 0.606636
[01:38:40.518] iteration 1761 : loss : 0.404331, loss_ce: 0.249628
[01:38:40.776] iteration 1762 : loss : 0.519758, loss_ce: 0.331221
[01:38:41.028] iteration 1763 : loss : 0.490153, loss_ce: 0.351090
[01:38:41.283] iteration 1764 : loss : 0.431702, loss_ce: 0.287733
[01:38:41.538] iteration 1765 : loss : 0.517632, loss_ce: 0.405070
[01:38:41.790] iteration 1766 : loss : 0.560808, loss_ce: 0.479783
[01:38:42.045] iteration 1767 : loss : 0.460352, loss_ce: 0.388478
[01:38:42.299] iteration 1768 : loss : 0.455423, loss_ce: 0.295088
[01:38:43.488] iteration 1769 : loss : 0.499956, loss_ce: 0.361393
[01:38:43.742] iteration 1770 : loss : 0.493731, loss_ce: 0.410573
[01:38:43.996] iteration 1771 : loss : 0.433272, loss_ce: 0.366706
[01:38:44.250] iteration 1772 : loss : 0.467002, loss_ce: 0.321343
[01:38:44.539] iteration 1773 : loss : 0.491299, loss_ce: 0.408569
[01:38:44.793] iteration 1774 : loss : 0.470527, loss_ce: 0.320148
[01:38:45.049] iteration 1775 : loss : 0.529274, loss_ce: 0.392068
[01:38:45.304] iteration 1776 : loss : 0.541017, loss_ce: 0.464704
[01:38:46.561] iteration 1777 : loss : 0.447705, loss_ce: 0.281676
[01:38:46.813] iteration 1778 : loss : 0.495001, loss_ce: 0.379780
[01:38:47.069] iteration 1779 : loss : 0.437347, loss_ce: 0.371770
[01:38:47.321] iteration 1780 : loss : 0.384188, loss_ce: 0.294699
[01:38:47.574] iteration 1781 : loss : 0.509099, loss_ce: 0.391101
[01:38:48.038] iteration 1782 : loss : 0.446175, loss_ce: 0.291864
[01:38:48.293] iteration 1783 : loss : 0.484667, loss_ce: 0.357284
[01:38:48.546] iteration 1784 : loss : 0.487502, loss_ce: 0.366127
[01:38:49.611] iteration 1785 : loss : 0.442543, loss_ce: 0.329685
[01:38:49.864] iteration 1786 : loss : 0.355985, loss_ce: 0.333423
[01:38:50.116] iteration 1787 : loss : 0.404819, loss_ce: 0.345315
[01:38:50.370] iteration 1788 : loss : 0.521153, loss_ce: 0.350979
[01:38:50.624] iteration 1789 : loss : 0.473820, loss_ce: 0.374459
[01:38:50.876] iteration 1790 : loss : 0.478915, loss_ce: 0.293138
[01:38:51.130] iteration 1791 : loss : 0.396257, loss_ce: 0.254110
[01:38:51.384] iteration 1792 : loss : 0.424475, loss_ce: 0.275584
[01:38:52.696] iteration 1793 : loss : 0.488175, loss_ce: 0.410245
[01:38:52.950] iteration 1794 : loss : 0.408173, loss_ce: 0.276205
[01:38:53.205] iteration 1795 : loss : 0.478140, loss_ce: 0.342174
[01:38:53.459] iteration 1796 : loss : 0.446642, loss_ce: 0.347927
[01:38:53.713] iteration 1797 : loss : 0.438603, loss_ce: 0.353224
[01:38:53.967] iteration 1798 : loss : 0.447388, loss_ce: 0.357576
[01:38:54.221] iteration 1799 : loss : 0.523545, loss_ce: 0.456334
[01:38:54.477] iteration 1800 : loss : 0.459421, loss_ce: 0.356931
[01:38:55.679] iteration 1801 : loss : 0.594694, loss_ce: 0.519371
[01:38:55.933] iteration 1802 : loss : 0.531688, loss_ce: 0.378302
[01:38:56.188] iteration 1803 : loss : 0.435463, loss_ce: 0.362458
[01:38:56.443] iteration 1804 : loss : 0.396679, loss_ce: 0.300509
[01:38:56.699] iteration 1805 : loss : 0.455054, loss_ce: 0.287374
[01:38:56.953] iteration 1806 : loss : 0.475048, loss_ce: 0.316598
[01:38:57.208] iteration 1807 : loss : 0.566031, loss_ce: 0.520908
[01:38:57.463] iteration 1808 : loss : 0.414335, loss_ce: 0.274678
[01:38:58.755] iteration 1809 : loss : 0.422781, loss_ce: 0.373408
[01:38:59.011] iteration 1810 : loss : 0.408125, loss_ce: 0.385050
[01:38:59.266] iteration 1811 : loss : 0.448372, loss_ce: 0.315086
[01:38:59.520] iteration 1812 : loss : 0.521530, loss_ce: 0.431497
[01:38:59.772] iteration 1813 : loss : 0.500443, loss_ce: 0.420433
[01:39:00.026] iteration 1814 : loss : 0.403708, loss_ce: 0.300632
[01:39:00.280] iteration 1815 : loss : 0.434769, loss_ce: 0.280399
[01:39:00.533] iteration 1816 : loss : 0.490174, loss_ce: 0.453352
[01:39:01.756] iteration 1817 : loss : 0.428537, loss_ce: 0.332704
[01:39:02.012] iteration 1818 : loss : 0.565114, loss_ce: 0.497676
[01:39:02.265] iteration 1819 : loss : 0.434191, loss_ce: 0.280904
[01:39:02.519] iteration 1820 : loss : 0.419683, loss_ce: 0.335513
[01:39:02.772] iteration 1821 : loss : 0.449659, loss_ce: 0.309341
[01:39:03.026] iteration 1822 : loss : 0.440201, loss_ce: 0.336108
[01:39:03.280] iteration 1823 : loss : 0.518099, loss_ce: 0.388948
[01:39:03.533] iteration 1824 : loss : 0.386183, loss_ce: 0.275369
[01:39:04.560] iteration 1825 : loss : 0.440748, loss_ce: 0.307989
[01:39:04.826] iteration 1826 : loss : 0.423310, loss_ce: 0.296907
[01:39:05.087] iteration 1827 : loss : 0.510833, loss_ce: 0.366175
[01:39:05.341] iteration 1828 : loss : 0.479496, loss_ce: 0.286510
[01:39:05.597] iteration 1829 : loss : 0.427020, loss_ce: 0.302629
[01:39:05.849] iteration 1830 : loss : 0.450472, loss_ce: 0.318559
[01:39:06.103] iteration 1831 : loss : 0.480489, loss_ce: 0.409961
[01:39:06.358] iteration 1832 : loss : 0.509482, loss_ce: 0.408955
[01:39:07.394] iteration 1833 : loss : 0.429388, loss_ce: 0.333379
[01:39:07.649] iteration 1834 : loss : 0.383997, loss_ce: 0.243170
[01:39:07.905] iteration 1835 : loss : 0.483948, loss_ce: 0.374326
[01:39:08.158] iteration 1836 : loss : 0.596021, loss_ce: 0.407879
[01:39:08.414] iteration 1837 : loss : 0.491230, loss_ce: 0.322072
[01:39:08.668] iteration 1838 : loss : 0.486101, loss_ce: 0.369835
[01:39:08.924] iteration 1839 : loss : 0.482711, loss_ce: 0.309325
[01:39:09.176] iteration 1840 : loss : 0.463193, loss_ce: 0.307561
[01:39:10.293] iteration 1841 : loss : 0.433005, loss_ce: 0.305850
[01:39:10.547] iteration 1842 : loss : 0.446590, loss_ce: 0.298168
[01:39:10.803] iteration 1843 : loss : 0.414950, loss_ce: 0.286138
[01:39:11.058] iteration 1844 : loss : 0.499750, loss_ce: 0.353145
[01:39:11.314] iteration 1845 : loss : 0.464829, loss_ce: 0.345393
[01:39:11.567] iteration 1846 : loss : 0.374981, loss_ce: 0.312265
[01:39:11.820] iteration 1847 : loss : 0.473117, loss_ce: 0.360700
[01:39:12.076] iteration 1848 : loss : 0.484487, loss_ce: 0.371591
[01:39:13.397] iteration 1849 : loss : 0.461101, loss_ce: 0.403860
[01:39:13.686] iteration 1850 : loss : 0.497591, loss_ce: 0.299808
[01:39:13.939] iteration 1851 : loss : 0.549724, loss_ce: 0.473557
[01:39:14.192] iteration 1852 : loss : 0.471252, loss_ce: 0.360759
[01:39:14.445] iteration 1853 : loss : 0.471033, loss_ce: 0.403092
[01:39:14.698] iteration 1854 : loss : 0.426064, loss_ce: 0.299057
[01:39:14.954] iteration 1855 : loss : 0.512107, loss_ce: 0.440628
[01:39:15.234] iteration 1856 : loss : 0.472570, loss_ce: 0.361335
[01:39:16.375] iteration 1857 : loss : 0.455012, loss_ce: 0.369063
[01:39:16.628] iteration 1858 : loss : 0.536061, loss_ce: 0.491781
[01:39:16.903] iteration 1859 : loss : 0.468402, loss_ce: 0.238990
[01:39:17.157] iteration 1860 : loss : 0.581861, loss_ce: 0.381923
[01:39:17.410] iteration 1861 : loss : 0.500698, loss_ce: 0.365067
[01:39:17.662] iteration 1862 : loss : 0.474584, loss_ce: 0.314546
[01:39:17.918] iteration 1863 : loss : 0.421512, loss_ce: 0.363114
[01:39:18.177] iteration 1864 : loss : 0.402989, loss_ce: 0.308927
[01:39:19.376] iteration 1865 : loss : 0.469589, loss_ce: 0.288843
[01:39:19.630] iteration 1866 : loss : 0.479942, loss_ce: 0.251437
[01:39:19.883] iteration 1867 : loss : 0.362806, loss_ce: 0.276388
[01:39:20.139] iteration 1868 : loss : 0.448393, loss_ce: 0.294021
[01:39:20.392] iteration 1869 : loss : 0.420463, loss_ce: 0.323792
[01:39:20.647] iteration 1870 : loss : 0.448057, loss_ce: 0.301020
[01:39:20.900] iteration 1871 : loss : 0.483281, loss_ce: 0.452286
[01:39:21.154] iteration 1872 : loss : 0.439844, loss_ce: 0.416924
[01:39:22.888] iteration 1873 : loss : 0.482178, loss_ce: 0.293055
[01:39:23.144] iteration 1874 : loss : 0.490898, loss_ce: 0.375823
[01:39:23.402] iteration 1875 : loss : 0.455988, loss_ce: 0.311632
[01:39:23.657] iteration 1876 : loss : 0.551980, loss_ce: 0.375801
[01:39:23.910] iteration 1877 : loss : 0.420515, loss_ce: 0.379074
[01:39:24.164] iteration 1878 : loss : 0.504156, loss_ce: 0.309858
[01:39:24.418] iteration 1879 : loss : 0.489127, loss_ce: 0.370502
[01:39:24.675] iteration 1880 : loss : 0.336755, loss_ce: 0.247586
[01:39:26.118] iteration 1881 : loss : 0.473406, loss_ce: 0.454880
[01:39:26.372] iteration 1882 : loss : 0.332748, loss_ce: 0.292080
[01:39:26.624] iteration 1883 : loss : 0.363149, loss_ce: 0.229240
[01:39:26.876] iteration 1884 : loss : 0.577592, loss_ce: 0.482029
[01:39:27.130] iteration 1885 : loss : 0.476009, loss_ce: 0.375874
[01:39:27.383] iteration 1886 : loss : 0.484563, loss_ce: 0.320417
[01:39:27.642] iteration 1887 : loss : 0.455846, loss_ce: 0.383924
[01:39:27.900] iteration 1888 : loss : 0.391783, loss_ce: 0.347686
[01:39:29.061] iteration 1889 : loss : 0.433066, loss_ce: 0.418986
[01:39:29.321] iteration 1890 : loss : 0.380911, loss_ce: 0.279258
[01:39:29.576] iteration 1891 : loss : 0.442732, loss_ce: 0.343035
[01:39:29.829] iteration 1892 : loss : 0.390134, loss_ce: 0.302205
[01:39:30.082] iteration 1893 : loss : 0.544371, loss_ce: 0.342103
[01:39:30.341] iteration 1894 : loss : 0.365866, loss_ce: 0.323323
[01:39:30.593] iteration 1895 : loss : 0.458061, loss_ce: 0.313075
[01:39:30.853] iteration 1896 : loss : 0.506126, loss_ce: 0.383847
[01:39:31.989] iteration 1897 : loss : 0.460037, loss_ce: 0.322123
[01:39:32.241] iteration 1898 : loss : 0.459240, loss_ce: 0.335103
[01:39:32.496] iteration 1899 : loss : 0.528828, loss_ce: 0.384047
[01:39:32.749] iteration 1900 : loss : 0.445522, loss_ce: 0.341158
[01:39:33.001] iteration 1901 : loss : 0.495467, loss_ce: 0.309015
[01:39:33.261] iteration 1902 : loss : 0.455437, loss_ce: 0.362958
[01:39:33.513] iteration 1903 : loss : 0.440859, loss_ce: 0.340972
[01:39:33.780] iteration 1904 : loss : 0.451146, loss_ce: 0.303058
[01:39:34.924] iteration 1905 : loss : 0.441153, loss_ce: 0.323658
[01:39:35.180] iteration 1906 : loss : 0.445530, loss_ce: 0.306861
[01:39:35.434] iteration 1907 : loss : 0.478399, loss_ce: 0.330945
[01:39:35.689] iteration 1908 : loss : 0.501193, loss_ce: 0.292026
[01:39:35.940] iteration 1909 : loss : 0.468903, loss_ce: 0.278811
[01:39:36.192] iteration 1910 : loss : 0.452137, loss_ce: 0.346928
[01:39:36.448] iteration 1911 : loss : 0.467859, loss_ce: 0.352456
[01:39:36.703] iteration 1912 : loss : 0.452060, loss_ce: 0.344627
[01:39:37.898] iteration 1913 : loss : 0.490113, loss_ce: 0.320791
[01:39:38.151] iteration 1914 : loss : 0.517271, loss_ce: 0.332458
[01:39:38.403] iteration 1915 : loss : 0.427923, loss_ce: 0.290922
[01:39:38.656] iteration 1916 : loss : 0.457735, loss_ce: 0.294253
[01:39:38.908] iteration 1917 : loss : 0.465643, loss_ce: 0.244060
[01:39:39.318] iteration 1918 : loss : 0.412438, loss_ce: 0.262220
[01:39:39.570] iteration 1919 : loss : 0.493362, loss_ce: 0.365637
[01:39:39.827] iteration 1920 : loss : 0.542536, loss_ce: 0.501004
[01:39:40.647] iteration 1921 : loss : 0.457757, loss_ce: 0.322843
[01:39:40.900] iteration 1922 : loss : 0.555667, loss_ce: 0.452398
[01:39:41.154] iteration 1923 : loss : 0.389974, loss_ce: 0.230951
[01:39:41.407] iteration 1924 : loss : 0.472070, loss_ce: 0.389203
[01:39:41.661] iteration 1925 : loss : 0.374071, loss_ce: 0.323243
[01:39:41.915] iteration 1926 : loss : 0.540559, loss_ce: 0.418796
[01:39:42.168] iteration 1927 : loss : 0.519177, loss_ce: 0.286830
[01:39:42.422] iteration 1928 : loss : 0.458785, loss_ce: 0.393742
[01:39:43.501] iteration 1929 : loss : 0.531523, loss_ce: 0.416950
[01:39:43.754] iteration 1930 : loss : 0.471051, loss_ce: 0.347551
[01:39:44.008] iteration 1931 : loss : 0.446084, loss_ce: 0.348719
[01:39:44.261] iteration 1932 : loss : 0.385177, loss_ce: 0.276391
[01:39:44.514] iteration 1933 : loss : 0.408462, loss_ce: 0.253743
[01:39:44.767] iteration 1934 : loss : 0.394936, loss_ce: 0.209780
[01:39:45.022] iteration 1935 : loss : 0.438300, loss_ce: 0.391812
[01:39:45.278] iteration 1936 : loss : 0.525442, loss_ce: 0.394686
[01:39:46.385] iteration 1937 : loss : 0.561581, loss_ce: 0.491881
[01:39:46.637] iteration 1938 : loss : 0.493772, loss_ce: 0.345172
[01:39:46.891] iteration 1939 : loss : 0.465645, loss_ce: 0.363542
[01:39:47.159] iteration 1940 : loss : 0.532376, loss_ce: 0.402693
[01:39:47.456] iteration 1941 : loss : 0.468627, loss_ce: 0.354639
[01:39:47.758] iteration 1942 : loss : 0.497637, loss_ce: 0.475392
[01:39:48.053] iteration 1943 : loss : 0.534870, loss_ce: 0.551683
[01:39:48.391] iteration 1944 : loss : 0.472530, loss_ce: 0.327198
[01:39:49.422] iteration 1945 : loss : 0.468819, loss_ce: 0.322980
[01:39:49.676] iteration 1946 : loss : 0.432628, loss_ce: 0.301805
[01:39:49.930] iteration 1947 : loss : 0.492484, loss_ce: 0.389805
[01:39:50.185] iteration 1948 : loss : 0.420930, loss_ce: 0.310497
[01:39:50.439] iteration 1949 : loss : 0.538758, loss_ce: 0.422409
[01:39:50.693] iteration 1950 : loss : 0.472757, loss_ce: 0.278344
[01:39:50.948] iteration 1951 : loss : 0.381700, loss_ce: 0.270569
[01:39:51.204] iteration 1952 : loss : 0.509972, loss_ce: 0.493341
[01:39:52.511] iteration 1953 : loss : 0.379866, loss_ce: 0.239112
[01:39:52.766] iteration 1954 : loss : 0.420688, loss_ce: 0.326401
[01:39:53.020] iteration 1955 : loss : 0.598436, loss_ce: 0.548851
[01:39:53.273] iteration 1956 : loss : 0.511752, loss_ce: 0.429881
[01:39:53.528] iteration 1957 : loss : 0.369281, loss_ce: 0.304560
[01:39:53.813] iteration 1958 : loss : 0.477631, loss_ce: 0.302948
[01:39:54.074] iteration 1959 : loss : 0.448721, loss_ce: 0.320324
[01:39:54.328] iteration 1960 : loss : 0.334112, loss_ce: 0.321101
[01:39:55.547] iteration 1961 : loss : 0.456669, loss_ce: 0.291991
[01:39:55.802] iteration 1962 : loss : 0.506023, loss_ce: 0.391183
[01:39:56.058] iteration 1963 : loss : 0.426224, loss_ce: 0.311524
[01:39:56.337] iteration 1964 : loss : 0.469539, loss_ce: 0.358128
[01:39:56.591] iteration 1965 : loss : 0.585917, loss_ce: 0.374726
[01:39:56.850] iteration 1966 : loss : 0.466161, loss_ce: 0.342201
[01:39:57.105] iteration 1967 : loss : 0.524201, loss_ce: 0.394741
[01:39:57.375] iteration 1968 : loss : 0.440499, loss_ce: 0.251864
[01:39:59.178] iteration 1969 : loss : 0.370274, loss_ce: 0.245785
[01:39:59.430] iteration 1970 : loss : 0.446577, loss_ce: 0.391900
[01:39:59.684] iteration 1971 : loss : 0.439423, loss_ce: 0.353601
[01:39:59.938] iteration 1972 : loss : 0.505950, loss_ce: 0.324461
[01:40:00.192] iteration 1973 : loss : 0.531656, loss_ce: 0.373419
[01:40:00.446] iteration 1974 : loss : 0.497576, loss_ce: 0.430035
[01:40:00.698] iteration 1975 : loss : 0.379894, loss_ce: 0.344825
[01:40:00.951] iteration 1976 : loss : 0.413550, loss_ce: 0.266162
[01:40:01.969] iteration 1977 : loss : 0.402691, loss_ce: 0.317937
[01:40:02.220] iteration 1978 : loss : 0.601000, loss_ce: 0.492599
[01:40:02.476] iteration 1979 : loss : 0.487643, loss_ce: 0.406539
[01:40:02.680] iteration 1980 : loss : 0.616283, loss_ce: 0.372439
[01:40:06.901] iteration 1981 : loss : 0.437329, loss_ce: 0.239137
[01:40:07.265] iteration 1982 : loss : 0.508784, loss_ce: 0.383387
[01:40:07.517] iteration 1983 : loss : 0.507156, loss_ce: 0.381282
[01:40:07.774] iteration 1984 : loss : 0.388376, loss_ce: 0.293981
[01:40:08.026] iteration 1985 : loss : 0.564399, loss_ce: 0.471763
[01:40:08.277] iteration 1986 : loss : 0.495699, loss_ce: 0.347813
[01:40:08.529] iteration 1987 : loss : 0.424942, loss_ce: 0.256110
[01:40:08.782] iteration 1988 : loss : 0.414383, loss_ce: 0.359094
[01:40:09.805] iteration 1989 : loss : 0.361518, loss_ce: 0.339813
[01:40:10.238] iteration 1990 : loss : 0.493263, loss_ce: 0.339748
[01:40:10.491] iteration 1991 : loss : 0.425047, loss_ce: 0.263584
[01:40:10.742] iteration 1992 : loss : 0.449902, loss_ce: 0.284939
[01:40:10.995] iteration 1993 : loss : 0.454057, loss_ce: 0.336928
[01:40:11.247] iteration 1994 : loss : 0.396809, loss_ce: 0.363027
[01:40:11.500] iteration 1995 : loss : 0.459647, loss_ce: 0.335953
[01:40:11.750] iteration 1996 : loss : 0.419114, loss_ce: 0.330152
[01:40:12.686] iteration 1997 : loss : 0.403517, loss_ce: 0.381464
[01:40:13.144] iteration 1998 : loss : 0.404078, loss_ce: 0.382554
[01:40:13.399] iteration 1999 : loss : 0.463859, loss_ce: 0.306401
[01:40:13.652] iteration 2000 : loss : 0.430845, loss_ce: 0.247946
[01:40:13.907] iteration 2001 : loss : 0.529635, loss_ce: 0.378082
[01:40:14.158] iteration 2002 : loss : 0.384184, loss_ce: 0.234912
[01:40:14.409] iteration 2003 : loss : 0.523470, loss_ce: 0.399279
[01:40:14.664] iteration 2004 : loss : 0.564736, loss_ce: 0.458793
[01:40:15.606] iteration 2005 : loss : 0.443321, loss_ce: 0.358380
[01:40:16.093] iteration 2006 : loss : 0.338995, loss_ce: 0.209028
[01:40:16.349] iteration 2007 : loss : 0.486779, loss_ce: 0.321988
[01:40:16.600] iteration 2008 : loss : 0.389380, loss_ce: 0.266641
[01:40:16.854] iteration 2009 : loss : 0.390969, loss_ce: 0.356470
[01:40:17.107] iteration 2010 : loss : 0.543090, loss_ce: 0.420296
[01:40:17.358] iteration 2011 : loss : 0.450161, loss_ce: 0.299080
[01:40:17.611] iteration 2012 : loss : 0.437640, loss_ce: 0.319702
[01:40:18.421] iteration 2013 : loss : 0.342624, loss_ce: 0.251605
[01:40:18.971] iteration 2014 : loss : 0.372716, loss_ce: 0.322504
[01:40:19.234] iteration 2015 : loss : 0.468858, loss_ce: 0.358657
[01:40:19.486] iteration 2016 : loss : 0.506357, loss_ce: 0.346345
[01:40:19.740] iteration 2017 : loss : 0.580054, loss_ce: 0.571388
[01:40:19.993] iteration 2018 : loss : 0.383046, loss_ce: 0.278290
[01:40:20.246] iteration 2019 : loss : 0.396727, loss_ce: 0.384380
[01:40:20.498] iteration 2020 : loss : 0.429506, loss_ce: 0.295753
[01:40:21.334] iteration 2021 : loss : 0.343055, loss_ce: 0.232941
[01:40:21.920] iteration 2022 : loss : 0.481839, loss_ce: 0.360140
[01:40:22.219] iteration 2023 : loss : 0.389184, loss_ce: 0.247164
[01:40:22.520] iteration 2024 : loss : 0.439878, loss_ce: 0.286213
[01:40:22.805] iteration 2025 : loss : 0.439537, loss_ce: 0.261154
[01:40:23.151] iteration 2026 : loss : 0.402701, loss_ce: 0.263346
[01:40:23.479] iteration 2027 : loss : 0.471375, loss_ce: 0.391718
[01:40:23.741] iteration 2028 : loss : 0.429635, loss_ce: 0.342475
[01:40:24.457] iteration 2029 : loss : 0.462617, loss_ce: 0.436974
[01:40:25.011] iteration 2030 : loss : 0.492085, loss_ce: 0.264745
[01:40:25.266] iteration 2031 : loss : 0.466856, loss_ce: 0.282524
[01:40:25.520] iteration 2032 : loss : 0.514762, loss_ce: 0.329255
[01:40:25.778] iteration 2033 : loss : 0.426876, loss_ce: 0.362973
[01:40:26.055] iteration 2034 : loss : 0.446119, loss_ce: 0.416315
[01:40:26.338] iteration 2035 : loss : 0.489623, loss_ce: 0.340700
[01:40:26.591] iteration 2036 : loss : 0.478227, loss_ce: 0.355942
[01:40:27.427] iteration 2037 : loss : 0.519995, loss_ce: 0.522088
[01:40:28.266] iteration 2038 : loss : 0.429678, loss_ce: 0.226401
[01:40:28.520] iteration 2039 : loss : 0.460466, loss_ce: 0.320241
[01:40:28.773] iteration 2040 : loss : 0.390944, loss_ce: 0.274151
[01:40:29.025] iteration 2041 : loss : 0.497315, loss_ce: 0.362395
[01:40:29.280] iteration 2042 : loss : 0.406704, loss_ce: 0.274910
[01:40:29.534] iteration 2043 : loss : 0.484433, loss_ce: 0.314644
[01:40:29.789] iteration 2044 : loss : 0.475049, loss_ce: 0.396317
[01:40:30.465] iteration 2045 : loss : 0.507105, loss_ce: 0.354099
[01:40:31.760] iteration 2046 : loss : 0.450881, loss_ce: 0.305105
[01:40:32.008] iteration 2047 : loss : 0.600198, loss_ce: 0.500058
[01:40:32.244] iteration 2048 : loss : 0.487285, loss_ce: 0.420333
[01:40:32.476] iteration 2049 : loss : 0.484441, loss_ce: 0.324550
[01:40:32.708] iteration 2050 : loss : 0.392331, loss_ce: 0.304975
[01:40:32.965] iteration 2051 : loss : 0.528574, loss_ce: 0.386815
[01:40:33.420] iteration 2052 : loss : 0.442457, loss_ce: 0.285269
[01:40:34.143] iteration 2053 : loss : 0.394572, loss_ce: 0.325859
[01:40:34.699] iteration 2054 : loss : 0.409288, loss_ce: 0.249098
[01:40:34.952] iteration 2055 : loss : 0.436320, loss_ce: 0.331811
[01:40:35.211] iteration 2056 : loss : 0.450224, loss_ce: 0.334007
[01:40:35.483] iteration 2057 : loss : 0.453695, loss_ce: 0.258519
[01:40:35.752] iteration 2058 : loss : 0.390169, loss_ce: 0.329129
[01:40:36.011] iteration 2059 : loss : 0.473890, loss_ce: 0.369674
[01:40:36.265] iteration 2060 : loss : 0.426683, loss_ce: 0.303277
[01:40:37.567] iteration 2061 : loss : 0.415157, loss_ce: 0.295999
[01:40:37.830] iteration 2062 : loss : 0.434502, loss_ce: 0.334708
[01:40:38.086] iteration 2063 : loss : 0.375183, loss_ce: 0.254843
[01:40:38.347] iteration 2064 : loss : 0.456840, loss_ce: 0.286090
[01:40:38.600] iteration 2065 : loss : 0.389074, loss_ce: 0.238688
[01:40:38.855] iteration 2066 : loss : 0.449967, loss_ce: 0.297914
[01:40:39.112] iteration 2067 : loss : 0.405033, loss_ce: 0.251551
[01:40:39.367] iteration 2068 : loss : 0.374750, loss_ce: 0.308109
[01:40:40.539] iteration 2069 : loss : 0.373896, loss_ce: 0.221941
[01:40:40.797] iteration 2070 : loss : 0.486849, loss_ce: 0.389851
[01:40:41.052] iteration 2071 : loss : 0.531423, loss_ce: 0.395418
[01:40:41.308] iteration 2072 : loss : 0.506045, loss_ce: 0.417441
[01:40:41.564] iteration 2073 : loss : 0.425262, loss_ce: 0.339478
[01:40:41.821] iteration 2074 : loss : 0.451172, loss_ce: 0.258672
[01:40:42.076] iteration 2075 : loss : 0.430356, loss_ce: 0.341544
[01:40:42.335] iteration 2076 : loss : 0.436191, loss_ce: 0.336998
[01:40:43.513] iteration 2077 : loss : 0.471561, loss_ce: 0.322316
[01:40:43.772] iteration 2078 : loss : 0.455169, loss_ce: 0.334523
[01:40:44.026] iteration 2079 : loss : 0.473678, loss_ce: 0.349240
[01:40:44.281] iteration 2080 : loss : 0.423070, loss_ce: 0.272386
[01:40:44.537] iteration 2081 : loss : 0.414118, loss_ce: 0.290484
[01:40:44.792] iteration 2082 : loss : 0.422598, loss_ce: 0.278007
[01:40:45.067] iteration 2083 : loss : 0.405303, loss_ce: 0.289620
[01:40:45.324] iteration 2084 : loss : 0.390424, loss_ce: 0.294088
[01:40:46.397] iteration 2085 : loss : 0.478056, loss_ce: 0.312784
[01:40:46.654] iteration 2086 : loss : 0.360520, loss_ce: 0.236787
[01:40:46.910] iteration 2087 : loss : 0.451768, loss_ce: 0.327442
[01:40:47.164] iteration 2088 : loss : 0.503799, loss_ce: 0.342438
[01:40:47.418] iteration 2089 : loss : 0.484392, loss_ce: 0.300649
[01:40:47.675] iteration 2090 : loss : 0.499546, loss_ce: 0.269355
[01:40:48.197] iteration 2091 : loss : 0.455615, loss_ce: 0.227432
[01:40:48.457] iteration 2092 : loss : 0.480418, loss_ce: 0.379248
[01:40:49.214] iteration 2093 : loss : 0.497184, loss_ce: 0.382001
[01:40:49.471] iteration 2094 : loss : 0.417648, loss_ce: 0.231383
[01:40:49.724] iteration 2095 : loss : 0.576502, loss_ce: 0.470108
[01:40:49.980] iteration 2096 : loss : 0.492031, loss_ce: 0.332018
[01:40:50.236] iteration 2097 : loss : 0.347126, loss_ce: 0.325221
[01:40:50.490] iteration 2098 : loss : 0.470639, loss_ce: 0.280257
[01:40:51.210] iteration 2099 : loss : 0.519308, loss_ce: 0.404011
[01:40:51.469] iteration 2100 : loss : 0.436531, loss_ce: 0.274110
[01:40:52.062] iteration 2101 : loss : 0.416604, loss_ce: 0.298644
[01:40:52.367] iteration 2102 : loss : 0.471015, loss_ce: 0.333915
[01:40:52.622] iteration 2103 : loss : 0.440754, loss_ce: 0.371675
[01:40:52.876] iteration 2104 : loss : 0.518177, loss_ce: 0.341661
[01:40:53.129] iteration 2105 : loss : 0.448646, loss_ce: 0.388817
[01:40:53.382] iteration 2106 : loss : 0.503914, loss_ce: 0.336186
[01:40:54.344] iteration 2107 : loss : 0.478636, loss_ce: 0.351647
[01:40:54.600] iteration 2108 : loss : 0.488282, loss_ce: 0.394473
[01:40:54.918] iteration 2109 : loss : 0.444058, loss_ce: 0.365252
[01:40:55.219] iteration 2110 : loss : 0.439170, loss_ce: 0.297872
[01:40:55.472] iteration 2111 : loss : 0.441088, loss_ce: 0.280942
[01:40:55.726] iteration 2112 : loss : 0.489713, loss_ce: 0.370435
[01:40:55.983] iteration 2113 : loss : 0.388983, loss_ce: 0.264978
[01:40:56.240] iteration 2114 : loss : 0.463315, loss_ce: 0.362861
[01:40:57.523] iteration 2115 : loss : 0.413485, loss_ce: 0.293669
[01:40:57.869] iteration 2116 : loss : 0.440186, loss_ce: 0.342896
[01:40:58.200] iteration 2117 : loss : 0.470460, loss_ce: 0.392759
[01:40:58.453] iteration 2118 : loss : 0.324242, loss_ce: 0.249346
[01:40:58.708] iteration 2119 : loss : 0.400957, loss_ce: 0.310709
[01:40:58.963] iteration 2120 : loss : 0.486135, loss_ce: 0.410848
[01:40:59.220] iteration 2121 : loss : 0.337332, loss_ce: 0.214112
[01:40:59.475] iteration 2122 : loss : 0.401982, loss_ce: 0.302355
[01:41:00.693] iteration 2123 : loss : 0.411032, loss_ce: 0.337876
[01:41:00.949] iteration 2124 : loss : 0.484035, loss_ce: 0.345165
[01:41:01.207] iteration 2125 : loss : 0.574948, loss_ce: 0.476715
[01:41:01.460] iteration 2126 : loss : 0.524377, loss_ce: 0.340242
[01:41:01.713] iteration 2127 : loss : 0.343334, loss_ce: 0.295643
[01:41:01.970] iteration 2128 : loss : 0.391812, loss_ce: 0.244389
[01:41:02.226] iteration 2129 : loss : 0.451196, loss_ce: 0.351299
[01:41:02.480] iteration 2130 : loss : 0.448118, loss_ce: 0.427371
[01:41:03.846] iteration 2131 : loss : 0.422092, loss_ce: 0.280422
[01:41:04.100] iteration 2132 : loss : 0.432022, loss_ce: 0.326206
[01:41:04.356] iteration 2133 : loss : 0.411905, loss_ce: 0.272010
[01:41:04.614] iteration 2134 : loss : 0.515351, loss_ce: 0.395447
[01:41:04.869] iteration 2135 : loss : 0.503471, loss_ce: 0.361283
[01:41:05.128] iteration 2136 : loss : 0.491806, loss_ce: 0.387053
[01:41:05.385] iteration 2137 : loss : 0.496410, loss_ce: 0.347186
[01:41:05.639] iteration 2138 : loss : 0.397588, loss_ce: 0.329842
[01:41:06.911] iteration 2139 : loss : 0.502546, loss_ce: 0.332031
[01:41:07.168] iteration 2140 : loss : 0.484964, loss_ce: 0.371841
[01:41:07.425] iteration 2141 : loss : 0.426225, loss_ce: 0.252630
[01:41:07.683] iteration 2142 : loss : 0.483872, loss_ce: 0.389712
[01:41:07.936] iteration 2143 : loss : 0.627169, loss_ce: 0.621544
[01:41:08.192] iteration 2144 : loss : 0.438054, loss_ce: 0.241991
[01:41:08.446] iteration 2145 : loss : 0.401922, loss_ce: 0.256963
[01:41:08.702] iteration 2146 : loss : 0.486217, loss_ce: 0.356189
[01:41:09.972] iteration 2147 : loss : 0.475486, loss_ce: 0.303141
[01:41:10.230] iteration 2148 : loss : 0.535954, loss_ce: 0.485937
[01:41:10.490] iteration 2149 : loss : 0.527429, loss_ce: 0.464189
[01:41:10.744] iteration 2150 : loss : 0.435743, loss_ce: 0.261940
[01:41:10.999] iteration 2151 : loss : 0.518753, loss_ce: 0.469640
[01:41:11.257] iteration 2152 : loss : 0.468126, loss_ce: 0.318113
[01:41:11.511] iteration 2153 : loss : 0.476194, loss_ce: 0.234964
[01:41:11.780] iteration 2154 : loss : 0.431529, loss_ce: 0.414517
[01:41:13.143] iteration 2155 : loss : 0.436849, loss_ce: 0.312853
[01:41:13.400] iteration 2156 : loss : 0.433669, loss_ce: 0.376859
[01:41:13.654] iteration 2157 : loss : 0.482552, loss_ce: 0.332649
[01:41:13.908] iteration 2158 : loss : 0.516524, loss_ce: 0.425369
[01:41:14.164] iteration 2159 : loss : 0.463390, loss_ce: 0.317686
[01:41:14.434] iteration 2160 : loss : 0.539132, loss_ce: 0.454084
[01:41:14.689] iteration 2161 : loss : 0.468505, loss_ce: 0.326712
[01:41:14.944] iteration 2162 : loss : 0.379991, loss_ce: 0.344122
[01:41:16.189] iteration 2163 : loss : 0.403922, loss_ce: 0.273584
[01:41:16.444] iteration 2164 : loss : 0.390069, loss_ce: 0.337059
[01:41:16.698] iteration 2165 : loss : 0.413460, loss_ce: 0.304036
[01:41:16.954] iteration 2166 : loss : 0.388060, loss_ce: 0.257190
[01:41:17.207] iteration 2167 : loss : 0.428181, loss_ce: 0.268635
[01:41:17.460] iteration 2168 : loss : 0.535201, loss_ce: 0.357345
[01:41:17.714] iteration 2169 : loss : 0.406750, loss_ce: 0.262288
[01:41:17.971] iteration 2170 : loss : 0.455320, loss_ce: 0.333503
[01:41:19.282] iteration 2171 : loss : 0.443640, loss_ce: 0.379186
[01:41:19.536] iteration 2172 : loss : 0.471308, loss_ce: 0.355849
[01:41:19.794] iteration 2173 : loss : 0.422499, loss_ce: 0.327859
[01:41:20.050] iteration 2174 : loss : 0.493588, loss_ce: 0.326510
[01:41:20.305] iteration 2175 : loss : 0.494169, loss_ce: 0.396430
[01:41:20.558] iteration 2176 : loss : 0.478033, loss_ce: 0.325397
[01:41:20.811] iteration 2177 : loss : 0.363128, loss_ce: 0.337443
[01:41:21.073] iteration 2178 : loss : 0.358880, loss_ce: 0.256015
[01:41:22.324] iteration 2179 : loss : 0.469306, loss_ce: 0.264713
[01:41:22.582] iteration 2180 : loss : 0.351163, loss_ce: 0.249902
[01:41:22.835] iteration 2181 : loss : 0.417000, loss_ce: 0.293986
[01:41:23.089] iteration 2182 : loss : 0.492149, loss_ce: 0.427961
[01:41:23.341] iteration 2183 : loss : 0.484718, loss_ce: 0.360014
[01:41:23.612] iteration 2184 : loss : 0.485998, loss_ce: 0.363399
[01:41:23.870] iteration 2185 : loss : 0.453552, loss_ce: 0.355834
[01:41:24.276] iteration 2186 : loss : 0.510141, loss_ce: 0.343433
[01:41:25.274] iteration 2187 : loss : 0.526177, loss_ce: 0.409724
[01:41:25.527] iteration 2188 : loss : 0.463252, loss_ce: 0.327922
[01:41:25.778] iteration 2189 : loss : 0.496017, loss_ce: 0.288540
[01:41:26.033] iteration 2190 : loss : 0.425555, loss_ce: 0.345630
[01:41:26.286] iteration 2191 : loss : 0.354835, loss_ce: 0.239102
[01:41:26.540] iteration 2192 : loss : 0.387162, loss_ce: 0.239446
[01:41:26.792] iteration 2193 : loss : 0.335305, loss_ce: 0.252427
[01:41:27.043] iteration 2194 : loss : 0.498233, loss_ce: 0.345960
[01:41:28.328] iteration 2195 : loss : 0.477526, loss_ce: 0.404097
[01:41:28.582] iteration 2196 : loss : 0.404239, loss_ce: 0.216926
[01:41:28.835] iteration 2197 : loss : 0.388985, loss_ce: 0.264822
[01:41:29.088] iteration 2198 : loss : 0.477275, loss_ce: 0.397088
[01:41:29.340] iteration 2199 : loss : 0.544622, loss_ce: 0.417360
[01:41:29.544] iteration 2200 : loss : 0.612673, loss_ce: 0.424808
[01:41:34.349] iteration 2201 : loss : 0.489216, loss_ce: 0.288314
[01:41:34.602] iteration 2202 : loss : 0.395635, loss_ce: 0.239375
[01:41:34.856] iteration 2203 : loss : 0.467165, loss_ce: 0.300231
[01:41:35.109] iteration 2204 : loss : 0.420092, loss_ce: 0.305661
[01:41:35.367] iteration 2205 : loss : 0.464607, loss_ce: 0.331171
[01:41:35.623] iteration 2206 : loss : 0.496952, loss_ce: 0.239695
[01:41:35.878] iteration 2207 : loss : 0.433576, loss_ce: 0.300769
[01:41:36.132] iteration 2208 : loss : 0.406862, loss_ce: 0.258501
[01:41:37.324] iteration 2209 : loss : 0.455545, loss_ce: 0.381505
[01:41:37.580] iteration 2210 : loss : 0.382467, loss_ce: 0.319136
[01:41:37.833] iteration 2211 : loss : 0.422571, loss_ce: 0.309582
[01:41:38.087] iteration 2212 : loss : 0.388824, loss_ce: 0.293151
[01:41:38.341] iteration 2213 : loss : 0.516062, loss_ce: 0.437915
[01:41:38.595] iteration 2214 : loss : 0.410152, loss_ce: 0.298793
[01:41:38.847] iteration 2215 : loss : 0.427957, loss_ce: 0.278053
[01:41:39.100] iteration 2216 : loss : 0.363690, loss_ce: 0.199166
[01:41:40.228] iteration 2217 : loss : 0.428229, loss_ce: 0.314681
[01:41:40.484] iteration 2218 : loss : 0.467614, loss_ce: 0.308299
[01:41:40.739] iteration 2219 : loss : 0.461940, loss_ce: 0.329445
[01:41:40.992] iteration 2220 : loss : 0.445423, loss_ce: 0.399684
[01:41:41.248] iteration 2221 : loss : 0.446259, loss_ce: 0.350101
[01:41:41.502] iteration 2222 : loss : 0.534391, loss_ce: 0.437753
[01:41:41.758] iteration 2223 : loss : 0.404290, loss_ce: 0.340914
[01:41:42.015] iteration 2224 : loss : 0.546936, loss_ce: 0.428234
[01:41:43.174] iteration 2225 : loss : 0.514013, loss_ce: 0.406919
[01:41:43.427] iteration 2226 : loss : 0.360422, loss_ce: 0.332922
[01:41:43.680] iteration 2227 : loss : 0.420943, loss_ce: 0.393151
[01:41:43.935] iteration 2228 : loss : 0.459642, loss_ce: 0.307437
[01:41:44.190] iteration 2229 : loss : 0.496309, loss_ce: 0.272247
[01:41:44.445] iteration 2230 : loss : 0.436095, loss_ce: 0.307054
[01:41:44.698] iteration 2231 : loss : 0.492557, loss_ce: 0.271159
[01:41:44.952] iteration 2232 : loss : 0.436342, loss_ce: 0.287056
[01:41:46.147] iteration 2233 : loss : 0.340906, loss_ce: 0.281890
[01:41:46.401] iteration 2234 : loss : 0.354963, loss_ce: 0.198145
[01:41:46.656] iteration 2235 : loss : 0.439364, loss_ce: 0.306066
[01:41:46.910] iteration 2236 : loss : 0.471137, loss_ce: 0.404863
[01:41:47.164] iteration 2237 : loss : 0.348426, loss_ce: 0.202312
[01:41:47.416] iteration 2238 : loss : 0.441514, loss_ce: 0.310419
[01:41:47.672] iteration 2239 : loss : 0.317572, loss_ce: 0.263397
[01:41:47.927] iteration 2240 : loss : 0.490419, loss_ce: 0.409952
[01:41:49.043] iteration 2241 : loss : 0.286621, loss_ce: 0.233877
[01:41:49.299] iteration 2242 : loss : 0.465433, loss_ce: 0.278229
[01:41:49.556] iteration 2243 : loss : 0.561776, loss_ce: 0.399836
[01:41:49.810] iteration 2244 : loss : 0.450159, loss_ce: 0.372199
[01:41:50.065] iteration 2245 : loss : 0.498363, loss_ce: 0.296091
[01:41:50.321] iteration 2246 : loss : 0.519120, loss_ce: 0.307629
[01:41:50.577] iteration 2247 : loss : 0.417212, loss_ce: 0.315080
[01:41:50.832] iteration 2248 : loss : 0.488217, loss_ce: 0.357789
[01:41:52.042] iteration 2249 : loss : 0.479950, loss_ce: 0.416008
[01:41:52.371] iteration 2250 : loss : 0.360246, loss_ce: 0.361928
[01:41:52.627] iteration 2251 : loss : 0.421069, loss_ce: 0.324359
[01:41:52.882] iteration 2252 : loss : 0.397375, loss_ce: 0.264810
[01:41:53.136] iteration 2253 : loss : 0.428557, loss_ce: 0.371759
[01:41:53.391] iteration 2254 : loss : 0.462493, loss_ce: 0.361776
[01:41:53.646] iteration 2255 : loss : 0.453353, loss_ce: 0.312219
[01:41:53.901] iteration 2256 : loss : 0.386218, loss_ce: 0.312684
[01:41:55.071] iteration 2257 : loss : 0.412683, loss_ce: 0.260116
[01:41:55.367] iteration 2258 : loss : 0.356911, loss_ce: 0.247850
[01:41:55.620] iteration 2259 : loss : 0.415581, loss_ce: 0.302928
[01:41:55.874] iteration 2260 : loss : 0.473103, loss_ce: 0.323962
[01:41:56.130] iteration 2261 : loss : 0.357418, loss_ce: 0.321740
[01:41:56.387] iteration 2262 : loss : 0.411768, loss_ce: 0.328902
[01:41:56.641] iteration 2263 : loss : 0.507651, loss_ce: 0.343680
[01:41:56.895] iteration 2264 : loss : 0.491583, loss_ce: 0.340812
[01:41:57.950] iteration 2265 : loss : 0.433390, loss_ce: 0.251546
[01:41:58.310] iteration 2266 : loss : 0.479466, loss_ce: 0.398465
[01:41:58.566] iteration 2267 : loss : 0.469715, loss_ce: 0.333823
[01:41:58.818] iteration 2268 : loss : 0.375568, loss_ce: 0.287777
[01:41:59.072] iteration 2269 : loss : 0.463409, loss_ce: 0.358107
[01:41:59.325] iteration 2270 : loss : 0.466525, loss_ce: 0.283009
[01:41:59.580] iteration 2271 : loss : 0.369467, loss_ce: 0.191567
[01:41:59.833] iteration 2272 : loss : 0.404919, loss_ce: 0.297068
[01:42:00.990] iteration 2273 : loss : 0.476692, loss_ce: 0.359004
[01:42:01.330] iteration 2274 : loss : 0.442534, loss_ce: 0.307652
[01:42:01.582] iteration 2275 : loss : 0.349104, loss_ce: 0.228067
[01:42:01.837] iteration 2276 : loss : 0.508957, loss_ce: 0.440711
[01:42:02.091] iteration 2277 : loss : 0.523497, loss_ce: 0.346755
[01:42:02.347] iteration 2278 : loss : 0.454039, loss_ce: 0.339030
[01:42:02.600] iteration 2279 : loss : 0.358023, loss_ce: 0.219916
[01:42:02.853] iteration 2280 : loss : 0.478233, loss_ce: 0.339552
[01:42:03.933] iteration 2281 : loss : 0.471427, loss_ce: 0.330309
[01:42:04.305] iteration 2282 : loss : 0.364707, loss_ce: 0.230603
[01:42:04.559] iteration 2283 : loss : 0.475735, loss_ce: 0.332628
[01:42:04.813] iteration 2284 : loss : 0.452794, loss_ce: 0.370216
[01:42:05.074] iteration 2285 : loss : 0.503104, loss_ce: 0.362418
[01:42:05.332] iteration 2286 : loss : 0.362706, loss_ce: 0.246383
[01:42:05.586] iteration 2287 : loss : 0.421549, loss_ce: 0.257321
[01:42:05.841] iteration 2288 : loss : 0.478049, loss_ce: 0.322824
[01:42:06.998] iteration 2289 : loss : 0.402736, loss_ce: 0.213343
[01:42:07.492] iteration 2290 : loss : 0.439540, loss_ce: 0.235452
[01:42:07.818] iteration 2291 : loss : 0.341538, loss_ce: 0.243770
[01:42:08.072] iteration 2292 : loss : 0.478819, loss_ce: 0.306905
[01:42:08.327] iteration 2293 : loss : 0.542792, loss_ce: 0.394804
[01:42:08.584] iteration 2294 : loss : 0.431403, loss_ce: 0.276725
[01:42:08.840] iteration 2295 : loss : 0.469508, loss_ce: 0.371673
[01:42:09.095] iteration 2296 : loss : 0.507720, loss_ce: 0.441617
[01:42:10.164] iteration 2297 : loss : 0.402258, loss_ce: 0.259975
[01:42:10.523] iteration 2298 : loss : 0.428129, loss_ce: 0.327544
[01:42:10.777] iteration 2299 : loss : 0.396929, loss_ce: 0.349366
[01:42:11.033] iteration 2300 : loss : 0.405856, loss_ce: 0.242986
[01:42:11.290] iteration 2301 : loss : 0.343092, loss_ce: 0.214434
[01:42:11.545] iteration 2302 : loss : 0.480444, loss_ce: 0.304837
[01:42:11.802] iteration 2303 : loss : 0.413320, loss_ce: 0.221340
[01:42:12.058] iteration 2304 : loss : 0.459140, loss_ce: 0.435688
[01:42:13.098] iteration 2305 : loss : 0.401854, loss_ce: 0.321800
[01:42:13.427] iteration 2306 : loss : 0.454928, loss_ce: 0.340571
[01:42:13.681] iteration 2307 : loss : 0.471673, loss_ce: 0.232132
[01:42:13.971] iteration 2308 : loss : 0.452682, loss_ce: 0.332047
[01:42:14.225] iteration 2309 : loss : 0.396639, loss_ce: 0.275074
[01:42:14.480] iteration 2310 : loss : 0.495914, loss_ce: 0.412907
[01:42:14.735] iteration 2311 : loss : 0.529042, loss_ce: 0.376767
[01:42:14.988] iteration 2312 : loss : 0.453065, loss_ce: 0.372040
[01:42:16.033] iteration 2313 : loss : 0.405591, loss_ce: 0.336248
[01:42:16.542] iteration 2314 : loss : 0.449173, loss_ce: 0.292554
[01:42:16.797] iteration 2315 : loss : 0.498607, loss_ce: 0.383259
[01:42:17.054] iteration 2316 : loss : 0.448864, loss_ce: 0.288878
[01:42:17.495] iteration 2317 : loss : 0.458614, loss_ce: 0.286804
[01:42:17.750] iteration 2318 : loss : 0.483816, loss_ce: 0.393947
[01:42:18.006] iteration 2319 : loss : 0.438462, loss_ce: 0.304704
[01:42:18.265] iteration 2320 : loss : 0.461208, loss_ce: 0.370635
[01:42:19.003] iteration 2321 : loss : 0.397035, loss_ce: 0.282431
[01:42:19.634] iteration 2322 : loss : 0.484171, loss_ce: 0.327221
[01:42:19.890] iteration 2323 : loss : 0.468055, loss_ce: 0.329085
[01:42:20.143] iteration 2324 : loss : 0.443563, loss_ce: 0.230117
[01:42:20.398] iteration 2325 : loss : 0.438796, loss_ce: 0.362906
[01:42:20.652] iteration 2326 : loss : 0.329525, loss_ce: 0.205706
[01:42:20.907] iteration 2327 : loss : 0.393747, loss_ce: 0.270957
[01:42:21.160] iteration 2328 : loss : 0.478900, loss_ce: 0.386433
[01:42:22.168] iteration 2329 : loss : 0.399919, loss_ce: 0.276539
[01:42:22.738] iteration 2330 : loss : 0.500864, loss_ce: 0.332213
[01:42:22.994] iteration 2331 : loss : 0.398130, loss_ce: 0.323179
[01:42:23.249] iteration 2332 : loss : 0.429611, loss_ce: 0.262130
[01:42:23.504] iteration 2333 : loss : 0.441545, loss_ce: 0.289763
[01:42:23.759] iteration 2334 : loss : 0.482254, loss_ce: 0.324215
[01:42:24.016] iteration 2335 : loss : 0.341667, loss_ce: 0.216935
[01:42:24.273] iteration 2336 : loss : 0.501163, loss_ce: 0.372910
[01:42:25.207] iteration 2337 : loss : 0.462529, loss_ce: 0.363163
[01:42:25.815] iteration 2338 : loss : 0.338609, loss_ce: 0.194287
[01:42:26.060] iteration 2339 : loss : 0.358162, loss_ce: 0.231763
[01:42:26.297] iteration 2340 : loss : 0.462029, loss_ce: 0.328274
[01:42:26.553] iteration 2341 : loss : 0.435761, loss_ce: 0.305340
[01:42:26.807] iteration 2342 : loss : 0.444497, loss_ce: 0.225367
[01:42:27.061] iteration 2343 : loss : 0.415320, loss_ce: 0.289827
[01:42:27.316] iteration 2344 : loss : 0.408700, loss_ce: 0.294497
[01:42:28.269] iteration 2345 : loss : 0.395635, loss_ce: 0.243705
[01:42:28.897] iteration 2346 : loss : 0.456254, loss_ce: 0.347037
[01:42:29.152] iteration 2347 : loss : 0.389641, loss_ce: 0.244642
[01:42:29.406] iteration 2348 : loss : 0.372407, loss_ce: 0.271497
[01:42:29.659] iteration 2349 : loss : 0.571299, loss_ce: 0.539911
[01:42:29.912] iteration 2350 : loss : 0.445784, loss_ce: 0.300179
[01:42:30.167] iteration 2351 : loss : 0.442882, loss_ce: 0.281255
[01:42:30.420] iteration 2352 : loss : 0.491733, loss_ce: 0.341392
[01:42:31.319] iteration 2353 : loss : 0.369713, loss_ce: 0.323754
[01:42:31.920] iteration 2354 : loss : 0.479591, loss_ce: 0.371057
[01:42:32.175] iteration 2355 : loss : 0.453158, loss_ce: 0.255864
[01:42:32.428] iteration 2356 : loss : 0.447863, loss_ce: 0.323396
[01:42:32.683] iteration 2357 : loss : 0.440671, loss_ce: 0.329384
[01:42:32.937] iteration 2358 : loss : 0.398295, loss_ce: 0.301637
[01:42:33.191] iteration 2359 : loss : 0.519389, loss_ce: 0.363031
[01:42:33.444] iteration 2360 : loss : 0.425956, loss_ce: 0.279634
[01:42:34.308] iteration 2361 : loss : 0.408246, loss_ce: 0.289361
[01:42:34.908] iteration 2362 : loss : 0.506377, loss_ce: 0.386902
[01:42:35.162] iteration 2363 : loss : 0.440610, loss_ce: 0.291259
[01:42:35.416] iteration 2364 : loss : 0.427447, loss_ce: 0.290095
[01:42:35.672] iteration 2365 : loss : 0.516058, loss_ce: 0.268491
[01:42:35.926] iteration 2366 : loss : 0.410917, loss_ce: 0.301926
[01:42:36.179] iteration 2367 : loss : 0.503496, loss_ce: 0.337769
[01:42:36.436] iteration 2368 : loss : 0.442263, loss_ce: 0.259418
[01:42:37.198] iteration 2369 : loss : 0.333444, loss_ce: 0.290329
[01:42:37.812] iteration 2370 : loss : 0.571669, loss_ce: 0.545519
[01:42:38.066] iteration 2371 : loss : 0.459838, loss_ce: 0.379722
[01:42:38.319] iteration 2372 : loss : 0.406668, loss_ce: 0.217677
[01:42:38.573] iteration 2373 : loss : 0.552163, loss_ce: 0.513820
[01:42:38.828] iteration 2374 : loss : 0.438705, loss_ce: 0.377122
[01:42:39.082] iteration 2375 : loss : 0.479154, loss_ce: 0.327743
[01:42:39.337] iteration 2376 : loss : 0.291145, loss_ce: 0.230381
[01:42:40.227] iteration 2377 : loss : 0.457009, loss_ce: 0.322231
[01:42:40.848] iteration 2378 : loss : 0.309840, loss_ce: 0.280214
[01:42:41.109] iteration 2379 : loss : 0.482084, loss_ce: 0.396217
[01:42:41.412] iteration 2380 : loss : 0.485874, loss_ce: 0.299727
[01:42:41.729] iteration 2381 : loss : 0.512395, loss_ce: 0.313338
[01:42:42.022] iteration 2382 : loss : 0.491498, loss_ce: 0.335656
[01:42:42.325] iteration 2383 : loss : 0.441107, loss_ce: 0.326312
[01:42:42.662] iteration 2384 : loss : 0.365855, loss_ce: 0.353249
[01:42:43.392] iteration 2385 : loss : 0.461699, loss_ce: 0.281270
[01:42:43.971] iteration 2386 : loss : 0.480544, loss_ce: 0.336198
[01:42:44.227] iteration 2387 : loss : 0.465037, loss_ce: 0.318157
[01:42:44.482] iteration 2388 : loss : 0.461594, loss_ce: 0.386382
[01:42:44.736] iteration 2389 : loss : 0.379883, loss_ce: 0.258140
[01:42:44.990] iteration 2390 : loss : 0.400939, loss_ce: 0.321655
[01:42:45.246] iteration 2391 : loss : 0.424211, loss_ce: 0.304746
[01:42:45.500] iteration 2392 : loss : 0.458259, loss_ce: 0.318522
[01:42:46.541] iteration 2393 : loss : 0.410641, loss_ce: 0.289816
[01:42:47.023] iteration 2394 : loss : 0.442615, loss_ce: 0.346623
[01:42:47.276] iteration 2395 : loss : 0.461170, loss_ce: 0.335858
[01:42:47.534] iteration 2396 : loss : 0.529843, loss_ce: 0.343333
[01:42:47.789] iteration 2397 : loss : 0.452521, loss_ce: 0.300424
[01:42:48.046] iteration 2398 : loss : 0.337428, loss_ce: 0.226830
[01:42:48.302] iteration 2399 : loss : 0.519143, loss_ce: 0.347315
[01:42:48.567] iteration 2400 : loss : 0.486634, loss_ce: 0.342315
[01:42:49.557] iteration 2401 : loss : 0.494310, loss_ce: 0.320689
[01:42:49.987] iteration 2402 : loss : 0.421598, loss_ce: 0.370561
[01:42:50.242] iteration 2403 : loss : 0.388022, loss_ce: 0.192629
[01:42:50.496] iteration 2404 : loss : 0.461540, loss_ce: 0.353048
[01:42:50.751] iteration 2405 : loss : 0.353565, loss_ce: 0.215289
[01:42:51.004] iteration 2406 : loss : 0.489849, loss_ce: 0.373549
[01:42:51.257] iteration 2407 : loss : 0.421562, loss_ce: 0.357372
[01:42:51.515] iteration 2408 : loss : 0.483514, loss_ce: 0.399451
[01:42:52.504] iteration 2409 : loss : 0.419681, loss_ce: 0.346559
[01:42:52.879] iteration 2410 : loss : 0.441735, loss_ce: 0.338876
[01:42:53.132] iteration 2411 : loss : 0.329971, loss_ce: 0.242541
[01:42:53.386] iteration 2412 : loss : 0.373494, loss_ce: 0.264553
[01:42:53.639] iteration 2413 : loss : 0.400192, loss_ce: 0.282984
[01:42:53.893] iteration 2414 : loss : 0.471284, loss_ce: 0.379913
[01:42:54.151] iteration 2415 : loss : 0.497669, loss_ce: 0.344156
[01:42:54.405] iteration 2416 : loss : 0.503487, loss_ce: 0.465592
[01:42:55.374] iteration 2417 : loss : 0.564509, loss_ce: 0.456948
[01:42:55.730] iteration 2418 : loss : 0.436517, loss_ce: 0.279920
[01:42:56.013] iteration 2419 : loss : 0.526585, loss_ce: 0.362628
[01:42:56.239] iteration 2420 : loss : 0.554629, loss_ce: 0.228024
[01:43:01.070] iteration 2421 : loss : 0.435399, loss_ce: 0.259307
[01:43:01.351] iteration 2422 : loss : 0.428075, loss_ce: 0.340664
[01:43:01.610] iteration 2423 : loss : 0.442107, loss_ce: 0.283101
[01:43:01.864] iteration 2424 : loss : 0.483646, loss_ce: 0.441892
[01:43:02.117] iteration 2425 : loss : 0.494746, loss_ce: 0.382545
[01:43:02.371] iteration 2426 : loss : 0.400139, loss_ce: 0.237203
[01:43:02.624] iteration 2427 : loss : 0.411671, loss_ce: 0.269068
[01:43:02.877] iteration 2428 : loss : 0.505776, loss_ce: 0.301264
[01:43:04.207] iteration 2429 : loss : 0.454228, loss_ce: 0.313285
[01:43:04.462] iteration 2430 : loss : 0.511252, loss_ce: 0.366334
[01:43:04.716] iteration 2431 : loss : 0.408780, loss_ce: 0.278269
[01:43:04.969] iteration 2432 : loss : 0.519480, loss_ce: 0.408956
[01:43:05.227] iteration 2433 : loss : 0.443024, loss_ce: 0.293962
[01:43:05.482] iteration 2434 : loss : 0.461866, loss_ce: 0.297361
[01:43:05.739] iteration 2435 : loss : 0.466015, loss_ce: 0.296440
[01:43:05.995] iteration 2436 : loss : 0.357461, loss_ce: 0.219891
[01:43:07.281] iteration 2437 : loss : 0.382236, loss_ce: 0.354334
[01:43:07.537] iteration 2438 : loss : 0.444506, loss_ce: 0.274868
[01:43:07.794] iteration 2439 : loss : 0.367498, loss_ce: 0.313916
[01:43:08.048] iteration 2440 : loss : 0.469469, loss_ce: 0.273442
[01:43:08.303] iteration 2441 : loss : 0.493638, loss_ce: 0.335603
[01:43:08.556] iteration 2442 : loss : 0.308744, loss_ce: 0.199377
[01:43:08.810] iteration 2443 : loss : 0.511498, loss_ce: 0.392765
[01:43:09.063] iteration 2444 : loss : 0.348891, loss_ce: 0.316240
[01:43:10.300] iteration 2445 : loss : 0.379026, loss_ce: 0.257407
[01:43:10.552] iteration 2446 : loss : 0.409468, loss_ce: 0.288076
[01:43:10.805] iteration 2447 : loss : 0.401202, loss_ce: 0.286921
[01:43:11.253] iteration 2448 : loss : 0.396422, loss_ce: 0.223135
[01:43:11.507] iteration 2449 : loss : 0.419700, loss_ce: 0.323387
[01:43:11.760] iteration 2450 : loss : 0.548716, loss_ce: 0.371048
[01:43:12.013] iteration 2451 : loss : 0.402562, loss_ce: 0.273865
[01:43:12.267] iteration 2452 : loss : 0.370215, loss_ce: 0.240604
[01:43:13.295] iteration 2453 : loss : 0.354508, loss_ce: 0.238290
[01:43:13.548] iteration 2454 : loss : 0.424981, loss_ce: 0.253342
[01:43:13.800] iteration 2455 : loss : 0.459842, loss_ce: 0.320069
[01:43:14.053] iteration 2456 : loss : 0.360870, loss_ce: 0.215258
[01:43:14.307] iteration 2457 : loss : 0.544638, loss_ce: 0.476838
[01:43:14.562] iteration 2458 : loss : 0.469791, loss_ce: 0.316264
[01:43:14.814] iteration 2459 : loss : 0.400061, loss_ce: 0.259086
[01:43:15.070] iteration 2460 : loss : 0.371357, loss_ce: 0.311555
[01:43:16.328] iteration 2461 : loss : 0.437250, loss_ce: 0.302115
[01:43:16.636] iteration 2462 : loss : 0.542093, loss_ce: 0.306100
[01:43:16.929] iteration 2463 : loss : 0.427856, loss_ce: 0.298440
[01:43:17.285] iteration 2464 : loss : 0.433557, loss_ce: 0.348686
[01:43:17.589] iteration 2465 : loss : 0.453440, loss_ce: 0.430070
[01:43:17.842] iteration 2466 : loss : 0.376670, loss_ce: 0.269788
[01:43:18.098] iteration 2467 : loss : 0.376911, loss_ce: 0.271056
[01:43:18.351] iteration 2468 : loss : 0.488001, loss_ce: 0.291537
[01:43:19.437] iteration 2469 : loss : 0.438893, loss_ce: 0.363231
[01:43:19.691] iteration 2470 : loss : 0.415762, loss_ce: 0.265289
[01:43:19.945] iteration 2471 : loss : 0.367679, loss_ce: 0.266028
[01:43:20.200] iteration 2472 : loss : 0.436021, loss_ce: 0.307433
[01:43:20.454] iteration 2473 : loss : 0.453895, loss_ce: 0.291017
[01:43:20.708] iteration 2474 : loss : 0.437139, loss_ce: 0.286819
[01:43:20.962] iteration 2475 : loss : 0.469875, loss_ce: 0.297476
[01:43:21.218] iteration 2476 : loss : 0.356494, loss_ce: 0.240976
[01:43:22.531] iteration 2477 : loss : 0.331452, loss_ce: 0.202708
[01:43:22.790] iteration 2478 : loss : 0.439794, loss_ce: 0.308985
[01:43:23.045] iteration 2479 : loss : 0.425581, loss_ce: 0.295367
[01:43:23.298] iteration 2480 : loss : 0.380884, loss_ce: 0.212962
[01:43:23.555] iteration 2481 : loss : 0.410175, loss_ce: 0.334334
[01:43:23.817] iteration 2482 : loss : 0.431886, loss_ce: 0.347983
[01:43:24.077] iteration 2483 : loss : 0.426929, loss_ce: 0.280910
[01:43:24.332] iteration 2484 : loss : 0.439504, loss_ce: 0.363856
[01:43:25.586] iteration 2485 : loss : 0.537445, loss_ce: 0.422222
[01:43:25.843] iteration 2486 : loss : 0.431903, loss_ce: 0.292448
[01:43:26.100] iteration 2487 : loss : 0.505929, loss_ce: 0.418976
[01:43:26.355] iteration 2488 : loss : 0.471942, loss_ce: 0.250951
[01:43:26.611] iteration 2489 : loss : 0.524622, loss_ce: 0.395673
[01:43:26.866] iteration 2490 : loss : 0.468602, loss_ce: 0.339908
[01:43:27.123] iteration 2491 : loss : 0.456507, loss_ce: 0.311895
[01:43:27.380] iteration 2492 : loss : 0.347888, loss_ce: 0.221514
[01:43:28.690] iteration 2493 : loss : 0.458015, loss_ce: 0.338800
[01:43:28.947] iteration 2494 : loss : 0.508596, loss_ce: 0.387335
[01:43:29.201] iteration 2495 : loss : 0.460226, loss_ce: 0.311840
[01:43:29.464] iteration 2496 : loss : 0.438340, loss_ce: 0.345141
[01:43:29.722] iteration 2497 : loss : 0.487924, loss_ce: 0.340475
[01:43:29.977] iteration 2498 : loss : 0.427498, loss_ce: 0.347771
[01:43:30.231] iteration 2499 : loss : 0.439056, loss_ce: 0.269252
[01:43:30.486] iteration 2500 : loss : 0.469012, loss_ce: 0.327303
[01:43:31.732] iteration 2501 : loss : 0.374517, loss_ce: 0.352145
[01:43:31.988] iteration 2502 : loss : 0.397460, loss_ce: 0.318460
[01:43:32.242] iteration 2503 : loss : 0.386278, loss_ce: 0.355583
[01:43:32.497] iteration 2504 : loss : 0.419855, loss_ce: 0.279446
[01:43:32.756] iteration 2505 : loss : 0.446143, loss_ce: 0.341646
[01:43:33.012] iteration 2506 : loss : 0.369105, loss_ce: 0.306979
[01:43:33.268] iteration 2507 : loss : 0.400737, loss_ce: 0.255763
[01:43:33.522] iteration 2508 : loss : 0.471078, loss_ce: 0.310137
[01:43:34.771] iteration 2509 : loss : 0.418427, loss_ce: 0.184331
[01:43:35.044] iteration 2510 : loss : 0.420482, loss_ce: 0.336728
[01:43:35.301] iteration 2511 : loss : 0.421284, loss_ce: 0.302920
[01:43:35.556] iteration 2512 : loss : 0.510109, loss_ce: 0.420632
[01:43:35.815] iteration 2513 : loss : 0.399328, loss_ce: 0.191103
[01:43:36.069] iteration 2514 : loss : 0.470096, loss_ce: 0.351963
[01:43:36.326] iteration 2515 : loss : 0.394878, loss_ce: 0.319957
[01:43:36.584] iteration 2516 : loss : 0.460097, loss_ce: 0.334913
[01:43:37.866] iteration 2517 : loss : 0.441839, loss_ce: 0.275907
[01:43:38.157] iteration 2518 : loss : 0.457407, loss_ce: 0.306195
[01:43:38.431] iteration 2519 : loss : 0.376391, loss_ce: 0.190859
[01:43:38.685] iteration 2520 : loss : 0.453281, loss_ce: 0.240580
[01:43:38.940] iteration 2521 : loss : 0.455928, loss_ce: 0.275458
[01:43:39.199] iteration 2522 : loss : 0.482154, loss_ce: 0.394782
[01:43:39.454] iteration 2523 : loss : 0.358787, loss_ce: 0.331881
[01:43:39.711] iteration 2524 : loss : 0.453786, loss_ce: 0.272608
[01:43:40.813] iteration 2525 : loss : 0.444429, loss_ce: 0.282464
[01:43:41.114] iteration 2526 : loss : 0.373327, loss_ce: 0.215528
[01:43:41.368] iteration 2527 : loss : 0.254350, loss_ce: 0.201580
[01:43:41.623] iteration 2528 : loss : 0.511816, loss_ce: 0.411912
[01:43:41.878] iteration 2529 : loss : 0.362575, loss_ce: 0.235404
[01:43:42.133] iteration 2530 : loss : 0.405680, loss_ce: 0.316915
[01:43:42.389] iteration 2531 : loss : 0.522430, loss_ce: 0.388379
[01:43:42.645] iteration 2532 : loss : 0.465971, loss_ce: 0.348096
[01:43:43.765] iteration 2533 : loss : 0.315138, loss_ce: 0.216027
[01:43:44.079] iteration 2534 : loss : 0.364379, loss_ce: 0.255121
[01:43:44.337] iteration 2535 : loss : 0.488591, loss_ce: 0.379436
[01:43:44.591] iteration 2536 : loss : 0.362916, loss_ce: 0.260591
[01:43:44.847] iteration 2537 : loss : 0.477468, loss_ce: 0.419564
[01:43:45.104] iteration 2538 : loss : 0.514462, loss_ce: 0.263265
[01:43:45.361] iteration 2539 : loss : 0.450127, loss_ce: 0.452583
[01:43:45.614] iteration 2540 : loss : 0.427794, loss_ce: 0.282723
[01:43:46.662] iteration 2541 : loss : 0.476718, loss_ce: 0.326274
[01:43:47.007] iteration 2542 : loss : 0.464383, loss_ce: 0.340406
[01:43:47.262] iteration 2543 : loss : 0.525346, loss_ce: 0.392449
[01:43:47.517] iteration 2544 : loss : 0.365572, loss_ce: 0.267124
[01:43:47.777] iteration 2545 : loss : 0.523483, loss_ce: 0.445975
[01:43:48.030] iteration 2546 : loss : 0.404599, loss_ce: 0.224792
[01:43:48.283] iteration 2547 : loss : 0.468112, loss_ce: 0.369982
[01:43:48.539] iteration 2548 : loss : 0.388036, loss_ce: 0.220007
[01:43:49.603] iteration 2549 : loss : 0.463160, loss_ce: 0.329716
[01:43:49.985] iteration 2550 : loss : 0.393649, loss_ce: 0.305550
[01:43:50.243] iteration 2551 : loss : 0.394149, loss_ce: 0.319394
[01:43:50.499] iteration 2552 : loss : 0.413366, loss_ce: 0.305644
[01:43:50.761] iteration 2553 : loss : 0.492527, loss_ce: 0.382888
[01:43:51.049] iteration 2554 : loss : 0.432601, loss_ce: 0.190342
[01:43:51.407] iteration 2555 : loss : 0.489677, loss_ce: 0.280725
[01:43:51.711] iteration 2556 : loss : 0.390757, loss_ce: 0.191379
[01:43:52.753] iteration 2557 : loss : 0.373943, loss_ce: 0.226071
[01:43:53.678] iteration 2558 : loss : 0.428239, loss_ce: 0.253655
[01:43:53.933] iteration 2559 : loss : 0.555714, loss_ce: 0.472210
[01:43:54.189] iteration 2560 : loss : 0.502215, loss_ce: 0.376119
[01:43:54.444] iteration 2561 : loss : 0.503054, loss_ce: 0.263906
[01:43:54.699] iteration 2562 : loss : 0.423836, loss_ce: 0.252045
[01:43:54.954] iteration 2563 : loss : 0.416108, loss_ce: 0.349209
[01:43:55.210] iteration 2564 : loss : 0.481806, loss_ce: 0.302777
[01:43:55.805] iteration 2565 : loss : 0.491671, loss_ce: 0.351481
[01:43:56.842] iteration 2566 : loss : 0.476654, loss_ce: 0.365099
[01:43:57.097] iteration 2567 : loss : 0.404985, loss_ce: 0.284148
[01:43:57.351] iteration 2568 : loss : 0.420082, loss_ce: 0.215381
[01:43:57.606] iteration 2569 : loss : 0.427525, loss_ce: 0.275195
[01:43:57.860] iteration 2570 : loss : 0.477012, loss_ce: 0.313692
[01:43:58.114] iteration 2571 : loss : 0.486948, loss_ce: 0.301034
[01:43:58.374] iteration 2572 : loss : 0.356686, loss_ce: 0.203270
[01:43:58.892] iteration 2573 : loss : 0.492740, loss_ce: 0.279917
[01:43:59.881] iteration 2574 : loss : 0.491965, loss_ce: 0.338639
[01:44:00.149] iteration 2575 : loss : 0.585170, loss_ce: 0.509159
[01:44:00.406] iteration 2576 : loss : 0.400548, loss_ce: 0.285218
[01:44:00.662] iteration 2577 : loss : 0.349492, loss_ce: 0.259649
[01:44:00.919] iteration 2578 : loss : 0.402539, loss_ce: 0.293837
[01:44:01.173] iteration 2579 : loss : 0.423010, loss_ce: 0.264430
[01:44:01.432] iteration 2580 : loss : 0.370057, loss_ce: 0.208972
[01:44:01.955] iteration 2581 : loss : 0.412453, loss_ce: 0.238982
[01:44:02.883] iteration 2582 : loss : 0.513434, loss_ce: 0.315786
[01:44:03.139] iteration 2583 : loss : 0.432280, loss_ce: 0.308648
[01:44:03.551] iteration 2584 : loss : 0.477374, loss_ce: 0.378104
[01:44:03.824] iteration 2585 : loss : 0.492866, loss_ce: 0.301885
[01:44:04.078] iteration 2586 : loss : 0.458256, loss_ce: 0.259811
[01:44:04.334] iteration 2587 : loss : 0.482967, loss_ce: 0.396780
[01:44:04.588] iteration 2588 : loss : 0.462367, loss_ce: 0.267756
[01:44:04.884] iteration 2589 : loss : 0.411045, loss_ce: 0.279348
[01:44:05.922] iteration 2590 : loss : 0.432238, loss_ce: 0.299347
[01:44:06.178] iteration 2591 : loss : 0.522352, loss_ce: 0.385491
[01:44:06.436] iteration 2592 : loss : 0.406418, loss_ce: 0.264144
[01:44:06.692] iteration 2593 : loss : 0.423407, loss_ce: 0.235042
[01:44:06.948] iteration 2594 : loss : 0.401620, loss_ce: 0.319235
[01:44:07.203] iteration 2595 : loss : 0.364759, loss_ce: 0.302664
[01:44:07.456] iteration 2596 : loss : 0.434739, loss_ce: 0.322706
[01:44:08.021] iteration 2597 : loss : 0.471831, loss_ce: 0.290306
[01:44:08.978] iteration 2598 : loss : 0.389010, loss_ce: 0.301808
[01:44:09.232] iteration 2599 : loss : 0.496795, loss_ce: 0.402330
[01:44:09.487] iteration 2600 : loss : 0.397305, loss_ce: 0.261875
[01:44:09.744] iteration 2601 : loss : 0.484106, loss_ce: 0.318582
[01:44:09.998] iteration 2602 : loss : 0.444260, loss_ce: 0.272890
[01:44:10.255] iteration 2603 : loss : 0.440826, loss_ce: 0.357206
[01:44:10.511] iteration 2604 : loss : 0.488543, loss_ce: 0.422067
[01:44:11.072] iteration 2605 : loss : 0.380675, loss_ce: 0.191280
[01:44:11.973] iteration 2606 : loss : 0.357245, loss_ce: 0.336743
[01:44:12.241] iteration 2607 : loss : 0.322294, loss_ce: 0.312606
[01:44:12.494] iteration 2608 : loss : 0.417232, loss_ce: 0.254704
[01:44:12.747] iteration 2609 : loss : 0.347347, loss_ce: 0.270356
[01:44:13.002] iteration 2610 : loss : 0.420640, loss_ce: 0.322717
[01:44:13.256] iteration 2611 : loss : 0.421531, loss_ce: 0.259571
[01:44:13.511] iteration 2612 : loss : 0.368320, loss_ce: 0.301717
[01:44:14.041] iteration 2613 : loss : 0.335691, loss_ce: 0.247506
[01:44:14.927] iteration 2614 : loss : 0.366788, loss_ce: 0.253422
[01:44:15.181] iteration 2615 : loss : 0.542861, loss_ce: 0.364456
[01:44:15.435] iteration 2616 : loss : 0.487980, loss_ce: 0.352075
[01:44:15.689] iteration 2617 : loss : 0.505114, loss_ce: 0.336524
[01:44:15.943] iteration 2618 : loss : 0.472795, loss_ce: 0.370234
[01:44:16.197] iteration 2619 : loss : 0.389884, loss_ce: 0.255657
[01:44:16.451] iteration 2620 : loss : 0.424554, loss_ce: 0.238080
[01:44:17.019] iteration 2621 : loss : 0.403580, loss_ce: 0.246496
[01:44:17.869] iteration 2622 : loss : 0.437006, loss_ce: 0.352746
[01:44:18.124] iteration 2623 : loss : 0.467606, loss_ce: 0.278218
[01:44:18.382] iteration 2624 : loss : 0.436519, loss_ce: 0.293729
[01:44:18.635] iteration 2625 : loss : 0.473943, loss_ce: 0.395705
[01:44:18.890] iteration 2626 : loss : 0.394134, loss_ce: 0.241204
[01:44:19.145] iteration 2627 : loss : 0.440061, loss_ce: 0.285894
[01:44:19.398] iteration 2628 : loss : 0.532304, loss_ce: 0.360070
[01:44:19.889] iteration 2629 : loss : 0.338651, loss_ce: 0.268566
[01:44:20.754] iteration 2630 : loss : 0.325082, loss_ce: 0.205813
[01:44:21.008] iteration 2631 : loss : 0.401603, loss_ce: 0.312114
[01:44:21.262] iteration 2632 : loss : 0.360769, loss_ce: 0.203544
[01:44:21.514] iteration 2633 : loss : 0.479462, loss_ce: 0.372764
[01:44:21.767] iteration 2634 : loss : 0.468955, loss_ce: 0.308048
[01:44:22.023] iteration 2635 : loss : 0.447796, loss_ce: 0.260470
[01:44:22.276] iteration 2636 : loss : 0.580932, loss_ce: 0.468941
[01:44:22.670] iteration 2637 : loss : 0.503938, loss_ce: 0.448074
[01:44:23.457] iteration 2638 : loss : 0.454505, loss_ce: 0.344941
[01:44:23.711] iteration 2639 : loss : 0.456987, loss_ce: 0.280385
[01:44:23.901] iteration 2640 : loss : 0.498299, loss_ce: 0.200035
[01:44:28.713] iteration 2641 : loss : 0.412836, loss_ce: 0.286139
[01:44:28.969] iteration 2642 : loss : 0.360589, loss_ce: 0.221081
[01:44:29.223] iteration 2643 : loss : 0.450891, loss_ce: 0.233812
[01:44:29.477] iteration 2644 : loss : 0.408596, loss_ce: 0.225661
[01:44:29.729] iteration 2645 : loss : 0.414484, loss_ce: 0.249801
[01:44:29.983] iteration 2646 : loss : 0.438230, loss_ce: 0.287225
[01:44:30.238] iteration 2647 : loss : 0.415061, loss_ce: 0.267619
[01:44:30.492] iteration 2648 : loss : 0.303501, loss_ce: 0.263922
[01:44:31.739] iteration 2649 : loss : 0.483828, loss_ce: 0.375007
[01:44:31.994] iteration 2650 : loss : 0.531078, loss_ce: 0.388334
[01:44:32.251] iteration 2651 : loss : 0.511897, loss_ce: 0.358476
[01:44:32.505] iteration 2652 : loss : 0.532691, loss_ce: 0.352984
[01:44:32.759] iteration 2653 : loss : 0.454545, loss_ce: 0.345316
[01:44:33.015] iteration 2654 : loss : 0.416501, loss_ce: 0.283860
[01:44:33.271] iteration 2655 : loss : 0.396482, loss_ce: 0.287484
[01:44:33.528] iteration 2656 : loss : 0.405969, loss_ce: 0.278566
[01:44:34.791] iteration 2657 : loss : 0.347460, loss_ce: 0.215173
[01:44:35.052] iteration 2658 : loss : 0.315985, loss_ce: 0.204294
[01:44:35.311] iteration 2659 : loss : 0.422879, loss_ce: 0.278525
[01:44:35.567] iteration 2660 : loss : 0.409495, loss_ce: 0.258817
[01:44:35.824] iteration 2661 : loss : 0.353499, loss_ce: 0.297401
[01:44:36.080] iteration 2662 : loss : 0.236945, loss_ce: 0.163618
[01:44:36.335] iteration 2663 : loss : 0.404673, loss_ce: 0.341390
[01:44:36.591] iteration 2664 : loss : 0.379598, loss_ce: 0.252201
[01:44:37.905] iteration 2665 : loss : 0.404599, loss_ce: 0.268633
[01:44:38.163] iteration 2666 : loss : 0.402150, loss_ce: 0.246776
[01:44:38.418] iteration 2667 : loss : 0.363327, loss_ce: 0.222172
[01:44:38.671] iteration 2668 : loss : 0.382280, loss_ce: 0.198939
[01:44:38.925] iteration 2669 : loss : 0.413418, loss_ce: 0.233238
[01:44:39.181] iteration 2670 : loss : 0.467586, loss_ce: 0.359225
[01:44:39.433] iteration 2671 : loss : 0.429104, loss_ce: 0.340774
[01:44:39.689] iteration 2672 : loss : 0.396084, loss_ce: 0.290419
[01:44:40.927] iteration 2673 : loss : 0.402375, loss_ce: 0.350670
[01:44:41.183] iteration 2674 : loss : 0.413371, loss_ce: 0.263690
[01:44:41.437] iteration 2675 : loss : 0.422563, loss_ce: 0.333825
[01:44:41.691] iteration 2676 : loss : 0.405068, loss_ce: 0.279584
[01:44:41.944] iteration 2677 : loss : 0.494887, loss_ce: 0.255818
[01:44:42.199] iteration 2678 : loss : 0.410457, loss_ce: 0.307107
[01:44:42.454] iteration 2679 : loss : 0.441768, loss_ce: 0.313567
[01:44:42.708] iteration 2680 : loss : 0.229069, loss_ce: 0.161789
[01:44:43.885] iteration 2681 : loss : 0.351703, loss_ce: 0.274293
[01:44:44.141] iteration 2682 : loss : 0.352936, loss_ce: 0.190926
[01:44:44.396] iteration 2683 : loss : 0.424050, loss_ce: 0.330654
[01:44:44.650] iteration 2684 : loss : 0.411482, loss_ce: 0.310180
[01:44:44.912] iteration 2685 : loss : 0.466643, loss_ce: 0.275714
[01:44:45.167] iteration 2686 : loss : 0.324886, loss_ce: 0.212703
[01:44:45.421] iteration 2687 : loss : 0.466187, loss_ce: 0.272711
[01:44:45.676] iteration 2688 : loss : 0.427567, loss_ce: 0.260077
[01:44:46.923] iteration 2689 : loss : 0.346584, loss_ce: 0.193417
[01:44:47.183] iteration 2690 : loss : 0.515004, loss_ce: 0.325948
[01:44:47.436] iteration 2691 : loss : 0.388275, loss_ce: 0.275661
[01:44:47.689] iteration 2692 : loss : 0.445601, loss_ce: 0.283161
[01:44:47.943] iteration 2693 : loss : 0.357743, loss_ce: 0.221088
[01:44:48.196] iteration 2694 : loss : 0.375821, loss_ce: 0.323962
[01:44:48.449] iteration 2695 : loss : 0.382154, loss_ce: 0.214040
[01:44:48.702] iteration 2696 : loss : 0.450107, loss_ce: 0.226971
[01:44:49.809] iteration 2697 : loss : 0.427821, loss_ce: 0.309230
[01:44:50.065] iteration 2698 : loss : 0.461993, loss_ce: 0.279670
[01:44:50.320] iteration 2699 : loss : 0.423740, loss_ce: 0.368539
[01:44:50.573] iteration 2700 : loss : 0.396516, loss_ce: 0.195778
[01:44:50.825] iteration 2701 : loss : 0.445486, loss_ce: 0.324884
[01:44:51.078] iteration 2702 : loss : 0.340018, loss_ce: 0.246783
[01:44:51.334] iteration 2703 : loss : 0.378220, loss_ce: 0.172298
[01:44:51.587] iteration 2704 : loss : 0.379641, loss_ce: 0.216547
[01:44:52.724] iteration 2705 : loss : 0.414194, loss_ce: 0.371425
[01:44:52.979] iteration 2706 : loss : 0.609553, loss_ce: 0.499636
[01:44:53.232] iteration 2707 : loss : 0.445624, loss_ce: 0.260880
[01:44:53.485] iteration 2708 : loss : 0.314548, loss_ce: 0.252086
[01:44:53.738] iteration 2709 : loss : 0.438112, loss_ce: 0.381194
[01:44:53.991] iteration 2710 : loss : 0.450456, loss_ce: 0.306347
[01:44:54.247] iteration 2711 : loss : 0.483012, loss_ce: 0.273725
[01:44:54.501] iteration 2712 : loss : 0.384823, loss_ce: 0.276769
[01:44:55.664] iteration 2713 : loss : 0.441779, loss_ce: 0.286550
[01:44:55.919] iteration 2714 : loss : 0.417576, loss_ce: 0.317666
[01:44:56.368] iteration 2715 : loss : 0.466622, loss_ce: 0.340354
[01:44:56.625] iteration 2716 : loss : 0.431081, loss_ce: 0.366983
[01:44:56.880] iteration 2717 : loss : 0.433425, loss_ce: 0.286401
[01:44:57.133] iteration 2718 : loss : 0.431687, loss_ce: 0.227658
[01:44:57.388] iteration 2719 : loss : 0.366272, loss_ce: 0.208717
[01:44:57.641] iteration 2720 : loss : 0.423192, loss_ce: 0.295505
[01:44:58.599] iteration 2721 : loss : 0.465905, loss_ce: 0.265432
[01:44:58.853] iteration 2722 : loss : 0.476494, loss_ce: 0.340638
[01:44:59.107] iteration 2723 : loss : 0.412618, loss_ce: 0.257663
[01:44:59.362] iteration 2724 : loss : 0.489657, loss_ce: 0.432193
[01:44:59.618] iteration 2725 : loss : 0.357534, loss_ce: 0.179168
[01:44:59.874] iteration 2726 : loss : 0.424564, loss_ce: 0.308933
[01:45:00.130] iteration 2727 : loss : 0.302328, loss_ce: 0.171936
[01:45:00.388] iteration 2728 : loss : 0.456235, loss_ce: 0.408587
[01:45:01.784] iteration 2729 : loss : 0.391999, loss_ce: 0.341699
[01:45:02.040] iteration 2730 : loss : 0.404293, loss_ce: 0.217539
[01:45:02.293] iteration 2731 : loss : 0.480924, loss_ce: 0.305608
[01:45:02.546] iteration 2732 : loss : 0.283232, loss_ce: 0.213198
[01:45:02.804] iteration 2733 : loss : 0.438447, loss_ce: 0.310925
[01:45:03.059] iteration 2734 : loss : 0.402380, loss_ce: 0.341139
[01:45:03.312] iteration 2735 : loss : 0.464774, loss_ce: 0.398632
[01:45:03.565] iteration 2736 : loss : 0.459729, loss_ce: 0.345653
[01:45:04.826] iteration 2737 : loss : 0.501858, loss_ce: 0.353862
[01:45:05.081] iteration 2738 : loss : 0.366036, loss_ce: 0.294968
[01:45:05.337] iteration 2739 : loss : 0.455685, loss_ce: 0.328958
[01:45:05.614] iteration 2740 : loss : 0.374326, loss_ce: 0.331336
[01:45:05.875] iteration 2741 : loss : 0.456856, loss_ce: 0.352117
[01:45:06.130] iteration 2742 : loss : 0.495164, loss_ce: 0.409721
[01:45:06.385] iteration 2743 : loss : 0.371598, loss_ce: 0.312146
[01:45:06.639] iteration 2744 : loss : 0.546807, loss_ce: 0.315939
[01:45:07.831] iteration 2745 : loss : 0.371246, loss_ce: 0.237921
[01:45:08.087] iteration 2746 : loss : 0.544821, loss_ce: 0.413722
[01:45:08.342] iteration 2747 : loss : 0.401745, loss_ce: 0.233703
[01:45:08.597] iteration 2748 : loss : 0.402327, loss_ce: 0.287077
[01:45:08.853] iteration 2749 : loss : 0.425991, loss_ce: 0.225664
[01:45:09.106] iteration 2750 : loss : 0.359856, loss_ce: 0.283239
[01:45:09.362] iteration 2751 : loss : 0.594364, loss_ce: 0.456184
[01:45:09.617] iteration 2752 : loss : 0.389548, loss_ce: 0.327123
[01:45:10.918] iteration 2753 : loss : 0.451349, loss_ce: 0.291110
[01:45:11.180] iteration 2754 : loss : 0.451777, loss_ce: 0.279624
[01:45:11.436] iteration 2755 : loss : 0.391786, loss_ce: 0.262433
[01:45:11.692] iteration 2756 : loss : 0.437050, loss_ce: 0.300353
[01:45:11.948] iteration 2757 : loss : 0.306804, loss_ce: 0.196764
[01:45:12.202] iteration 2758 : loss : 0.366647, loss_ce: 0.191595
[01:45:12.455] iteration 2759 : loss : 0.368682, loss_ce: 0.281763
[01:45:12.710] iteration 2760 : loss : 0.435162, loss_ce: 0.345510
[01:45:13.948] iteration 2761 : loss : 0.461619, loss_ce: 0.341712
[01:45:14.204] iteration 2762 : loss : 0.563374, loss_ce: 0.453644
[01:45:14.459] iteration 2763 : loss : 0.556961, loss_ce: 0.414652
[01:45:14.713] iteration 2764 : loss : 0.396642, loss_ce: 0.321846
[01:45:14.969] iteration 2765 : loss : 0.405785, loss_ce: 0.326968
[01:45:15.224] iteration 2766 : loss : 0.412524, loss_ce: 0.253519
[01:45:15.479] iteration 2767 : loss : 0.410446, loss_ce: 0.306491
[01:45:15.735] iteration 2768 : loss : 0.424179, loss_ce: 0.306142
[01:45:16.978] iteration 2769 : loss : 0.444894, loss_ce: 0.304043
[01:45:17.217] iteration 2770 : loss : 0.379924, loss_ce: 0.293502
[01:45:17.447] iteration 2771 : loss : 0.506598, loss_ce: 0.341035
[01:45:17.683] iteration 2772 : loss : 0.419233, loss_ce: 0.257813
[01:45:17.915] iteration 2773 : loss : 0.438947, loss_ce: 0.343333
[01:45:18.148] iteration 2774 : loss : 0.503085, loss_ce: 0.532385
[01:45:18.382] iteration 2775 : loss : 0.350929, loss_ce: 0.238710
[01:45:18.615] iteration 2776 : loss : 0.407395, loss_ce: 0.212112
[01:45:19.866] iteration 2777 : loss : 0.397620, loss_ce: 0.302057
[01:45:20.102] iteration 2778 : loss : 0.415247, loss_ce: 0.260113
[01:45:20.345] iteration 2779 : loss : 0.497629, loss_ce: 0.321989
[01:45:20.579] iteration 2780 : loss : 0.377652, loss_ce: 0.284741
[01:45:20.820] iteration 2781 : loss : 0.416645, loss_ce: 0.304305
[01:45:21.051] iteration 2782 : loss : 0.302973, loss_ce: 0.266461
[01:45:21.290] iteration 2783 : loss : 0.432687, loss_ce: 0.309512
[01:45:21.523] iteration 2784 : loss : 0.390908, loss_ce: 0.316483
[01:45:22.796] iteration 2785 : loss : 0.467805, loss_ce: 0.329627
[01:45:23.030] iteration 2786 : loss : 0.372762, loss_ce: 0.221604
[01:45:23.262] iteration 2787 : loss : 0.518924, loss_ce: 0.419217
[01:45:23.495] iteration 2788 : loss : 0.489025, loss_ce: 0.342994
[01:45:23.727] iteration 2789 : loss : 0.371032, loss_ce: 0.228507
[01:45:23.955] iteration 2790 : loss : 0.440140, loss_ce: 0.377343
[01:45:24.184] iteration 2791 : loss : 0.459566, loss_ce: 0.375763
[01:45:24.412] iteration 2792 : loss : 0.397576, loss_ce: 0.196441
[01:45:25.678] iteration 2793 : loss : 0.452324, loss_ce: 0.314677
[01:45:25.941] iteration 2794 : loss : 0.533346, loss_ce: 0.334479
[01:45:26.194] iteration 2795 : loss : 0.503282, loss_ce: 0.375539
[01:45:26.447] iteration 2796 : loss : 0.473041, loss_ce: 0.319955
[01:45:26.701] iteration 2797 : loss : 0.306238, loss_ce: 0.273176
[01:45:26.957] iteration 2798 : loss : 0.363442, loss_ce: 0.243595
[01:45:27.210] iteration 2799 : loss : 0.465799, loss_ce: 0.349391
[01:45:27.463] iteration 2800 : loss : 0.325211, loss_ce: 0.265761
[01:45:28.579] iteration 2801 : loss : 0.394174, loss_ce: 0.341571
[01:45:28.834] iteration 2802 : loss : 0.404091, loss_ce: 0.275558
[01:45:29.087] iteration 2803 : loss : 0.487574, loss_ce: 0.387325
[01:45:29.343] iteration 2804 : loss : 0.433743, loss_ce: 0.267381
[01:45:29.596] iteration 2805 : loss : 0.429314, loss_ce: 0.389287
[01:45:29.850] iteration 2806 : loss : 0.504921, loss_ce: 0.389710
[01:45:30.104] iteration 2807 : loss : 0.490193, loss_ce: 0.305351
[01:45:30.360] iteration 2808 : loss : 0.369594, loss_ce: 0.277771
[01:45:31.471] iteration 2809 : loss : 0.434820, loss_ce: 0.264270
[01:45:31.728] iteration 2810 : loss : 0.415519, loss_ce: 0.244760
[01:45:31.981] iteration 2811 : loss : 0.479849, loss_ce: 0.303221
[01:45:32.234] iteration 2812 : loss : 0.510205, loss_ce: 0.337042
[01:45:32.487] iteration 2813 : loss : 0.381929, loss_ce: 0.210725
[01:45:32.741] iteration 2814 : loss : 0.407833, loss_ce: 0.360464
[01:45:32.996] iteration 2815 : loss : 0.555376, loss_ce: 0.531529
[01:45:33.250] iteration 2816 : loss : 0.384260, loss_ce: 0.285327
[01:45:34.295] iteration 2817 : loss : 0.485560, loss_ce: 0.382794
[01:45:34.552] iteration 2818 : loss : 0.270779, loss_ce: 0.210502
[01:45:34.829] iteration 2819 : loss : 0.456886, loss_ce: 0.284099
[01:45:35.084] iteration 2820 : loss : 0.456971, loss_ce: 0.298467
[01:45:35.355] iteration 2821 : loss : 0.459766, loss_ce: 0.300356
[01:45:35.655] iteration 2822 : loss : 0.452065, loss_ce: 0.341055
[01:45:35.951] iteration 2823 : loss : 0.412698, loss_ce: 0.310263
[01:45:36.234] iteration 2824 : loss : 0.404411, loss_ce: 0.236447
[01:45:37.400] iteration 2825 : loss : 0.380494, loss_ce: 0.314363
[01:45:37.656] iteration 2826 : loss : 0.383994, loss_ce: 0.279772
[01:45:37.910] iteration 2827 : loss : 0.445560, loss_ce: 0.305529
[01:45:38.163] iteration 2828 : loss : 0.405507, loss_ce: 0.319309
[01:45:38.446] iteration 2829 : loss : 0.452948, loss_ce: 0.289422
[01:45:38.699] iteration 2830 : loss : 0.476222, loss_ce: 0.288073
[01:45:38.954] iteration 2831 : loss : 0.410587, loss_ce: 0.301638
[01:45:39.207] iteration 2832 : loss : 0.441395, loss_ce: 0.370184
[01:45:40.368] iteration 2833 : loss : 0.410832, loss_ce: 0.318576
[01:45:40.631] iteration 2834 : loss : 0.408825, loss_ce: 0.260727
[01:45:40.883] iteration 2835 : loss : 0.357074, loss_ce: 0.303180
[01:45:41.140] iteration 2836 : loss : 0.351881, loss_ce: 0.227723
[01:45:41.395] iteration 2837 : loss : 0.419172, loss_ce: 0.276283
[01:45:41.649] iteration 2838 : loss : 0.528586, loss_ce: 0.363092
[01:45:41.904] iteration 2839 : loss : 0.497904, loss_ce: 0.316943
[01:45:42.159] iteration 2840 : loss : 0.362210, loss_ce: 0.173248
[01:45:43.444] iteration 2841 : loss : 0.473557, loss_ce: 0.313931
[01:45:43.699] iteration 2842 : loss : 0.419905, loss_ce: 0.375279
[01:45:43.954] iteration 2843 : loss : 0.383102, loss_ce: 0.270813
[01:45:44.210] iteration 2844 : loss : 0.507934, loss_ce: 0.465217
[01:45:44.465] iteration 2845 : loss : 0.586015, loss_ce: 0.315127
[01:45:44.721] iteration 2846 : loss : 0.428111, loss_ce: 0.193993
[01:45:44.977] iteration 2847 : loss : 0.562234, loss_ce: 0.436892
[01:45:45.239] iteration 2848 : loss : 0.410617, loss_ce: 0.312634
[01:45:46.630] iteration 2849 : loss : 0.330710, loss_ce: 0.234291
[01:45:46.883] iteration 2850 : loss : 0.384427, loss_ce: 0.281167
[01:45:47.135] iteration 2851 : loss : 0.357894, loss_ce: 0.305642
[01:45:47.390] iteration 2852 : loss : 0.351069, loss_ce: 0.178928
[01:45:47.642] iteration 2853 : loss : 0.313589, loss_ce: 0.230527
[01:45:47.895] iteration 2854 : loss : 0.376597, loss_ce: 0.266731
[01:45:48.149] iteration 2855 : loss : 0.430842, loss_ce: 0.354161
[01:45:48.402] iteration 2856 : loss : 0.377745, loss_ce: 0.214201
[01:45:49.237] iteration 2857 : loss : 0.371631, loss_ce: 0.286356
[01:45:49.489] iteration 2858 : loss : 0.539718, loss_ce: 0.314227
[01:45:49.741] iteration 2859 : loss : 0.411648, loss_ce: 0.307392
[01:45:49.966] iteration 2860 : loss : 0.522473, loss_ce: 0.156886
[01:45:54.107] iteration 2861 : loss : 0.381031, loss_ce: 0.251796
[01:45:54.366] iteration 2862 : loss : 0.254481, loss_ce: 0.155674
[01:45:54.625] iteration 2863 : loss : 0.386906, loss_ce: 0.312898
[01:45:54.890] iteration 2864 : loss : 0.470870, loss_ce: 0.341647
[01:45:55.150] iteration 2865 : loss : 0.467456, loss_ce: 0.304250
[01:45:55.405] iteration 2866 : loss : 0.298449, loss_ce: 0.197828
[01:45:55.658] iteration 2867 : loss : 0.367874, loss_ce: 0.284819
[01:45:55.912] iteration 2868 : loss : 0.452364, loss_ce: 0.312417
[01:45:57.175] iteration 2869 : loss : 0.408690, loss_ce: 0.233608
[01:45:57.432] iteration 2870 : loss : 0.509652, loss_ce: 0.367011
[01:45:57.685] iteration 2871 : loss : 0.309626, loss_ce: 0.238074
[01:45:57.939] iteration 2872 : loss : 0.334487, loss_ce: 0.243862
[01:45:58.191] iteration 2873 : loss : 0.491793, loss_ce: 0.405758
[01:45:58.443] iteration 2874 : loss : 0.540157, loss_ce: 0.355532
[01:45:58.695] iteration 2875 : loss : 0.573173, loss_ce: 0.531230
[01:45:58.948] iteration 2876 : loss : 0.460981, loss_ce: 0.239152
[01:46:00.066] iteration 2877 : loss : 0.399181, loss_ce: 0.294178
[01:46:00.322] iteration 2878 : loss : 0.461769, loss_ce: 0.276801
[01:46:00.603] iteration 2879 : loss : 0.472865, loss_ce: 0.374343
[01:46:00.855] iteration 2880 : loss : 0.442748, loss_ce: 0.309748
[01:46:01.107] iteration 2881 : loss : 0.432240, loss_ce: 0.319220
[01:46:01.361] iteration 2882 : loss : 0.406212, loss_ce: 0.276789
[01:46:01.614] iteration 2883 : loss : 0.332300, loss_ce: 0.264963
[01:46:01.867] iteration 2884 : loss : 0.536785, loss_ce: 0.387575
[01:46:03.010] iteration 2885 : loss : 0.410980, loss_ce: 0.274413
[01:46:03.264] iteration 2886 : loss : 0.385826, loss_ce: 0.310367
[01:46:03.993] iteration 2887 : loss : 0.310163, loss_ce: 0.256016
[01:46:04.250] iteration 2888 : loss : 0.519635, loss_ce: 0.369660
[01:46:04.504] iteration 2889 : loss : 0.396179, loss_ce: 0.211332
[01:46:04.756] iteration 2890 : loss : 0.371767, loss_ce: 0.246953
[01:46:05.009] iteration 2891 : loss : 0.422093, loss_ce: 0.303403
[01:46:05.266] iteration 2892 : loss : 0.427611, loss_ce: 0.295692
[01:46:05.921] iteration 2893 : loss : 0.359942, loss_ce: 0.271098
[01:46:06.179] iteration 2894 : loss : 0.394759, loss_ce: 0.286509
[01:46:06.937] iteration 2895 : loss : 0.410580, loss_ce: 0.253760
[01:46:07.193] iteration 2896 : loss : 0.366837, loss_ce: 0.284789
[01:46:07.445] iteration 2897 : loss : 0.385235, loss_ce: 0.256870
[01:46:07.698] iteration 2898 : loss : 0.432410, loss_ce: 0.396232
[01:46:07.951] iteration 2899 : loss : 0.400921, loss_ce: 0.286309
[01:46:08.206] iteration 2900 : loss : 0.466151, loss_ce: 0.292638
[01:46:08.789] iteration 2901 : loss : 0.505814, loss_ce: 0.388405
[01:46:09.044] iteration 2902 : loss : 0.377117, loss_ce: 0.362749
[01:46:09.807] iteration 2903 : loss : 0.500252, loss_ce: 0.315346
[01:46:10.081] iteration 2904 : loss : 0.382744, loss_ce: 0.271971
[01:46:10.417] iteration 2905 : loss : 0.506893, loss_ce: 0.348244
[01:46:10.742] iteration 2906 : loss : 0.483486, loss_ce: 0.282352
[01:46:11.060] iteration 2907 : loss : 0.291656, loss_ce: 0.248216
[01:46:11.435] iteration 2908 : loss : 0.368021, loss_ce: 0.211537
[01:46:12.026] iteration 2909 : loss : 0.503942, loss_ce: 0.335982
[01:46:12.281] iteration 2910 : loss : 0.569059, loss_ce: 0.429631
[01:46:12.976] iteration 2911 : loss : 0.437289, loss_ce: 0.297572
[01:46:13.232] iteration 2912 : loss : 0.360393, loss_ce: 0.204441
[01:46:13.485] iteration 2913 : loss : 0.395030, loss_ce: 0.311356
[01:46:13.742] iteration 2914 : loss : 0.340030, loss_ce: 0.270742
[01:46:13.994] iteration 2915 : loss : 0.486330, loss_ce: 0.355892
[01:46:14.251] iteration 2916 : loss : 0.348068, loss_ce: 0.159406
[01:46:14.906] iteration 2917 : loss : 0.412984, loss_ce: 0.233686
[01:46:15.160] iteration 2918 : loss : 0.340598, loss_ce: 0.246041
[01:46:15.878] iteration 2919 : loss : 0.480060, loss_ce: 0.325673
[01:46:16.136] iteration 2920 : loss : 0.398757, loss_ce: 0.331104
[01:46:16.390] iteration 2921 : loss : 0.518316, loss_ce: 0.288835
[01:46:16.645] iteration 2922 : loss : 0.472971, loss_ce: 0.272567
[01:46:16.898] iteration 2923 : loss : 0.434761, loss_ce: 0.288337
[01:46:17.150] iteration 2924 : loss : 0.431937, loss_ce: 0.324439
[01:46:17.762] iteration 2925 : loss : 0.482592, loss_ce: 0.350914
[01:46:18.016] iteration 2926 : loss : 0.536506, loss_ce: 0.347396
[01:46:18.715] iteration 2927 : loss : 0.429245, loss_ce: 0.331081
[01:46:18.970] iteration 2928 : loss : 0.418668, loss_ce: 0.242864
[01:46:19.222] iteration 2929 : loss : 0.502612, loss_ce: 0.366186
[01:46:19.477] iteration 2930 : loss : 0.443736, loss_ce: 0.292984
[01:46:19.730] iteration 2931 : loss : 0.397391, loss_ce: 0.366005
[01:46:19.984] iteration 2932 : loss : 0.385795, loss_ce: 0.293820
[01:46:20.645] iteration 2933 : loss : 0.432975, loss_ce: 0.298023
[01:46:20.902] iteration 2934 : loss : 0.353663, loss_ce: 0.224400
[01:46:21.605] iteration 2935 : loss : 0.359644, loss_ce: 0.279079
[01:46:21.859] iteration 2936 : loss : 0.354627, loss_ce: 0.202763
[01:46:22.112] iteration 2937 : loss : 0.411726, loss_ce: 0.232839
[01:46:22.364] iteration 2938 : loss : 0.478510, loss_ce: 0.307271
[01:46:22.617] iteration 2939 : loss : 0.462515, loss_ce: 0.291249
[01:46:22.871] iteration 2940 : loss : 0.400636, loss_ce: 0.320207
[01:46:23.559] iteration 2941 : loss : 0.261288, loss_ce: 0.212766
[01:46:23.817] iteration 2942 : loss : 0.263176, loss_ce: 0.171477
[01:46:24.540] iteration 2943 : loss : 0.379498, loss_ce: 0.312836
[01:46:24.796] iteration 2944 : loss : 0.395480, loss_ce: 0.222894
[01:46:25.052] iteration 2945 : loss : 0.465577, loss_ce: 0.300157
[01:46:25.306] iteration 2946 : loss : 0.481052, loss_ce: 0.393335
[01:46:25.560] iteration 2947 : loss : 0.509554, loss_ce: 0.395908
[01:46:25.832] iteration 2948 : loss : 0.508459, loss_ce: 0.441828
[01:46:26.544] iteration 2949 : loss : 0.376533, loss_ce: 0.315057
[01:46:26.800] iteration 2950 : loss : 0.339777, loss_ce: 0.255834
[01:46:27.530] iteration 2951 : loss : 0.322134, loss_ce: 0.237267
[01:46:27.783] iteration 2952 : loss : 0.405254, loss_ce: 0.200259
[01:46:28.037] iteration 2953 : loss : 0.276294, loss_ce: 0.196085
[01:46:28.291] iteration 2954 : loss : 0.364313, loss_ce: 0.302531
[01:46:28.545] iteration 2955 : loss : 0.417980, loss_ce: 0.316677
[01:46:28.798] iteration 2956 : loss : 0.316986, loss_ce: 0.253094
[01:46:29.653] iteration 2957 : loss : 0.534656, loss_ce: 0.305174
[01:46:29.909] iteration 2958 : loss : 0.518525, loss_ce: 0.304309
[01:46:30.572] iteration 2959 : loss : 0.367413, loss_ce: 0.261587
[01:46:30.837] iteration 2960 : loss : 0.476552, loss_ce: 0.313518
[01:46:31.123] iteration 2961 : loss : 0.460321, loss_ce: 0.309543
[01:46:31.375] iteration 2962 : loss : 0.453768, loss_ce: 0.355674
[01:46:31.628] iteration 2963 : loss : 0.384180, loss_ce: 0.353165
[01:46:31.883] iteration 2964 : loss : 0.350305, loss_ce: 0.267211
[01:46:32.567] iteration 2965 : loss : 0.496629, loss_ce: 0.286141
[01:46:32.851] iteration 2966 : loss : 0.418503, loss_ce: 0.325493
[01:46:33.484] iteration 2967 : loss : 0.387152, loss_ce: 0.234683
[01:46:33.736] iteration 2968 : loss : 0.389298, loss_ce: 0.325472
[01:46:33.989] iteration 2969 : loss : 0.452393, loss_ce: 0.262489
[01:46:34.240] iteration 2970 : loss : 0.422020, loss_ce: 0.287711
[01:46:34.493] iteration 2971 : loss : 0.382372, loss_ce: 0.281484
[01:46:34.746] iteration 2972 : loss : 0.322940, loss_ce: 0.211997
[01:46:35.462] iteration 2973 : loss : 0.401013, loss_ce: 0.269640
[01:46:35.716] iteration 2974 : loss : 0.354176, loss_ce: 0.319410
[01:46:36.386] iteration 2975 : loss : 0.386706, loss_ce: 0.335402
[01:46:36.642] iteration 2976 : loss : 0.434970, loss_ce: 0.330372
[01:46:36.895] iteration 2977 : loss : 0.335365, loss_ce: 0.241530
[01:46:37.147] iteration 2978 : loss : 0.434077, loss_ce: 0.269980
[01:46:37.402] iteration 2979 : loss : 0.462020, loss_ce: 0.273673
[01:46:37.655] iteration 2980 : loss : 0.423855, loss_ce: 0.321167
[01:46:38.348] iteration 2981 : loss : 0.435363, loss_ce: 0.272610
[01:46:38.603] iteration 2982 : loss : 0.337562, loss_ce: 0.256491
[01:46:39.399] iteration 2983 : loss : 0.404217, loss_ce: 0.241541
[01:46:39.655] iteration 2984 : loss : 0.500134, loss_ce: 0.313465
[01:46:39.908] iteration 2985 : loss : 0.464556, loss_ce: 0.314696
[01:46:40.164] iteration 2986 : loss : 0.458511, loss_ce: 0.352605
[01:46:40.417] iteration 2987 : loss : 0.530364, loss_ce: 0.367681
[01:46:40.673] iteration 2988 : loss : 0.353927, loss_ce: 0.282547
[01:46:41.343] iteration 2989 : loss : 0.384033, loss_ce: 0.277833
[01:46:41.601] iteration 2990 : loss : 0.447992, loss_ce: 0.323531
[01:46:42.155] iteration 2991 : loss : 0.298101, loss_ce: 0.193798
[01:46:42.408] iteration 2992 : loss : 0.392660, loss_ce: 0.267222
[01:46:42.664] iteration 2993 : loss : 0.406969, loss_ce: 0.244584
[01:46:42.918] iteration 2994 : loss : 0.410605, loss_ce: 0.347329
[01:46:43.174] iteration 2995 : loss : 0.411795, loss_ce: 0.302637
[01:46:43.430] iteration 2996 : loss : 0.495940, loss_ce: 0.341908
[01:46:44.285] iteration 2997 : loss : 0.364912, loss_ce: 0.263784
[01:46:44.545] iteration 2998 : loss : 0.420691, loss_ce: 0.227790
[01:46:45.146] iteration 2999 : loss : 0.450272, loss_ce: 0.278865
[01:46:45.471] iteration 3000 : loss : 0.494199, loss_ce: 0.373295
[01:46:45.766] iteration 3001 : loss : 0.473075, loss_ce: 0.248829
[01:46:46.059] iteration 3002 : loss : 0.403283, loss_ce: 0.266430
[01:46:46.394] iteration 3003 : loss : 0.451866, loss_ce: 0.287733
[01:46:46.648] iteration 3004 : loss : 0.443081, loss_ce: 0.325053
[01:46:47.431] iteration 3005 : loss : 0.373501, loss_ce: 0.181382
[01:46:47.688] iteration 3006 : loss : 0.441645, loss_ce: 0.275099
[01:46:48.932] iteration 3007 : loss : 0.393265, loss_ce: 0.263684
[01:46:49.187] iteration 3008 : loss : 0.442150, loss_ce: 0.294404
[01:46:49.444] iteration 3009 : loss : 0.448364, loss_ce: 0.310596
[01:46:49.698] iteration 3010 : loss : 0.433619, loss_ce: 0.303891
[01:46:49.953] iteration 3011 : loss : 0.499963, loss_ce: 0.373005
[01:46:50.207] iteration 3012 : loss : 0.405510, loss_ce: 0.223623
[01:46:50.463] iteration 3013 : loss : 0.361866, loss_ce: 0.285960
[01:46:50.719] iteration 3014 : loss : 0.439501, loss_ce: 0.329956
[01:46:51.934] iteration 3015 : loss : 0.408794, loss_ce: 0.261937
[01:46:52.188] iteration 3016 : loss : 0.463020, loss_ce: 0.365537
[01:46:52.443] iteration 3017 : loss : 0.404093, loss_ce: 0.245045
[01:46:52.701] iteration 3018 : loss : 0.452588, loss_ce: 0.288346
[01:46:52.957] iteration 3019 : loss : 0.386362, loss_ce: 0.327643
[01:46:53.213] iteration 3020 : loss : 0.408281, loss_ce: 0.346048
[01:46:53.491] iteration 3021 : loss : 0.488849, loss_ce: 0.399175
[01:46:53.752] iteration 3022 : loss : 0.304563, loss_ce: 0.219224
[01:46:54.875] iteration 3023 : loss : 0.463227, loss_ce: 0.370406
[01:46:55.142] iteration 3024 : loss : 0.468981, loss_ce: 0.286292
[01:46:55.396] iteration 3025 : loss : 0.404652, loss_ce: 0.249698
[01:46:55.653] iteration 3026 : loss : 0.283328, loss_ce: 0.200345
[01:46:55.910] iteration 3027 : loss : 0.369795, loss_ce: 0.295607
[01:46:56.166] iteration 3028 : loss : 0.432740, loss_ce: 0.369964
[01:46:56.423] iteration 3029 : loss : 0.440322, loss_ce: 0.315959
[01:46:56.676] iteration 3030 : loss : 0.402112, loss_ce: 0.247886
[01:46:57.897] iteration 3031 : loss : 0.512182, loss_ce: 0.401656
[01:46:58.149] iteration 3032 : loss : 0.486007, loss_ce: 0.347338
[01:46:58.403] iteration 3033 : loss : 0.407332, loss_ce: 0.269048
[01:46:58.656] iteration 3034 : loss : 0.341776, loss_ce: 0.246921
[01:46:58.911] iteration 3035 : loss : 0.371745, loss_ce: 0.227704
[01:46:59.172] iteration 3036 : loss : 0.305114, loss_ce: 0.226005
[01:46:59.428] iteration 3037 : loss : 0.354146, loss_ce: 0.144583
[01:46:59.684] iteration 3038 : loss : 0.268802, loss_ce: 0.219434
[01:47:00.986] iteration 3039 : loss : 0.408364, loss_ce: 0.234865
[01:47:01.243] iteration 3040 : loss : 0.447101, loss_ce: 0.331344
[01:47:01.500] iteration 3041 : loss : 0.399841, loss_ce: 0.258773
[01:47:01.758] iteration 3042 : loss : 0.286403, loss_ce: 0.166754
[01:47:02.013] iteration 3043 : loss : 0.427828, loss_ce: 0.281987
[01:47:02.271] iteration 3044 : loss : 0.358245, loss_ce: 0.256141
[01:47:02.527] iteration 3045 : loss : 0.412583, loss_ce: 0.194337
[01:47:02.784] iteration 3046 : loss : 0.309946, loss_ce: 0.215514
[01:47:03.977] iteration 3047 : loss : 0.452135, loss_ce: 0.338210
[01:47:04.231] iteration 3048 : loss : 0.460941, loss_ce: 0.348344
[01:47:04.487] iteration 3049 : loss : 0.471454, loss_ce: 0.397988
[01:47:04.740] iteration 3050 : loss : 0.431289, loss_ce: 0.310039
[01:47:04.994] iteration 3051 : loss : 0.442268, loss_ce: 0.286734
[01:47:05.252] iteration 3052 : loss : 0.427498, loss_ce: 0.228537
[01:47:05.507] iteration 3053 : loss : 0.443683, loss_ce: 0.249763
[01:47:05.761] iteration 3054 : loss : 0.439984, loss_ce: 0.254344
[01:47:06.966] iteration 3055 : loss : 0.430101, loss_ce: 0.262587
[01:47:07.219] iteration 3056 : loss : 0.412329, loss_ce: 0.225487
[01:47:07.473] iteration 3057 : loss : 0.500584, loss_ce: 0.343039
[01:47:07.724] iteration 3058 : loss : 0.418994, loss_ce: 0.333930
[01:47:07.976] iteration 3059 : loss : 0.458525, loss_ce: 0.264996
[01:47:08.232] iteration 3060 : loss : 0.584404, loss_ce: 0.416343
[01:47:08.486] iteration 3061 : loss : 0.404074, loss_ce: 0.259237
[01:47:08.738] iteration 3062 : loss : 0.375264, loss_ce: 0.184445
[01:47:09.874] iteration 3063 : loss : 0.467347, loss_ce: 0.306417
[01:47:10.130] iteration 3064 : loss : 0.213118, loss_ce: 0.146405
[01:47:10.385] iteration 3065 : loss : 0.422877, loss_ce: 0.341310
[01:47:10.640] iteration 3066 : loss : 0.372219, loss_ce: 0.275404
[01:47:10.894] iteration 3067 : loss : 0.406415, loss_ce: 0.296983
[01:47:11.149] iteration 3068 : loss : 0.355844, loss_ce: 0.298859
[01:47:11.404] iteration 3069 : loss : 0.300536, loss_ce: 0.200889
[01:47:11.657] iteration 3070 : loss : 0.355175, loss_ce: 0.196422
[01:47:12.687] iteration 3071 : loss : 0.394731, loss_ce: 0.274470
[01:47:12.939] iteration 3072 : loss : 0.388792, loss_ce: 0.254328
[01:47:13.197] iteration 3073 : loss : 0.421982, loss_ce: 0.323828
[01:47:13.449] iteration 3074 : loss : 0.408175, loss_ce: 0.204446
[01:47:13.702] iteration 3075 : loss : 0.408910, loss_ce: 0.365622
[01:47:13.961] iteration 3076 : loss : 0.507558, loss_ce: 0.341280
[01:47:14.218] iteration 3077 : loss : 0.442229, loss_ce: 0.221235
[01:47:14.470] iteration 3078 : loss : 0.409305, loss_ce: 0.318720
[01:47:15.311] iteration 3079 : loss : 0.523139, loss_ce: 0.291366
[01:47:15.501] iteration 3080 : loss : 0.482039, loss_ce: 0.209284
[01:47:20.309] iteration 3081 : loss : 0.409827, loss_ce: 0.304536
[01:47:20.626] iteration 3082 : loss : 0.336917, loss_ce: 0.266331
[01:47:21.011] iteration 3083 : loss : 0.394767, loss_ce: 0.248275
[01:47:21.302] iteration 3084 : loss : 0.419554, loss_ce: 0.291800
[01:47:21.555] iteration 3085 : loss : 0.395043, loss_ce: 0.241555
[01:47:21.809] iteration 3086 : loss : 0.417700, loss_ce: 0.258611
[01:47:22.065] iteration 3087 : loss : 0.428085, loss_ce: 0.258284
[01:47:22.320] iteration 3088 : loss : 0.447869, loss_ce: 0.338049
[01:47:23.324] iteration 3089 : loss : 0.419995, loss_ce: 0.329398
[01:47:23.578] iteration 3090 : loss : 0.371375, loss_ce: 0.218861
[01:47:23.833] iteration 3091 : loss : 0.459727, loss_ce: 0.371523
[01:47:24.088] iteration 3092 : loss : 0.360655, loss_ce: 0.260035
[01:47:24.342] iteration 3093 : loss : 0.407354, loss_ce: 0.208604
[01:47:24.594] iteration 3094 : loss : 0.418630, loss_ce: 0.251235
[01:47:24.847] iteration 3095 : loss : 0.486535, loss_ce: 0.343423
[01:47:25.101] iteration 3096 : loss : 0.502438, loss_ce: 0.285897
[01:47:26.363] iteration 3097 : loss : 0.399429, loss_ce: 0.236086
[01:47:26.618] iteration 3098 : loss : 0.490203, loss_ce: 0.506649
[01:47:26.872] iteration 3099 : loss : 0.485309, loss_ce: 0.287901
[01:47:27.124] iteration 3100 : loss : 0.411346, loss_ce: 0.254193
[01:47:27.376] iteration 3101 : loss : 0.370789, loss_ce: 0.272078
[01:47:27.629] iteration 3102 : loss : 0.463907, loss_ce: 0.371108
[01:47:27.880] iteration 3103 : loss : 0.460132, loss_ce: 0.246632
[01:47:28.121] iteration 3104 : loss : 0.430585, loss_ce: 0.327096
[01:47:29.392] iteration 3105 : loss : 0.369391, loss_ce: 0.209019
[01:47:29.665] iteration 3106 : loss : 0.414788, loss_ce: 0.292043
[01:47:29.932] iteration 3107 : loss : 0.378351, loss_ce: 0.277254
[01:47:30.185] iteration 3108 : loss : 0.440014, loss_ce: 0.318300
[01:47:30.439] iteration 3109 : loss : 0.415452, loss_ce: 0.307641
[01:47:30.693] iteration 3110 : loss : 0.392843, loss_ce: 0.257673
[01:47:30.947] iteration 3111 : loss : 0.440868, loss_ce: 0.389426
[01:47:31.201] iteration 3112 : loss : 0.385157, loss_ce: 0.227831
[01:47:32.357] iteration 3113 : loss : 0.406115, loss_ce: 0.236449
[01:47:32.613] iteration 3114 : loss : 0.331087, loss_ce: 0.173318
[01:47:32.869] iteration 3115 : loss : 0.390766, loss_ce: 0.318489
[01:47:33.124] iteration 3116 : loss : 0.433141, loss_ce: 0.328699
[01:47:33.584] iteration 3117 : loss : 0.523705, loss_ce: 0.453613
[01:47:33.837] iteration 3118 : loss : 0.369822, loss_ce: 0.301165
[01:47:34.089] iteration 3119 : loss : 0.419312, loss_ce: 0.285783
[01:47:34.344] iteration 3120 : loss : 0.312687, loss_ce: 0.171243
[01:47:35.259] iteration 3121 : loss : 0.324940, loss_ce: 0.238931
[01:47:35.518] iteration 3122 : loss : 0.393603, loss_ce: 0.221125
[01:47:35.771] iteration 3123 : loss : 0.532302, loss_ce: 0.401960
[01:47:36.031] iteration 3124 : loss : 0.455700, loss_ce: 0.454768
[01:47:36.285] iteration 3125 : loss : 0.324834, loss_ce: 0.228356
[01:47:36.540] iteration 3126 : loss : 0.237453, loss_ce: 0.195133
[01:47:36.796] iteration 3127 : loss : 0.422189, loss_ce: 0.302544
[01:47:37.050] iteration 3128 : loss : 0.406029, loss_ce: 0.228649
[01:47:38.244] iteration 3129 : loss : 0.525090, loss_ce: 0.466114
[01:47:38.504] iteration 3130 : loss : 0.412825, loss_ce: 0.281121
[01:47:38.759] iteration 3131 : loss : 0.480766, loss_ce: 0.352973
[01:47:39.015] iteration 3132 : loss : 0.353938, loss_ce: 0.336014
[01:47:39.271] iteration 3133 : loss : 0.395930, loss_ce: 0.275692
[01:47:39.527] iteration 3134 : loss : 0.326669, loss_ce: 0.304679
[01:47:39.782] iteration 3135 : loss : 0.296598, loss_ce: 0.162229
[01:47:40.038] iteration 3136 : loss : 0.400623, loss_ce: 0.232777
[01:47:41.223] iteration 3137 : loss : 0.338523, loss_ce: 0.244678
[01:47:41.478] iteration 3138 : loss : 0.398146, loss_ce: 0.235587
[01:47:41.733] iteration 3139 : loss : 0.370289, loss_ce: 0.289023
[01:47:41.987] iteration 3140 : loss : 0.283293, loss_ce: 0.236882
[01:47:42.242] iteration 3141 : loss : 0.402477, loss_ce: 0.255668
[01:47:42.495] iteration 3142 : loss : 0.376876, loss_ce: 0.256037
[01:47:42.750] iteration 3143 : loss : 0.321715, loss_ce: 0.208575
[01:47:43.005] iteration 3144 : loss : 0.394548, loss_ce: 0.242067
[01:47:44.084] iteration 3145 : loss : 0.396119, loss_ce: 0.293718
[01:47:44.340] iteration 3146 : loss : 0.293602, loss_ce: 0.189309
[01:47:44.595] iteration 3147 : loss : 0.398806, loss_ce: 0.247051
[01:47:44.850] iteration 3148 : loss : 0.363823, loss_ce: 0.224260
[01:47:45.105] iteration 3149 : loss : 0.433871, loss_ce: 0.302575
[01:47:45.360] iteration 3150 : loss : 0.417055, loss_ce: 0.253477
[01:47:45.636] iteration 3151 : loss : 0.410849, loss_ce: 0.234672
[01:47:45.891] iteration 3152 : loss : 0.429918, loss_ce: 0.315222
[01:47:46.942] iteration 3153 : loss : 0.421388, loss_ce: 0.305590
[01:47:47.198] iteration 3154 : loss : 0.339134, loss_ce: 0.223914
[01:47:47.451] iteration 3155 : loss : 0.374837, loss_ce: 0.196968
[01:47:47.705] iteration 3156 : loss : 0.353063, loss_ce: 0.303641
[01:47:47.960] iteration 3157 : loss : 0.462934, loss_ce: 0.331149
[01:47:48.215] iteration 3158 : loss : 0.450545, loss_ce: 0.321287
[01:47:48.468] iteration 3159 : loss : 0.452627, loss_ce: 0.349844
[01:47:48.725] iteration 3160 : loss : 0.445078, loss_ce: 0.264379
[01:47:49.705] iteration 3161 : loss : 0.427535, loss_ce: 0.394659
[01:47:49.962] iteration 3162 : loss : 0.328593, loss_ce: 0.275948
[01:47:50.218] iteration 3163 : loss : 0.291404, loss_ce: 0.198947
[01:47:50.471] iteration 3164 : loss : 0.580782, loss_ce: 0.515872
[01:47:50.724] iteration 3165 : loss : 0.348909, loss_ce: 0.325969
[01:47:50.979] iteration 3166 : loss : 0.401104, loss_ce: 0.257020
[01:47:51.233] iteration 3167 : loss : 0.379312, loss_ce: 0.213295
[01:47:51.486] iteration 3168 : loss : 0.311434, loss_ce: 0.264104
[01:47:52.586] iteration 3169 : loss : 0.407648, loss_ce: 0.247039
[01:47:52.843] iteration 3170 : loss : 0.333299, loss_ce: 0.255889
[01:47:53.096] iteration 3171 : loss : 0.406162, loss_ce: 0.314093
[01:47:53.352] iteration 3172 : loss : 0.450433, loss_ce: 0.334457
[01:47:53.607] iteration 3173 : loss : 0.539643, loss_ce: 0.361796
[01:47:53.862] iteration 3174 : loss : 0.407570, loss_ce: 0.303207
[01:47:54.115] iteration 3175 : loss : 0.447662, loss_ce: 0.332485
[01:47:54.369] iteration 3176 : loss : 0.422512, loss_ce: 0.258653
[01:47:55.761] iteration 3177 : loss : 0.398506, loss_ce: 0.240414
[01:47:56.018] iteration 3178 : loss : 0.452056, loss_ce: 0.299267
[01:47:56.272] iteration 3179 : loss : 0.367536, loss_ce: 0.189244
[01:47:56.526] iteration 3180 : loss : 0.359314, loss_ce: 0.249313
[01:47:56.779] iteration 3181 : loss : 0.461667, loss_ce: 0.434697
[01:47:57.033] iteration 3182 : loss : 0.437354, loss_ce: 0.334482
[01:47:57.288] iteration 3183 : loss : 0.397730, loss_ce: 0.369439
[01:47:57.544] iteration 3184 : loss : 0.387804, loss_ce: 0.256831
[01:47:58.620] iteration 3185 : loss : 0.472262, loss_ce: 0.382813
[01:47:58.877] iteration 3186 : loss : 0.354911, loss_ce: 0.273386
[01:47:59.134] iteration 3187 : loss : 0.445668, loss_ce: 0.251541
[01:47:59.389] iteration 3188 : loss : 0.410931, loss_ce: 0.207007
[01:47:59.645] iteration 3189 : loss : 0.455028, loss_ce: 0.294968
[01:47:59.901] iteration 3190 : loss : 0.379777, loss_ce: 0.247875
[01:48:00.159] iteration 3191 : loss : 0.416545, loss_ce: 0.297822
[01:48:00.414] iteration 3192 : loss : 0.512819, loss_ce: 0.367720
[01:48:01.585] iteration 3193 : loss : 0.405647, loss_ce: 0.340031
[01:48:01.844] iteration 3194 : loss : 0.384333, loss_ce: 0.241544
[01:48:02.099] iteration 3195 : loss : 0.339777, loss_ce: 0.182131
[01:48:02.356] iteration 3196 : loss : 0.417994, loss_ce: 0.263530
[01:48:02.614] iteration 3197 : loss : 0.469725, loss_ce: 0.373119
[01:48:02.867] iteration 3198 : loss : 0.424620, loss_ce: 0.291149
[01:48:03.123] iteration 3199 : loss : 0.402118, loss_ce: 0.344785
[01:48:03.380] iteration 3200 : loss : 0.423393, loss_ce: 0.304606
[01:48:04.578] iteration 3201 : loss : 0.364728, loss_ce: 0.304067
[01:48:04.835] iteration 3202 : loss : 0.489238, loss_ce: 0.250651
[01:48:05.095] iteration 3203 : loss : 0.344654, loss_ce: 0.256367
[01:48:05.355] iteration 3204 : loss : 0.392980, loss_ce: 0.263601
[01:48:05.610] iteration 3205 : loss : 0.307603, loss_ce: 0.255091
[01:48:05.864] iteration 3206 : loss : 0.399635, loss_ce: 0.170454
[01:48:06.122] iteration 3207 : loss : 0.474522, loss_ce: 0.298095
[01:48:06.378] iteration 3208 : loss : 0.457391, loss_ce: 0.315572
[01:48:07.600] iteration 3209 : loss : 0.421941, loss_ce: 0.205219
[01:48:08.548] iteration 3210 : loss : 0.464047, loss_ce: 0.369942
[01:48:08.805] iteration 3211 : loss : 0.403828, loss_ce: 0.250000
[01:48:09.061] iteration 3212 : loss : 0.373155, loss_ce: 0.204193
[01:48:09.320] iteration 3213 : loss : 0.421430, loss_ce: 0.289338
[01:48:09.577] iteration 3214 : loss : 0.378170, loss_ce: 0.287636
[01:48:09.832] iteration 3215 : loss : 0.472196, loss_ce: 0.299744
[01:48:10.089] iteration 3216 : loss : 0.389298, loss_ce: 0.251825
[01:48:10.652] iteration 3217 : loss : 0.411053, loss_ce: 0.251438
[01:48:11.600] iteration 3218 : loss : 0.428105, loss_ce: 0.285547
[01:48:11.855] iteration 3219 : loss : 0.321722, loss_ce: 0.206348
[01:48:12.111] iteration 3220 : loss : 0.420105, loss_ce: 0.269407
[01:48:12.366] iteration 3221 : loss : 0.380628, loss_ce: 0.247501
[01:48:12.622] iteration 3222 : loss : 0.439237, loss_ce: 0.306718
[01:48:12.879] iteration 3223 : loss : 0.418536, loss_ce: 0.268617
[01:48:13.137] iteration 3224 : loss : 0.341302, loss_ce: 0.325130
[01:48:13.660] iteration 3225 : loss : 0.329081, loss_ce: 0.182789
[01:48:15.244] iteration 3226 : loss : 0.334537, loss_ce: 0.200848
[01:48:15.498] iteration 3227 : loss : 0.433737, loss_ce: 0.243711
[01:48:15.756] iteration 3228 : loss : 0.423413, loss_ce: 0.285152
[01:48:16.013] iteration 3229 : loss : 0.365618, loss_ce: 0.178194
[01:48:16.267] iteration 3230 : loss : 0.434510, loss_ce: 0.259304
[01:48:16.525] iteration 3231 : loss : 0.532385, loss_ce: 0.351849
[01:48:16.784] iteration 3232 : loss : 0.303067, loss_ce: 0.190518
[01:48:17.040] iteration 3233 : loss : 0.434711, loss_ce: 0.307979
[01:48:18.243] iteration 3234 : loss : 0.412798, loss_ce: 0.232164
[01:48:18.498] iteration 3235 : loss : 0.362696, loss_ce: 0.238305
[01:48:18.766] iteration 3236 : loss : 0.452171, loss_ce: 0.205971
[01:48:19.023] iteration 3237 : loss : 0.423106, loss_ce: 0.256156
[01:48:19.279] iteration 3238 : loss : 0.349128, loss_ce: 0.213269
[01:48:19.536] iteration 3239 : loss : 0.427881, loss_ce: 0.240028
[01:48:19.793] iteration 3240 : loss : 0.413662, loss_ce: 0.263705
[01:48:20.051] iteration 3241 : loss : 0.249644, loss_ce: 0.218704
[01:48:21.249] iteration 3242 : loss : 0.332684, loss_ce: 0.249596
[01:48:21.502] iteration 3243 : loss : 0.360677, loss_ce: 0.293323
[01:48:21.756] iteration 3244 : loss : 0.290260, loss_ce: 0.161633
[01:48:22.010] iteration 3245 : loss : 0.510742, loss_ce: 0.405337
[01:48:22.262] iteration 3246 : loss : 0.488379, loss_ce: 0.338268
[01:48:22.523] iteration 3247 : loss : 0.440199, loss_ce: 0.328933
[01:48:22.780] iteration 3248 : loss : 0.400198, loss_ce: 0.221771
[01:48:23.191] iteration 3249 : loss : 0.393045, loss_ce: 0.245456
[01:48:24.281] iteration 3250 : loss : 0.457178, loss_ce: 0.280707
[01:48:24.536] iteration 3251 : loss : 0.417186, loss_ce: 0.281068
[01:48:24.789] iteration 3252 : loss : 0.481601, loss_ce: 0.357505
[01:48:25.044] iteration 3253 : loss : 0.303420, loss_ce: 0.223044
[01:48:25.304] iteration 3254 : loss : 0.449393, loss_ce: 0.377801
[01:48:25.558] iteration 3255 : loss : 0.421279, loss_ce: 0.250013
[01:48:25.811] iteration 3256 : loss : 0.477226, loss_ce: 0.296655
[01:48:26.068] iteration 3257 : loss : 0.431180, loss_ce: 0.305457
[01:48:27.266] iteration 3258 : loss : 0.536109, loss_ce: 0.456900
[01:48:27.519] iteration 3259 : loss : 0.491453, loss_ce: 0.497623
[01:48:27.773] iteration 3260 : loss : 0.527722, loss_ce: 0.427959
[01:48:28.027] iteration 3261 : loss : 0.409845, loss_ce: 0.287453
[01:48:28.285] iteration 3262 : loss : 0.276754, loss_ce: 0.209661
[01:48:28.544] iteration 3263 : loss : 0.339764, loss_ce: 0.180097
[01:48:28.798] iteration 3264 : loss : 0.326992, loss_ce: 0.206866
[01:48:29.054] iteration 3265 : loss : 0.446938, loss_ce: 0.263414
[01:48:30.445] iteration 3266 : loss : 0.437763, loss_ce: 0.308646
[01:48:30.705] iteration 3267 : loss : 0.547261, loss_ce: 0.401071
[01:48:30.962] iteration 3268 : loss : 0.425252, loss_ce: 0.300390
[01:48:31.219] iteration 3269 : loss : 0.407916, loss_ce: 0.339207
[01:48:31.495] iteration 3270 : loss : 0.482054, loss_ce: 0.340163
[01:48:31.864] iteration 3271 : loss : 0.356643, loss_ce: 0.222633
[01:48:32.184] iteration 3272 : loss : 0.446142, loss_ce: 0.248081
[01:48:32.511] iteration 3273 : loss : 0.453549, loss_ce: 0.326098
[01:48:34.164] iteration 3274 : loss : 0.491876, loss_ce: 0.327042
[01:48:34.421] iteration 3275 : loss : 0.445072, loss_ce: 0.273779
[01:48:34.676] iteration 3276 : loss : 0.346171, loss_ce: 0.163134
[01:48:34.931] iteration 3277 : loss : 0.576097, loss_ce: 0.431216
[01:48:35.185] iteration 3278 : loss : 0.524742, loss_ce: 0.374124
[01:48:35.453] iteration 3279 : loss : 0.473129, loss_ce: 0.359721
[01:48:35.706] iteration 3280 : loss : 0.307997, loss_ce: 0.199151
[01:48:35.963] iteration 3281 : loss : 0.318980, loss_ce: 0.209871
[01:48:37.299] iteration 3282 : loss : 0.312352, loss_ce: 0.228120
[01:48:37.553] iteration 3283 : loss : 0.473893, loss_ce: 0.231151
[01:48:37.812] iteration 3284 : loss : 0.341883, loss_ce: 0.187606
[01:48:38.068] iteration 3285 : loss : 0.417180, loss_ce: 0.183629
[01:48:38.324] iteration 3286 : loss : 0.459158, loss_ce: 0.356203
[01:48:38.580] iteration 3287 : loss : 0.466024, loss_ce: 0.437311
[01:48:38.840] iteration 3288 : loss : 0.522211, loss_ce: 0.406568
[01:48:39.095] iteration 3289 : loss : 0.426234, loss_ce: 0.227712
[01:48:40.109] iteration 3290 : loss : 0.471953, loss_ce: 0.408321
[01:48:40.362] iteration 3291 : loss : 0.510068, loss_ce: 0.344031
[01:48:40.617] iteration 3292 : loss : 0.401186, loss_ce: 0.230338
[01:48:40.870] iteration 3293 : loss : 0.539342, loss_ce: 0.359430
[01:48:41.123] iteration 3294 : loss : 0.524253, loss_ce: 0.420994
[01:48:41.376] iteration 3295 : loss : 0.328225, loss_ce: 0.212785
[01:48:41.632] iteration 3296 : loss : 0.403455, loss_ce: 0.267702
[01:48:41.887] iteration 3297 : loss : 0.418745, loss_ce: 0.236317
[01:48:42.809] iteration 3298 : loss : 0.519646, loss_ce: 0.406746
[01:48:43.060] iteration 3299 : loss : 0.479966, loss_ce: 0.328552
[01:48:43.260] iteration 3300 : loss : 0.825310, loss_ce: 0.816693
[01:48:48.044] iteration 3301 : loss : 0.390431, loss_ce: 0.291716
[01:48:48.308] iteration 3302 : loss : 0.454395, loss_ce: 0.285542
[01:48:48.562] iteration 3303 : loss : 0.379028, loss_ce: 0.171497
[01:48:48.816] iteration 3304 : loss : 0.324061, loss_ce: 0.204128
[01:48:49.076] iteration 3305 : loss : 0.410073, loss_ce: 0.274648
[01:48:49.330] iteration 3306 : loss : 0.374946, loss_ce: 0.274753
[01:48:49.583] iteration 3307 : loss : 0.363379, loss_ce: 0.227154
[01:48:49.836] iteration 3308 : loss : 0.373820, loss_ce: 0.243136
[01:48:50.939] iteration 3309 : loss : 0.395310, loss_ce: 0.253133
[01:48:51.194] iteration 3310 : loss : 0.322606, loss_ce: 0.340872
[01:48:51.447] iteration 3311 : loss : 0.469138, loss_ce: 0.255082
[01:48:51.700] iteration 3312 : loss : 0.402680, loss_ce: 0.279121
[01:48:51.954] iteration 3313 : loss : 0.451736, loss_ce: 0.335029
[01:48:52.207] iteration 3314 : loss : 0.443712, loss_ce: 0.246898
[01:48:52.460] iteration 3315 : loss : 0.394440, loss_ce: 0.308579
[01:48:52.713] iteration 3316 : loss : 0.509208, loss_ce: 0.374320
[01:48:53.809] iteration 3317 : loss : 0.416279, loss_ce: 0.239126
[01:48:54.065] iteration 3318 : loss : 0.453675, loss_ce: 0.340669
[01:48:54.321] iteration 3319 : loss : 0.410216, loss_ce: 0.287883
[01:48:54.899] iteration 3320 : loss : 0.381087, loss_ce: 0.242402
[01:48:55.152] iteration 3321 : loss : 0.439720, loss_ce: 0.302461
[01:48:55.407] iteration 3322 : loss : 0.381676, loss_ce: 0.246655
[01:48:55.665] iteration 3323 : loss : 0.491103, loss_ce: 0.298861
[01:48:55.920] iteration 3324 : loss : 0.300292, loss_ce: 0.200487
[01:48:56.595] iteration 3325 : loss : 0.497534, loss_ce: 0.277640
[01:48:56.855] iteration 3326 : loss : 0.509117, loss_ce: 0.343392
[01:48:57.110] iteration 3327 : loss : 0.394079, loss_ce: 0.221267
[01:48:57.858] iteration 3328 : loss : 0.429715, loss_ce: 0.343327
[01:48:58.113] iteration 3329 : loss : 0.472976, loss_ce: 0.255216
[01:48:58.366] iteration 3330 : loss : 0.370320, loss_ce: 0.305997
[01:48:58.620] iteration 3331 : loss : 0.319435, loss_ce: 0.209002
[01:48:58.873] iteration 3332 : loss : 0.355758, loss_ce: 0.198545
[01:48:59.507] iteration 3333 : loss : 0.359701, loss_ce: 0.294715
[01:48:59.765] iteration 3334 : loss : 0.403131, loss_ce: 0.367638
[01:49:00.020] iteration 3335 : loss : 0.363299, loss_ce: 0.201619
[01:49:00.840] iteration 3336 : loss : 0.280423, loss_ce: 0.180091
[01:49:01.097] iteration 3337 : loss : 0.450173, loss_ce: 0.429539
[01:49:01.351] iteration 3338 : loss : 0.335895, loss_ce: 0.219064
[01:49:01.611] iteration 3339 : loss : 0.376027, loss_ce: 0.270080
[01:49:01.869] iteration 3340 : loss : 0.321656, loss_ce: 0.215516
[01:49:02.432] iteration 3341 : loss : 0.401319, loss_ce: 0.274899
[01:49:02.687] iteration 3342 : loss : 0.448541, loss_ce: 0.292698
[01:49:02.944] iteration 3343 : loss : 0.340928, loss_ce: 0.288824
[01:49:04.275] iteration 3344 : loss : 0.298412, loss_ce: 0.183379
[01:49:04.513] iteration 3345 : loss : 0.272752, loss_ce: 0.239072
[01:49:04.753] iteration 3346 : loss : 0.326486, loss_ce: 0.280339
[01:49:04.988] iteration 3347 : loss : 0.486700, loss_ce: 0.333232
[01:49:05.228] iteration 3348 : loss : 0.350063, loss_ce: 0.226098
[01:49:06.186] iteration 3349 : loss : 0.449133, loss_ce: 0.312126
[01:49:06.490] iteration 3350 : loss : 0.405529, loss_ce: 0.312578
[01:49:06.784] iteration 3351 : loss : 0.422170, loss_ce: 0.411053
[01:49:07.461] iteration 3352 : loss : 0.471686, loss_ce: 0.360031
[01:49:07.697] iteration 3353 : loss : 0.390014, loss_ce: 0.172065
[01:49:07.958] iteration 3354 : loss : 0.356363, loss_ce: 0.254961
[01:49:08.210] iteration 3355 : loss : 0.518470, loss_ce: 0.319203
[01:49:08.439] iteration 3356 : loss : 0.376055, loss_ce: 0.271297
[01:49:09.240] iteration 3357 : loss : 0.302126, loss_ce: 0.237252
[01:49:09.471] iteration 3358 : loss : 0.334225, loss_ce: 0.216745
[01:49:09.708] iteration 3359 : loss : 0.430744, loss_ce: 0.252064
[01:49:10.446] iteration 3360 : loss : 0.372172, loss_ce: 0.245321
[01:49:10.676] iteration 3361 : loss : 0.425063, loss_ce: 0.281010
[01:49:10.907] iteration 3362 : loss : 0.550307, loss_ce: 0.379076
[01:49:11.145] iteration 3363 : loss : 0.463693, loss_ce: 0.381793
[01:49:11.384] iteration 3364 : loss : 0.520400, loss_ce: 0.443969
[01:49:12.241] iteration 3365 : loss : 0.466841, loss_ce: 0.323604
[01:49:12.478] iteration 3366 : loss : 0.350471, loss_ce: 0.209677
[01:49:12.714] iteration 3367 : loss : 0.390862, loss_ce: 0.237494
[01:49:13.482] iteration 3368 : loss : 0.362142, loss_ce: 0.280911
[01:49:13.715] iteration 3369 : loss : 0.587691, loss_ce: 0.383118
[01:49:13.949] iteration 3370 : loss : 0.536928, loss_ce: 0.346751
[01:49:14.184] iteration 3371 : loss : 0.416806, loss_ce: 0.257347
[01:49:14.442] iteration 3372 : loss : 0.530246, loss_ce: 0.458125
[01:49:15.280] iteration 3373 : loss : 0.345494, loss_ce: 0.144054
[01:49:15.534] iteration 3374 : loss : 0.516996, loss_ce: 0.445762
[01:49:15.787] iteration 3375 : loss : 0.225925, loss_ce: 0.171781
[01:49:16.477] iteration 3376 : loss : 0.374624, loss_ce: 0.244207
[01:49:16.731] iteration 3377 : loss : 0.304256, loss_ce: 0.194681
[01:49:16.986] iteration 3378 : loss : 0.273953, loss_ce: 0.220360
[01:49:17.242] iteration 3379 : loss : 0.452717, loss_ce: 0.281234
[01:49:17.498] iteration 3380 : loss : 0.437214, loss_ce: 0.289864
[01:49:18.348] iteration 3381 : loss : 0.453804, loss_ce: 0.412038
[01:49:18.604] iteration 3382 : loss : 0.344799, loss_ce: 0.258918
[01:49:19.063] iteration 3383 : loss : 0.412334, loss_ce: 0.335389
[01:49:19.470] iteration 3384 : loss : 0.348778, loss_ce: 0.268215
[01:49:19.724] iteration 3385 : loss : 0.381880, loss_ce: 0.307906
[01:49:19.978] iteration 3386 : loss : 0.246495, loss_ce: 0.188271
[01:49:20.232] iteration 3387 : loss : 0.449376, loss_ce: 0.315218
[01:49:20.488] iteration 3388 : loss : 0.405773, loss_ce: 0.232839
[01:49:21.264] iteration 3389 : loss : 0.447692, loss_ce: 0.240842
[01:49:21.518] iteration 3390 : loss : 0.401939, loss_ce: 0.299783
[01:49:21.772] iteration 3391 : loss : 0.369124, loss_ce: 0.258869
[01:49:22.557] iteration 3392 : loss : 0.314864, loss_ce: 0.274986
[01:49:22.811] iteration 3393 : loss : 0.328829, loss_ce: 0.224451
[01:49:23.064] iteration 3394 : loss : 0.418055, loss_ce: 0.248322
[01:49:23.320] iteration 3395 : loss : 0.340783, loss_ce: 0.236745
[01:49:23.573] iteration 3396 : loss : 0.359352, loss_ce: 0.297187
[01:49:24.184] iteration 3397 : loss : 0.571916, loss_ce: 0.360372
[01:49:24.439] iteration 3398 : loss : 0.505710, loss_ce: 0.369017
[01:49:24.695] iteration 3399 : loss : 0.489967, loss_ce: 0.380570
[01:49:25.314] iteration 3400 : loss : 0.333073, loss_ce: 0.230092
[01:49:25.567] iteration 3401 : loss : 0.453928, loss_ce: 0.298534
[01:49:25.821] iteration 3402 : loss : 0.286047, loss_ce: 0.169178
[01:49:26.074] iteration 3403 : loss : 0.356067, loss_ce: 0.241562
[01:49:26.330] iteration 3404 : loss : 0.484133, loss_ce: 0.269852
[01:49:27.044] iteration 3405 : loss : 0.334648, loss_ce: 0.185985
[01:49:27.298] iteration 3406 : loss : 0.359248, loss_ce: 0.237899
[01:49:27.551] iteration 3407 : loss : 0.428998, loss_ce: 0.296389
[01:49:28.259] iteration 3408 : loss : 0.411360, loss_ce: 0.206838
[01:49:28.512] iteration 3409 : loss : 0.403553, loss_ce: 0.295548
[01:49:28.764] iteration 3410 : loss : 0.350279, loss_ce: 0.285215
[01:49:29.019] iteration 3411 : loss : 0.484805, loss_ce: 0.349950
[01:49:29.277] iteration 3412 : loss : 0.258233, loss_ce: 0.191627
[01:49:29.902] iteration 3413 : loss : 0.451485, loss_ce: 0.329271
[01:49:30.158] iteration 3414 : loss : 0.432763, loss_ce: 0.295131
[01:49:30.411] iteration 3415 : loss : 0.497226, loss_ce: 0.285632
[01:49:31.098] iteration 3416 : loss : 0.431873, loss_ce: 0.262985
[01:49:31.351] iteration 3417 : loss : 0.339651, loss_ce: 0.292317
[01:49:31.605] iteration 3418 : loss : 0.422704, loss_ce: 0.272140
[01:49:31.860] iteration 3419 : loss : 0.474614, loss_ce: 0.396353
[01:49:32.116] iteration 3420 : loss : 0.321926, loss_ce: 0.240088
[01:49:32.739] iteration 3421 : loss : 0.547261, loss_ce: 0.413765
[01:49:32.996] iteration 3422 : loss : 0.434700, loss_ce: 0.340961
[01:49:33.249] iteration 3423 : loss : 0.302334, loss_ce: 0.199527
[01:49:33.971] iteration 3424 : loss : 0.225365, loss_ce: 0.169412
[01:49:34.224] iteration 3425 : loss : 0.405568, loss_ce: 0.242135
[01:49:34.476] iteration 3426 : loss : 0.447091, loss_ce: 0.242829
[01:49:34.731] iteration 3427 : loss : 0.443364, loss_ce: 0.279404
[01:49:34.985] iteration 3428 : loss : 0.499858, loss_ce: 0.312994
[01:49:35.650] iteration 3429 : loss : 0.317115, loss_ce: 0.217518
[01:49:35.907] iteration 3430 : loss : 0.465295, loss_ce: 0.359282
[01:49:36.161] iteration 3431 : loss : 0.286319, loss_ce: 0.173148
[01:49:37.015] iteration 3432 : loss : 0.348983, loss_ce: 0.284851
[01:49:37.269] iteration 3433 : loss : 0.355656, loss_ce: 0.189961
[01:49:37.523] iteration 3434 : loss : 0.385781, loss_ce: 0.262038
[01:49:37.778] iteration 3435 : loss : 0.369732, loss_ce: 0.196880
[01:49:38.035] iteration 3436 : loss : 0.426082, loss_ce: 0.345007
[01:49:38.673] iteration 3437 : loss : 0.404173, loss_ce: 0.224509
[01:49:38.931] iteration 3438 : loss : 0.451885, loss_ce: 0.345932
[01:49:39.188] iteration 3439 : loss : 0.449783, loss_ce: 0.320704
[01:49:40.036] iteration 3440 : loss : 0.511292, loss_ce: 0.262356
[01:49:40.293] iteration 3441 : loss : 0.297920, loss_ce: 0.263506
[01:49:40.546] iteration 3442 : loss : 0.376505, loss_ce: 0.236115
[01:49:40.800] iteration 3443 : loss : 0.463255, loss_ce: 0.300428
[01:49:41.071] iteration 3444 : loss : 0.406673, loss_ce: 0.205093
[01:49:41.798] iteration 3445 : loss : 0.415216, loss_ce: 0.240703
[01:49:42.186] iteration 3446 : loss : 0.299873, loss_ce: 0.172897
[01:49:42.488] iteration 3447 : loss : 0.586454, loss_ce: 0.527680
[01:49:43.218] iteration 3448 : loss : 0.398789, loss_ce: 0.246276
[01:49:43.476] iteration 3449 : loss : 0.421800, loss_ce: 0.227383
[01:49:43.732] iteration 3450 : loss : 0.344741, loss_ce: 0.168367
[01:49:43.988] iteration 3451 : loss : 0.472843, loss_ce: 0.392731
[01:49:44.242] iteration 3452 : loss : 0.476517, loss_ce: 0.328963
[01:49:44.947] iteration 3453 : loss : 0.405934, loss_ce: 0.315967
[01:49:45.204] iteration 3454 : loss : 0.369005, loss_ce: 0.181167
[01:49:45.458] iteration 3455 : loss : 0.529246, loss_ce: 0.328896
[01:49:46.240] iteration 3456 : loss : 0.351509, loss_ce: 0.217395
[01:49:46.496] iteration 3457 : loss : 0.395834, loss_ce: 0.303725
[01:49:46.752] iteration 3458 : loss : 0.314270, loss_ce: 0.226899
[01:49:47.009] iteration 3459 : loss : 0.450353, loss_ce: 0.276295
[01:49:47.264] iteration 3460 : loss : 0.351226, loss_ce: 0.256659
[01:49:47.931] iteration 3461 : loss : 0.484728, loss_ce: 0.341798
[01:49:48.186] iteration 3462 : loss : 0.294627, loss_ce: 0.197912
[01:49:48.439] iteration 3463 : loss : 0.372142, loss_ce: 0.185816
[01:49:49.216] iteration 3464 : loss : 0.358465, loss_ce: 0.222038
[01:49:49.469] iteration 3465 : loss : 0.379276, loss_ce: 0.288254
[01:49:49.725] iteration 3466 : loss : 0.361185, loss_ce: 0.265533
[01:49:49.978] iteration 3467 : loss : 0.393675, loss_ce: 0.272005
[01:49:50.235] iteration 3468 : loss : 0.344419, loss_ce: 0.207587
[01:49:50.905] iteration 3469 : loss : 0.430126, loss_ce: 0.294309
[01:49:51.162] iteration 3470 : loss : 0.361323, loss_ce: 0.304377
[01:49:51.431] iteration 3471 : loss : 0.425228, loss_ce: 0.220638
[01:49:52.148] iteration 3472 : loss : 0.431899, loss_ce: 0.286982
[01:49:52.402] iteration 3473 : loss : 0.451921, loss_ce: 0.254524
[01:49:52.658] iteration 3474 : loss : 0.447146, loss_ce: 0.329485
[01:49:52.911] iteration 3475 : loss : 0.438486, loss_ce: 0.327558
[01:49:53.167] iteration 3476 : loss : 0.387982, loss_ce: 0.251625
[01:49:53.942] iteration 3477 : loss : 0.437654, loss_ce: 0.348393
[01:49:54.195] iteration 3478 : loss : 0.328044, loss_ce: 0.216057
[01:49:54.448] iteration 3479 : loss : 0.443724, loss_ce: 0.344154
[01:49:55.115] iteration 3480 : loss : 0.501981, loss_ce: 0.260751
[01:49:55.370] iteration 3481 : loss : 0.447920, loss_ce: 0.311124
[01:49:55.626] iteration 3482 : loss : 0.325818, loss_ce: 0.255218
[01:49:55.906] iteration 3483 : loss : 0.374427, loss_ce: 0.305806
[01:49:56.165] iteration 3484 : loss : 0.360657, loss_ce: 0.239721
[01:49:56.884] iteration 3485 : loss : 0.461445, loss_ce: 0.313530
[01:49:57.139] iteration 3486 : loss : 0.494510, loss_ce: 0.306465
[01:49:57.395] iteration 3487 : loss : 0.522349, loss_ce: 0.319232
[01:49:58.127] iteration 3488 : loss : 0.459601, loss_ce: 0.374717
[01:49:58.382] iteration 3489 : loss : 0.464132, loss_ce: 0.360175
[01:49:58.639] iteration 3490 : loss : 0.377477, loss_ce: 0.244264
[01:49:58.892] iteration 3491 : loss : 0.425161, loss_ce: 0.281602
[01:49:59.148] iteration 3492 : loss : 0.441593, loss_ce: 0.316253
[01:49:59.802] iteration 3493 : loss : 0.414058, loss_ce: 0.349375
[01:50:00.059] iteration 3494 : loss : 0.409155, loss_ce: 0.297769
[01:50:00.320] iteration 3495 : loss : 0.537165, loss_ce: 0.318919
[01:50:01.093] iteration 3496 : loss : 0.402757, loss_ce: 0.276698
[01:50:01.347] iteration 3497 : loss : 0.514493, loss_ce: 0.432438
[01:50:01.601] iteration 3498 : loss : 0.499987, loss_ce: 0.282950
[01:50:01.858] iteration 3499 : loss : 0.372616, loss_ce: 0.254775
[01:50:02.112] iteration 3500 : loss : 0.437295, loss_ce: 0.303630
[01:50:02.703] iteration 3501 : loss : 0.502325, loss_ce: 0.337711
[01:50:02.958] iteration 3502 : loss : 0.409651, loss_ce: 0.296943
[01:50:03.213] iteration 3503 : loss : 0.426567, loss_ce: 0.314853
[01:50:03.933] iteration 3504 : loss : 0.435825, loss_ce: 0.322065
[01:50:04.185] iteration 3505 : loss : 0.341715, loss_ce: 0.238642
[01:50:04.439] iteration 3506 : loss : 0.422727, loss_ce: 0.276383
[01:50:04.694] iteration 3507 : loss : 0.420115, loss_ce: 0.337474
[01:50:04.950] iteration 3508 : loss : 0.366125, loss_ce: 0.299525
[01:50:05.585] iteration 3509 : loss : 0.314365, loss_ce: 0.209127
[01:50:05.839] iteration 3510 : loss : 0.300777, loss_ce: 0.226944
[01:50:06.092] iteration 3511 : loss : 0.411667, loss_ce: 0.292845
[01:50:06.796] iteration 3512 : loss : 0.379186, loss_ce: 0.330292
[01:50:07.050] iteration 3513 : loss : 0.464105, loss_ce: 0.272367
[01:50:07.306] iteration 3514 : loss : 0.359735, loss_ce: 0.246317
[01:50:07.562] iteration 3515 : loss : 0.373899, loss_ce: 0.250795
[01:50:07.813] iteration 3516 : loss : 0.281672, loss_ce: 0.218990
[01:50:08.253] iteration 3517 : loss : 0.387556, loss_ce: 0.245849
[01:50:08.505] iteration 3518 : loss : 0.489752, loss_ce: 0.298715
[01:50:08.757] iteration 3519 : loss : 0.377650, loss_ce: 0.303822
[01:50:09.045] iteration 3520 : loss : 0.562976, loss_ce: 0.358092
[01:50:13.502] iteration 3521 : loss : 0.345300, loss_ce: 0.236126
[01:50:13.731] iteration 3522 : loss : 0.496556, loss_ce: 0.320945
[01:50:13.966] iteration 3523 : loss : 0.299077, loss_ce: 0.217984
[01:50:14.193] iteration 3524 : loss : 0.303751, loss_ce: 0.213185
[01:50:14.427] iteration 3525 : loss : 0.463371, loss_ce: 0.253503
[01:50:14.659] iteration 3526 : loss : 0.430041, loss_ce: 0.240671
[01:50:14.891] iteration 3527 : loss : 0.414138, loss_ce: 0.343951
[01:50:15.125] iteration 3528 : loss : 0.490044, loss_ce: 0.389061
[01:50:16.552] iteration 3529 : loss : 0.261890, loss_ce: 0.231929
[01:50:16.868] iteration 3530 : loss : 0.287657, loss_ce: 0.239501
[01:50:17.157] iteration 3531 : loss : 0.507073, loss_ce: 0.304909
[01:50:17.410] iteration 3532 : loss : 0.412451, loss_ce: 0.211840
[01:50:17.663] iteration 3533 : loss : 0.484888, loss_ce: 0.343723
[01:50:17.919] iteration 3534 : loss : 0.323565, loss_ce: 0.178526
[01:50:18.172] iteration 3535 : loss : 0.354237, loss_ce: 0.200218
[01:50:18.426] iteration 3536 : loss : 0.363208, loss_ce: 0.208591
[01:50:19.708] iteration 3537 : loss : 0.403968, loss_ce: 0.253164
[01:50:19.964] iteration 3538 : loss : 0.356518, loss_ce: 0.270932
[01:50:20.220] iteration 3539 : loss : 0.318467, loss_ce: 0.212672
[01:50:21.105] iteration 3540 : loss : 0.383193, loss_ce: 0.301996
[01:50:21.363] iteration 3541 : loss : 0.340998, loss_ce: 0.229788
[01:50:21.619] iteration 3542 : loss : 0.374955, loss_ce: 0.228797
[01:50:21.890] iteration 3543 : loss : 0.419638, loss_ce: 0.268397
[01:50:22.145] iteration 3544 : loss : 0.483682, loss_ce: 0.340600
[01:50:22.761] iteration 3545 : loss : 0.505923, loss_ce: 0.401471
[01:50:23.017] iteration 3546 : loss : 0.347460, loss_ce: 0.191915
[01:50:23.276] iteration 3547 : loss : 0.375888, loss_ce: 0.222281
[01:50:24.205] iteration 3548 : loss : 0.402874, loss_ce: 0.276550
[01:50:24.459] iteration 3549 : loss : 0.374692, loss_ce: 0.207259
[01:50:24.712] iteration 3550 : loss : 0.310212, loss_ce: 0.246015
[01:50:24.966] iteration 3551 : loss : 0.361614, loss_ce: 0.222296
[01:50:25.223] iteration 3552 : loss : 0.416972, loss_ce: 0.181352
[01:50:26.365] iteration 3553 : loss : 0.440969, loss_ce: 0.328243
[01:50:26.619] iteration 3554 : loss : 0.294829, loss_ce: 0.144633
[01:50:26.877] iteration 3555 : loss : 0.387395, loss_ce: 0.263274
[01:50:27.255] iteration 3556 : loss : 0.480337, loss_ce: 0.309682
[01:50:27.508] iteration 3557 : loss : 0.418662, loss_ce: 0.274861
[01:50:27.761] iteration 3558 : loss : 0.361478, loss_ce: 0.347760
[01:50:28.015] iteration 3559 : loss : 0.348551, loss_ce: 0.213212
[01:50:28.271] iteration 3560 : loss : 0.493533, loss_ce: 0.443783
[01:50:29.362] iteration 3561 : loss : 0.472725, loss_ce: 0.279607
[01:50:29.615] iteration 3562 : loss : 0.446175, loss_ce: 0.307966
[01:50:29.872] iteration 3563 : loss : 0.430936, loss_ce: 0.231595
[01:50:30.376] iteration 3564 : loss : 0.404340, loss_ce: 0.344028
[01:50:30.631] iteration 3565 : loss : 0.349926, loss_ce: 0.212136
[01:50:30.895] iteration 3566 : loss : 0.503412, loss_ce: 0.379440
[01:50:31.162] iteration 3567 : loss : 0.456472, loss_ce: 0.365166
[01:50:31.418] iteration 3568 : loss : 0.412960, loss_ce: 0.215615
[01:50:32.512] iteration 3569 : loss : 0.506782, loss_ce: 0.295410
[01:50:32.785] iteration 3570 : loss : 0.344319, loss_ce: 0.245036
[01:50:33.043] iteration 3571 : loss : 0.494160, loss_ce: 0.344486
[01:50:33.424] iteration 3572 : loss : 0.436032, loss_ce: 0.237131
[01:50:33.682] iteration 3573 : loss : 0.362698, loss_ce: 0.267859
[01:50:33.936] iteration 3574 : loss : 0.339289, loss_ce: 0.231647
[01:50:34.192] iteration 3575 : loss : 0.411376, loss_ce: 0.274368
[01:50:34.450] iteration 3576 : loss : 0.423184, loss_ce: 0.212671
[01:50:35.535] iteration 3577 : loss : 0.461090, loss_ce: 0.248187
[01:50:35.790] iteration 3578 : loss : 0.494533, loss_ce: 0.362994
[01:50:36.044] iteration 3579 : loss : 0.456133, loss_ce: 0.283093
[01:50:36.417] iteration 3580 : loss : 0.442865, loss_ce: 0.242958
[01:50:36.671] iteration 3581 : loss : 0.377796, loss_ce: 0.297312
[01:50:36.929] iteration 3582 : loss : 0.350753, loss_ce: 0.167841
[01:50:37.188] iteration 3583 : loss : 0.391219, loss_ce: 0.317217
[01:50:37.445] iteration 3584 : loss : 0.428957, loss_ce: 0.234029
[01:50:39.458] iteration 3585 : loss : 0.392197, loss_ce: 0.235227
[01:50:39.715] iteration 3586 : loss : 0.422476, loss_ce: 0.208978
[01:50:39.967] iteration 3587 : loss : 0.459473, loss_ce: 0.290028
[01:50:40.226] iteration 3588 : loss : 0.371238, loss_ce: 0.169641
[01:50:40.480] iteration 3589 : loss : 0.241946, loss_ce: 0.125192
[01:50:40.734] iteration 3590 : loss : 0.522255, loss_ce: 0.313338
[01:50:40.989] iteration 3591 : loss : 0.410228, loss_ce: 0.263693
[01:50:41.243] iteration 3592 : loss : 0.430613, loss_ce: 0.227015
[01:50:42.316] iteration 3593 : loss : 0.471050, loss_ce: 0.283939
[01:50:42.571] iteration 3594 : loss : 0.525033, loss_ce: 0.370063
[01:50:42.825] iteration 3595 : loss : 0.408799, loss_ce: 0.265369
[01:50:43.083] iteration 3596 : loss : 0.432239, loss_ce: 0.248823
[01:50:43.320] iteration 3597 : loss : 0.583748, loss_ce: 0.431067
[01:50:43.546] iteration 3598 : loss : 0.415746, loss_ce: 0.317686
[01:50:43.783] iteration 3599 : loss : 0.360113, loss_ce: 0.220295
[01:50:44.014] iteration 3600 : loss : 0.396506, loss_ce: 0.253642
[01:50:45.128] iteration 3601 : loss : 0.278186, loss_ce: 0.236478
[01:50:45.368] iteration 3602 : loss : 0.388497, loss_ce: 0.235022
[01:50:45.602] iteration 3603 : loss : 0.322784, loss_ce: 0.210904
[01:50:45.845] iteration 3604 : loss : 0.415061, loss_ce: 0.240683
[01:50:46.086] iteration 3605 : loss : 0.523043, loss_ce: 0.333814
[01:50:46.329] iteration 3606 : loss : 0.387021, loss_ce: 0.221213
[01:50:46.566] iteration 3607 : loss : 0.424627, loss_ce: 0.273892
[01:50:46.822] iteration 3608 : loss : 0.399011, loss_ce: 0.214136
[01:50:48.102] iteration 3609 : loss : 0.424235, loss_ce: 0.356264
[01:50:48.357] iteration 3610 : loss : 0.459759, loss_ce: 0.329480
[01:50:48.612] iteration 3611 : loss : 0.427016, loss_ce: 0.263993
[01:50:48.869] iteration 3612 : loss : 0.352452, loss_ce: 0.247518
[01:50:49.128] iteration 3613 : loss : 0.351042, loss_ce: 0.224061
[01:50:49.381] iteration 3614 : loss : 0.448887, loss_ce: 0.349952
[01:50:49.638] iteration 3615 : loss : 0.332817, loss_ce: 0.198194
[01:50:49.898] iteration 3616 : loss : 0.515533, loss_ce: 0.307729
[01:50:51.204] iteration 3617 : loss : 0.301906, loss_ce: 0.184414
[01:50:51.511] iteration 3618 : loss : 0.400050, loss_ce: 0.276490
[01:50:51.848] iteration 3619 : loss : 0.369288, loss_ce: 0.239113
[01:50:52.121] iteration 3620 : loss : 0.461578, loss_ce: 0.383674
[01:50:52.375] iteration 3621 : loss : 0.399876, loss_ce: 0.255081
[01:50:52.627] iteration 3622 : loss : 0.280480, loss_ce: 0.169707
[01:50:52.884] iteration 3623 : loss : 0.310916, loss_ce: 0.251232
[01:50:53.139] iteration 3624 : loss : 0.383695, loss_ce: 0.334748
[01:50:54.052] iteration 3625 : loss : 0.446260, loss_ce: 0.312600
[01:50:54.307] iteration 3626 : loss : 0.370339, loss_ce: 0.293967
[01:50:54.560] iteration 3627 : loss : 0.440449, loss_ce: 0.295782
[01:50:54.813] iteration 3628 : loss : 0.392840, loss_ce: 0.323703
[01:50:55.069] iteration 3629 : loss : 0.343204, loss_ce: 0.211708
[01:50:55.326] iteration 3630 : loss : 0.414968, loss_ce: 0.213557
[01:50:55.608] iteration 3631 : loss : 0.520150, loss_ce: 0.374414
[01:50:55.864] iteration 3632 : loss : 0.401467, loss_ce: 0.261760
[01:50:56.985] iteration 3633 : loss : 0.388698, loss_ce: 0.325352
[01:50:57.237] iteration 3634 : loss : 0.357915, loss_ce: 0.187768
[01:50:57.489] iteration 3635 : loss : 0.483531, loss_ce: 0.264388
[01:50:57.745] iteration 3636 : loss : 0.372935, loss_ce: 0.265026
[01:50:58.001] iteration 3637 : loss : 0.430694, loss_ce: 0.376388
[01:50:58.253] iteration 3638 : loss : 0.451221, loss_ce: 0.347907
[01:50:58.505] iteration 3639 : loss : 0.360945, loss_ce: 0.201837
[01:50:58.761] iteration 3640 : loss : 0.514628, loss_ce: 0.380998
[01:50:59.797] iteration 3641 : loss : 0.365438, loss_ce: 0.195306
[01:51:00.051] iteration 3642 : loss : 0.340363, loss_ce: 0.204940
[01:51:00.308] iteration 3643 : loss : 0.390644, loss_ce: 0.327814
[01:51:00.563] iteration 3644 : loss : 0.518671, loss_ce: 0.326590
[01:51:00.819] iteration 3645 : loss : 0.389894, loss_ce: 0.227330
[01:51:01.075] iteration 3646 : loss : 0.397429, loss_ce: 0.338845
[01:51:01.329] iteration 3647 : loss : 0.288525, loss_ce: 0.173617
[01:51:01.584] iteration 3648 : loss : 0.252994, loss_ce: 0.252658
[01:51:02.645] iteration 3649 : loss : 0.370315, loss_ce: 0.353373
[01:51:02.899] iteration 3650 : loss : 0.372503, loss_ce: 0.242043
[01:51:03.155] iteration 3651 : loss : 0.449797, loss_ce: 0.288240
[01:51:03.411] iteration 3652 : loss : 0.335780, loss_ce: 0.223211
[01:51:03.669] iteration 3653 : loss : 0.471263, loss_ce: 0.263712
[01:51:04.100] iteration 3654 : loss : 0.370680, loss_ce: 0.237137
[01:51:04.355] iteration 3655 : loss : 0.485840, loss_ce: 0.365938
[01:51:04.633] iteration 3656 : loss : 0.474240, loss_ce: 0.469276
[01:51:05.560] iteration 3657 : loss : 0.511017, loss_ce: 0.402924
[01:51:05.816] iteration 3658 : loss : 0.282966, loss_ce: 0.167240
[01:51:06.071] iteration 3659 : loss : 0.353908, loss_ce: 0.243859
[01:51:06.327] iteration 3660 : loss : 0.325008, loss_ce: 0.207624
[01:51:06.582] iteration 3661 : loss : 0.520187, loss_ce: 0.392756
[01:51:06.843] iteration 3662 : loss : 0.428408, loss_ce: 0.248708
[01:51:07.096] iteration 3663 : loss : 0.366638, loss_ce: 0.240822
[01:51:07.351] iteration 3664 : loss : 0.419564, loss_ce: 0.288489
[01:51:08.487] iteration 3665 : loss : 0.422329, loss_ce: 0.248689
[01:51:08.745] iteration 3666 : loss : 0.327892, loss_ce: 0.207296
[01:51:08.998] iteration 3667 : loss : 0.379044, loss_ce: 0.209525
[01:51:09.251] iteration 3668 : loss : 0.308258, loss_ce: 0.185373
[01:51:09.508] iteration 3669 : loss : 0.308958, loss_ce: 0.175337
[01:51:09.760] iteration 3670 : loss : 0.469245, loss_ce: 0.272536
[01:51:10.012] iteration 3671 : loss : 0.434174, loss_ce: 0.334017
[01:51:10.268] iteration 3672 : loss : 0.353926, loss_ce: 0.206156
[01:51:11.478] iteration 3673 : loss : 0.450541, loss_ce: 0.342243
[01:51:11.731] iteration 3674 : loss : 0.365261, loss_ce: 0.229809
[01:51:11.987] iteration 3675 : loss : 0.316852, loss_ce: 0.210557
[01:51:12.240] iteration 3676 : loss : 0.388290, loss_ce: 0.227411
[01:51:12.496] iteration 3677 : loss : 0.366677, loss_ce: 0.257244
[01:51:12.748] iteration 3678 : loss : 0.449394, loss_ce: 0.351680
[01:51:13.000] iteration 3679 : loss : 0.248440, loss_ce: 0.159364
[01:51:13.257] iteration 3680 : loss : 0.465617, loss_ce: 0.377068
[01:51:14.452] iteration 3681 : loss : 0.307725, loss_ce: 0.253752
[01:51:14.705] iteration 3682 : loss : 0.293060, loss_ce: 0.182259
[01:51:14.959] iteration 3683 : loss : 0.321660, loss_ce: 0.185758
[01:51:15.218] iteration 3684 : loss : 0.298910, loss_ce: 0.251737
[01:51:15.475] iteration 3685 : loss : 0.348599, loss_ce: 0.249659
[01:51:15.730] iteration 3686 : loss : 0.396176, loss_ce: 0.225005
[01:51:15.983] iteration 3687 : loss : 0.388226, loss_ce: 0.279467
[01:51:16.239] iteration 3688 : loss : 0.429162, loss_ce: 0.270041
[01:51:17.358] iteration 3689 : loss : 0.439197, loss_ce: 0.312485
[01:51:17.612] iteration 3690 : loss : 0.306246, loss_ce: 0.227334
[01:51:17.865] iteration 3691 : loss : 0.464411, loss_ce: 0.331523
[01:51:18.124] iteration 3692 : loss : 0.449048, loss_ce: 0.182860
[01:51:18.384] iteration 3693 : loss : 0.319252, loss_ce: 0.251943
[01:51:18.641] iteration 3694 : loss : 0.302684, loss_ce: 0.246554
[01:51:18.893] iteration 3695 : loss : 0.349545, loss_ce: 0.175078
[01:51:19.148] iteration 3696 : loss : 0.340316, loss_ce: 0.193047
[01:51:20.319] iteration 3697 : loss : 0.360991, loss_ce: 0.272292
[01:51:20.577] iteration 3698 : loss : 0.415136, loss_ce: 0.304590
[01:51:20.833] iteration 3699 : loss : 0.445347, loss_ce: 0.300181
[01:51:21.088] iteration 3700 : loss : 0.435321, loss_ce: 0.237416
[01:51:21.347] iteration 3701 : loss : 0.389780, loss_ce: 0.231612
[01:51:21.602] iteration 3702 : loss : 0.485497, loss_ce: 0.367395
[01:51:21.855] iteration 3703 : loss : 0.410481, loss_ce: 0.300428
[01:51:22.110] iteration 3704 : loss : 0.394511, loss_ce: 0.304759
[01:51:23.394] iteration 3705 : loss : 0.292752, loss_ce: 0.211866
[01:51:23.647] iteration 3706 : loss : 0.366556, loss_ce: 0.218556
[01:51:23.900] iteration 3707 : loss : 0.314975, loss_ce: 0.256562
[01:51:24.154] iteration 3708 : loss : 0.307704, loss_ce: 0.213256
[01:51:24.411] iteration 3709 : loss : 0.497802, loss_ce: 0.375924
[01:51:24.668] iteration 3710 : loss : 0.532682, loss_ce: 0.383864
[01:51:24.921] iteration 3711 : loss : 0.318944, loss_ce: 0.272856
[01:51:25.190] iteration 3712 : loss : 0.376197, loss_ce: 0.251011
[01:51:26.624] iteration 3713 : loss : 0.450371, loss_ce: 0.258067
[01:51:26.883] iteration 3714 : loss : 0.404200, loss_ce: 0.220758
[01:51:27.137] iteration 3715 : loss : 0.398086, loss_ce: 0.205205
[01:51:27.393] iteration 3716 : loss : 0.433541, loss_ce: 0.240103
[01:51:27.646] iteration 3717 : loss : 0.477701, loss_ce: 0.326496
[01:51:27.900] iteration 3718 : loss : 0.501908, loss_ce: 0.293501
[01:51:28.156] iteration 3719 : loss : 0.409877, loss_ce: 0.260581
[01:51:28.413] iteration 3720 : loss : 0.412968, loss_ce: 0.202946
[01:51:29.544] iteration 3721 : loss : 0.471082, loss_ce: 0.406781
[01:51:29.800] iteration 3722 : loss : 0.416964, loss_ce: 0.267089
[01:51:30.054] iteration 3723 : loss : 0.352351, loss_ce: 0.171122
[01:51:30.294] iteration 3724 : loss : 0.461709, loss_ce: 0.335653
[01:51:30.533] iteration 3725 : loss : 0.406786, loss_ce: 0.455257
[01:51:30.771] iteration 3726 : loss : 0.372118, loss_ce: 0.202173
[01:51:31.001] iteration 3727 : loss : 0.440278, loss_ce: 0.263299
[01:51:31.232] iteration 3728 : loss : 0.357949, loss_ce: 0.306420
[01:51:32.576] iteration 3729 : loss : 0.434516, loss_ce: 0.323001
[01:51:32.809] iteration 3730 : loss : 0.344068, loss_ce: 0.317082
[01:51:33.040] iteration 3731 : loss : 0.461757, loss_ce: 0.331314
[01:51:33.266] iteration 3732 : loss : 0.358161, loss_ce: 0.188118
[01:51:33.491] iteration 3733 : loss : 0.381138, loss_ce: 0.302009
[01:51:33.718] iteration 3734 : loss : 0.309663, loss_ce: 0.259448
[01:51:33.942] iteration 3735 : loss : 0.553944, loss_ce: 0.431345
[01:51:34.167] iteration 3736 : loss : 0.478432, loss_ce: 0.336984
[01:51:35.214] iteration 3737 : loss : 0.308981, loss_ce: 0.190503
[01:51:35.444] iteration 3738 : loss : 0.357802, loss_ce: 0.199215
[01:51:35.666] iteration 3739 : loss : 0.431661, loss_ce: 0.277273
[01:51:35.815] iteration 3740 : loss : 0.554080, loss_ce: 0.239459
[01:51:40.910] iteration 3741 : loss : 0.511111, loss_ce: 0.375241
[01:51:41.163] iteration 3742 : loss : 0.348859, loss_ce: 0.204832
[01:51:41.420] iteration 3743 : loss : 0.386565, loss_ce: 0.221014
[01:51:41.673] iteration 3744 : loss : 0.397497, loss_ce: 0.305083
[01:51:41.927] iteration 3745 : loss : 0.307137, loss_ce: 0.255243
[01:51:42.182] iteration 3746 : loss : 0.370259, loss_ce: 0.354667
[01:51:42.436] iteration 3747 : loss : 0.347537, loss_ce: 0.188754
[01:51:42.693] iteration 3748 : loss : 0.416957, loss_ce: 0.253429
[01:51:43.720] iteration 3749 : loss : 0.457372, loss_ce: 0.231723
[01:51:43.975] iteration 3750 : loss : 0.316463, loss_ce: 0.194330
[01:51:44.231] iteration 3751 : loss : 0.300857, loss_ce: 0.269322
[01:51:44.484] iteration 3752 : loss : 0.348654, loss_ce: 0.330351
[01:51:44.739] iteration 3753 : loss : 0.358128, loss_ce: 0.268836
[01:51:44.993] iteration 3754 : loss : 0.276123, loss_ce: 0.167103
[01:51:45.249] iteration 3755 : loss : 0.405693, loss_ce: 0.241761
[01:51:45.507] iteration 3756 : loss : 0.425739, loss_ce: 0.328733
[01:51:46.599] iteration 3757 : loss : 0.453711, loss_ce: 0.273509
[01:51:46.854] iteration 3758 : loss : 0.347347, loss_ce: 0.241919
[01:51:47.111] iteration 3759 : loss : 0.505834, loss_ce: 0.294145
[01:51:47.363] iteration 3760 : loss : 0.410803, loss_ce: 0.276093
[01:51:47.618] iteration 3761 : loss : 0.393986, loss_ce: 0.313090
[01:51:47.872] iteration 3762 : loss : 0.295598, loss_ce: 0.267450
[01:51:48.124] iteration 3763 : loss : 0.343707, loss_ce: 0.217047
[01:51:48.385] iteration 3764 : loss : 0.460171, loss_ce: 0.296596
[01:51:49.391] iteration 3765 : loss : 0.365869, loss_ce: 0.264372
[01:51:49.645] iteration 3766 : loss : 0.478956, loss_ce: 0.361972
[01:51:49.994] iteration 3767 : loss : 0.345147, loss_ce: 0.162206
[01:51:50.249] iteration 3768 : loss : 0.296802, loss_ce: 0.213673
[01:51:50.506] iteration 3769 : loss : 0.328788, loss_ce: 0.252953
[01:51:50.759] iteration 3770 : loss : 0.376256, loss_ce: 0.251524
[01:51:51.011] iteration 3771 : loss : 0.286317, loss_ce: 0.208355
[01:51:51.269] iteration 3772 : loss : 0.429989, loss_ce: 0.327551
[01:51:52.270] iteration 3773 : loss : 0.434164, loss_ce: 0.293259
[01:51:52.522] iteration 3774 : loss : 0.408296, loss_ce: 0.286965
[01:51:53.027] iteration 3775 : loss : 0.375867, loss_ce: 0.202821
[01:51:53.281] iteration 3776 : loss : 0.450407, loss_ce: 0.333963
[01:51:53.536] iteration 3777 : loss : 0.464908, loss_ce: 0.317674
[01:51:53.792] iteration 3778 : loss : 0.388270, loss_ce: 0.226600
[01:51:54.051] iteration 3779 : loss : 0.320656, loss_ce: 0.190462
[01:51:54.304] iteration 3780 : loss : 0.266619, loss_ce: 0.248346
[01:51:55.076] iteration 3781 : loss : 0.437692, loss_ce: 0.288368
[01:51:55.337] iteration 3782 : loss : 0.293747, loss_ce: 0.194930
[01:51:56.093] iteration 3783 : loss : 0.325591, loss_ce: 0.218857
[01:51:56.350] iteration 3784 : loss : 0.500418, loss_ce: 0.334627
[01:51:56.609] iteration 3785 : loss : 0.428420, loss_ce: 0.374871
[01:51:56.873] iteration 3786 : loss : 0.279007, loss_ce: 0.155608
[01:51:57.128] iteration 3787 : loss : 0.314041, loss_ce: 0.234229
[01:51:57.595] iteration 3788 : loss : 0.441025, loss_ce: 0.283906
[01:51:58.059] iteration 3789 : loss : 0.456129, loss_ce: 0.350592
[01:51:58.312] iteration 3790 : loss : 0.415430, loss_ce: 0.276487
[01:51:59.179] iteration 3791 : loss : 0.322150, loss_ce: 0.200804
[01:51:59.433] iteration 3792 : loss : 0.522576, loss_ce: 0.397214
[01:51:59.686] iteration 3793 : loss : 0.355754, loss_ce: 0.195208
[01:51:59.950] iteration 3794 : loss : 0.409243, loss_ce: 0.250481
[01:52:00.210] iteration 3795 : loss : 0.486107, loss_ce: 0.224611
[01:52:00.523] iteration 3796 : loss : 0.309289, loss_ce: 0.171857
[01:52:01.264] iteration 3797 : loss : 0.402731, loss_ce: 0.276373
[01:52:01.617] iteration 3798 : loss : 0.379147, loss_ce: 0.288020
[01:52:02.476] iteration 3799 : loss : 0.413193, loss_ce: 0.237899
[01:52:02.730] iteration 3800 : loss : 0.370589, loss_ce: 0.275847
[01:52:02.986] iteration 3801 : loss : 0.464556, loss_ce: 0.285481
[01:52:03.239] iteration 3802 : loss : 0.407232, loss_ce: 0.369207
[01:52:03.492] iteration 3803 : loss : 0.450204, loss_ce: 0.272887
[01:52:03.750] iteration 3804 : loss : 0.308719, loss_ce: 0.155302
[01:52:04.199] iteration 3805 : loss : 0.403309, loss_ce: 0.340002
[01:52:04.452] iteration 3806 : loss : 0.469427, loss_ce: 0.254021
[01:52:05.542] iteration 3807 : loss : 0.318899, loss_ce: 0.278127
[01:52:05.797] iteration 3808 : loss : 0.329742, loss_ce: 0.206959
[01:52:06.054] iteration 3809 : loss : 0.455739, loss_ce: 0.321192
[01:52:06.337] iteration 3810 : loss : 0.363869, loss_ce: 0.237088
[01:52:06.591] iteration 3811 : loss : 0.394629, loss_ce: 0.300476
[01:52:06.856] iteration 3812 : loss : 0.395802, loss_ce: 0.283488
[01:52:07.157] iteration 3813 : loss : 0.375190, loss_ce: 0.361716
[01:52:07.393] iteration 3814 : loss : 0.450509, loss_ce: 0.289888
[01:52:08.625] iteration 3815 : loss : 0.425910, loss_ce: 0.253629
[01:52:08.863] iteration 3816 : loss : 0.343754, loss_ce: 0.263329
[01:52:09.103] iteration 3817 : loss : 0.458987, loss_ce: 0.271886
[01:52:09.340] iteration 3818 : loss : 0.389874, loss_ce: 0.212775
[01:52:09.579] iteration 3819 : loss : 0.501407, loss_ce: 0.306892
[01:52:09.816] iteration 3820 : loss : 0.432624, loss_ce: 0.316948
[01:52:10.132] iteration 3821 : loss : 0.394980, loss_ce: 0.265077
[01:52:10.371] iteration 3822 : loss : 0.413726, loss_ce: 0.273147
[01:52:11.664] iteration 3823 : loss : 0.353232, loss_ce: 0.273706
[01:52:11.894] iteration 3824 : loss : 0.263823, loss_ce: 0.240407
[01:52:12.134] iteration 3825 : loss : 0.369750, loss_ce: 0.227389
[01:52:12.369] iteration 3826 : loss : 0.448254, loss_ce: 0.345384
[01:52:12.599] iteration 3827 : loss : 0.453045, loss_ce: 0.302982
[01:52:12.836] iteration 3828 : loss : 0.409196, loss_ce: 0.207839
[01:52:13.103] iteration 3829 : loss : 0.494711, loss_ce: 0.316510
[01:52:13.442] iteration 3830 : loss : 0.315720, loss_ce: 0.304131
[01:52:14.735] iteration 3831 : loss : 0.451101, loss_ce: 0.297032
[01:52:14.969] iteration 3832 : loss : 0.436645, loss_ce: 0.223163
[01:52:15.207] iteration 3833 : loss : 0.390476, loss_ce: 0.346118
[01:52:15.442] iteration 3834 : loss : 0.347775, loss_ce: 0.216305
[01:52:15.674] iteration 3835 : loss : 0.430249, loss_ce: 0.344271
[01:52:15.907] iteration 3836 : loss : 0.323884, loss_ce: 0.281198
[01:52:16.207] iteration 3837 : loss : 0.387083, loss_ce: 0.277680
[01:52:16.525] iteration 3838 : loss : 0.521580, loss_ce: 0.378333
[01:52:17.821] iteration 3839 : loss : 0.350510, loss_ce: 0.245570
[01:52:18.055] iteration 3840 : loss : 0.421364, loss_ce: 0.350532
[01:52:18.293] iteration 3841 : loss : 0.329247, loss_ce: 0.337297
[01:52:18.534] iteration 3842 : loss : 0.379149, loss_ce: 0.284779
[01:52:18.770] iteration 3843 : loss : 0.454384, loss_ce: 0.289697
[01:52:19.003] iteration 3844 : loss : 0.477008, loss_ce: 0.338527
[01:52:19.234] iteration 3845 : loss : 0.447111, loss_ce: 0.257567
[01:52:19.566] iteration 3846 : loss : 0.430948, loss_ce: 0.275945
[01:52:20.849] iteration 3847 : loss : 0.413983, loss_ce: 0.320471
[01:52:21.085] iteration 3848 : loss : 0.391703, loss_ce: 0.225194
[01:52:21.320] iteration 3849 : loss : 0.349237, loss_ce: 0.272096
[01:52:21.554] iteration 3850 : loss : 0.378372, loss_ce: 0.228348
[01:52:21.789] iteration 3851 : loss : 0.421910, loss_ce: 0.274431
[01:52:22.020] iteration 3852 : loss : 0.448130, loss_ce: 0.283345
[01:52:22.252] iteration 3853 : loss : 0.395075, loss_ce: 0.248347
[01:52:22.508] iteration 3854 : loss : 0.390533, loss_ce: 0.224051
[01:52:23.850] iteration 3855 : loss : 0.468089, loss_ce: 0.254042
[01:52:24.079] iteration 3856 : loss : 0.378039, loss_ce: 0.234453
[01:52:24.306] iteration 3857 : loss : 0.337181, loss_ce: 0.257864
[01:52:24.538] iteration 3858 : loss : 0.434464, loss_ce: 0.256459
[01:52:24.766] iteration 3859 : loss : 0.542322, loss_ce: 0.369883
[01:52:25.004] iteration 3860 : loss : 0.441309, loss_ce: 0.193927
[01:52:25.242] iteration 3861 : loss : 0.421093, loss_ce: 0.362084
[01:52:25.476] iteration 3862 : loss : 0.364202, loss_ce: 0.202512
[01:52:26.611] iteration 3863 : loss : 0.442594, loss_ce: 0.275458
[01:52:26.840] iteration 3864 : loss : 0.369712, loss_ce: 0.190672
[01:52:27.068] iteration 3865 : loss : 0.452145, loss_ce: 0.384448
[01:52:27.302] iteration 3866 : loss : 0.376582, loss_ce: 0.265253
[01:52:27.530] iteration 3867 : loss : 0.526572, loss_ce: 0.352935
[01:52:27.763] iteration 3868 : loss : 0.515280, loss_ce: 0.311184
[01:52:28.002] iteration 3869 : loss : 0.361798, loss_ce: 0.315066
[01:52:28.389] iteration 3870 : loss : 0.323850, loss_ce: 0.208918
[01:52:29.324] iteration 3871 : loss : 0.442572, loss_ce: 0.214497
[01:52:29.559] iteration 3872 : loss : 0.415612, loss_ce: 0.365475
[01:52:29.791] iteration 3873 : loss : 0.421055, loss_ce: 0.272169
[01:52:30.026] iteration 3874 : loss : 0.375961, loss_ce: 0.240197
[01:52:30.284] iteration 3875 : loss : 0.400992, loss_ce: 0.290484
[01:52:30.521] iteration 3876 : loss : 0.436091, loss_ce: 0.297102
[01:52:30.926] iteration 3877 : loss : 0.390226, loss_ce: 0.287964
[01:52:31.346] iteration 3878 : loss : 0.412731, loss_ce: 0.199956
[01:52:32.233] iteration 3879 : loss : 0.346789, loss_ce: 0.230577
[01:52:32.464] iteration 3880 : loss : 0.485540, loss_ce: 0.242028
[01:52:32.695] iteration 3881 : loss : 0.344782, loss_ce: 0.203522
[01:52:32.932] iteration 3882 : loss : 0.447868, loss_ce: 0.222469
[01:52:33.169] iteration 3883 : loss : 0.421228, loss_ce: 0.210521
[01:52:33.403] iteration 3884 : loss : 0.475230, loss_ce: 0.390878
[01:52:33.866] iteration 3885 : loss : 0.396513, loss_ce: 0.348233
[01:52:34.353] iteration 3886 : loss : 0.468785, loss_ce: 0.323596
[01:52:35.101] iteration 3887 : loss : 0.457251, loss_ce: 0.259843
[01:52:35.382] iteration 3888 : loss : 0.390376, loss_ce: 0.241760
[01:52:35.641] iteration 3889 : loss : 0.351431, loss_ce: 0.200994
[01:52:35.894] iteration 3890 : loss : 0.444288, loss_ce: 0.263833
[01:52:36.156] iteration 3891 : loss : 0.458290, loss_ce: 0.251326
[01:52:36.467] iteration 3892 : loss : 0.250289, loss_ce: 0.193109
[01:52:36.971] iteration 3893 : loss : 0.389076, loss_ce: 0.188984
[01:52:37.380] iteration 3894 : loss : 0.319609, loss_ce: 0.205636
[01:52:38.192] iteration 3895 : loss : 0.266748, loss_ce: 0.224737
[01:52:38.420] iteration 3896 : loss : 0.438904, loss_ce: 0.319693
[01:52:38.645] iteration 3897 : loss : 0.377427, loss_ce: 0.269529
[01:52:38.882] iteration 3898 : loss : 0.417280, loss_ce: 0.327093
[01:52:39.115] iteration 3899 : loss : 0.417341, loss_ce: 0.162397
[01:52:39.350] iteration 3900 : loss : 0.385102, loss_ce: 0.276152
[01:52:39.916] iteration 3901 : loss : 0.397297, loss_ce: 0.242209
[01:52:40.427] iteration 3902 : loss : 0.417081, loss_ce: 0.223335
[01:52:41.147] iteration 3903 : loss : 0.347301, loss_ce: 0.160572
[01:52:41.409] iteration 3904 : loss : 0.302424, loss_ce: 0.168874
[01:52:41.674] iteration 3905 : loss : 0.407762, loss_ce: 0.327765
[01:52:41.951] iteration 3906 : loss : 0.320235, loss_ce: 0.244610
[01:52:42.212] iteration 3907 : loss : 0.433407, loss_ce: 0.321910
[01:52:42.472] iteration 3908 : loss : 0.397449, loss_ce: 0.262081
[01:52:42.973] iteration 3909 : loss : 0.396753, loss_ce: 0.251300
[01:52:43.488] iteration 3910 : loss : 0.349290, loss_ce: 0.193576
[01:52:44.174] iteration 3911 : loss : 0.406830, loss_ce: 0.324718
[01:52:44.444] iteration 3912 : loss : 0.332188, loss_ce: 0.287411
[01:52:44.707] iteration 3913 : loss : 0.318762, loss_ce: 0.209374
[01:52:44.975] iteration 3914 : loss : 0.289093, loss_ce: 0.221214
[01:52:45.239] iteration 3915 : loss : 0.388855, loss_ce: 0.236072
[01:52:45.503] iteration 3916 : loss : 0.344601, loss_ce: 0.266715
[01:52:46.069] iteration 3917 : loss : 0.369538, loss_ce: 0.195076
[01:52:46.477] iteration 3918 : loss : 0.372568, loss_ce: 0.343404
[01:52:47.196] iteration 3919 : loss : 0.426748, loss_ce: 0.329249
[01:52:47.452] iteration 3920 : loss : 0.423124, l